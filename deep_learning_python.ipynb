{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep-learning-python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "11A2mcExEnNuXnWWiV9veJp3dm42k8Bm2",
      "authorship_tag": "ABX9TyNZys9eOoEd/tg0Knfx3WfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marabian/toxic-comment-classification/blob/master/deep_learning_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RtkzhYT_k5b"
      },
      "source": [
        "# ***Deep Learning with Python***\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWUgSvsP_xRz"
      },
      "source": [
        "**Definitions**\n",
        "\n",
        "*Artificial Intelligence* - the effort to automate intellectual tasks normally performed by humans. \n",
        "\n",
        "*Machine Learning* - Machine learning discovers rules to execute a data-processing task, given examples of what's expected.\n",
        "ML is a subset of artificial intelligence; in fact, it’s simply a technique for realizing AI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhMns_Ho_1rn"
      },
      "source": [
        "# check colab gpu if using\n",
        "# ! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYrQORJ__xV9"
      },
      "source": [
        "# <font color=\"orange\">What is Machine Learning?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbt3Nu3fOoBr"
      },
      "source": [
        "**Machine learning** discovers rules to execute a data-processing task, given examples of what's expected.\n",
        "\n",
        "So, to do **machine learning** we need three things:\n",
        "\n",
        "  * Input data points\n",
        "  * Examples out expected output\n",
        "  * A way to measure whether the algorithm is doing a good job. This is necessary in order to determine the distance between the algorithm’s current output and its expected output. The measurement is used as a feedback signal to adjust the way the algorithm works. This adjustment step is what we call learning.\n",
        "\n",
        "\n",
        "\n",
        "A machine-learning model transforms its input data into meaningful outputs, a process that is “learned” from exposure to known examples of inputs and outputs. Therefore, the central problem in machine learning and deep learning is to *meaningfully\n",
        "transform data*: in other words, to learn useful *representations* of the input data at\n",
        "hand—representations that get us closer to the expected output. \n",
        "\n",
        "*Learning*, in the context of machine learning, describes an automatic search\n",
        "process for better representations. \n",
        "\n",
        "All machine-learning algorithms consist of automatically finding such transformations that turn data into more-useful representations for a given task. These operations can be coordinate changes, or linear projections (which may\n",
        "destroy information), translations, nonlinear operations (such as “select all points\n",
        "such that x > 0”), and so on. \n",
        "Machine-learning algorithms aren’t usually creative in finding these transformations; they’re merely searching through a predefined set of operations, called a *hypothesis space*.\n",
        "\n",
        "So that’s what machine learning is, technically: searching for useful representations of some input data, within a predefined space of possibilities, using guidance\n",
        "from a feedback signal. This simple idea allows for solving a remarkably broad range\n",
        "of intellectual tasks, from speech recognition to autonomous car driving.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0OsW1kMOoEb"
      },
      "source": [
        "# <font color=\"orange\">What is Deep Learning?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doQtHMQPXgqG"
      },
      "source": [
        "Deep learning is a specific subfield of machine learning: a new take on learning representations from data that puts an emphasis on learning successive *layers* of increasingly\n",
        "meaningful representations. The *deep* in *deep learning* isn’t a reference to any kind of deeper understanding achieved by the approach; rather, it stands for this idea of successive layers of representations.  How many layers contribute to a model of the data is called the *depth* of the model.\n",
        "Other appropriate names for the field could have been\n",
        "*layered representations learning* and *hierarchical representations learning*.\n",
        "\n",
        "In deep learning, these layered representations are (almost always) learned via models called **neural networks**, structured in literal layers stacked on top of each other.\n",
        "\n",
        "For our purposes, deep learning is a mathematical framework for **learning representations from data**.\n",
        "\n",
        "The specification of what a layer does to its input data is stored in the layer’s *weights*, which in essence are a bunch of numbers. In technical terms, we’d say that the transformation implemented by a layer is *parameterized* by its weights (see figure 1.7). (Weights are also sometimes called the parameters of a layer.) In this context, learning\n",
        "means finding a set of values for the weights of all layers in a network, such that the\n",
        "network will correctly map example inputs to their associated targets. But here’s the thing: a deep neural network can contain tens of millions of parameters. Finding the correct value for all of them may seem like a daunting task, especially given that modifying the value of one parameter will affect the behavior of all the others!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NcCCilPeRLJ"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1cKYKaLeFCyiG098BYNXXsZFrFzpJW6no\">\n",
        "</img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1eQFpmxhVM7"
      },
      "source": [
        "To control something, first you need to be able to observe it. To control the output of a neural network, you need to be able to measure how far this output is from what you expected. This is the job of the **loss function** of the network, also called the **objective function**. The loss function takes the predictions of the network and the true target (what you wanted the network to output) and computes a distance score, capturing how well the network has done on this specific example.\n",
        "\n",
        "The fundamental trick in deep learning is to use this score as a feedback signal to adjust the value of the weights a little, in a direction that will lower the loss score for the current example (see figure 1.9). This adjustment is the job of the **optimizer**, which implements what’s called the *Backpropagation algorithm*: the central algorithm in deep learning. The next chapter explains in more detail how backpropagation works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyrTiXL7fDy7"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1lhFvbFl93q-kZo6LRnQpfpFloKSu3nYu\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adwjCoS3hcvN"
      },
      "source": [
        "Initially, the weights of the network are assigned random values, so the network merely implements a series of random transformations. Naturally, its output is far from what it should ideally be, and the loss score is accordingly very high. But with every example the network processes, the weights are adjusted a little in the correct direction, and the loss score decreases. This is the training loop, which, repeated a sufficient number of times (typically tens of iterations over thousands of examples), yields\n",
        "weight values that minimize the loss function. A network with a minimal loss is one for which the outputs are as close as they can be to the targets: a trained network. Once again, it’s a simple mechanism that, once scaled, ends up looking like magic. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mh6m5iyBL6n"
      },
      "source": [
        "# <font color=\"orange\">Some History</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWbC1YfeByc0"
      },
      "source": [
        "### **Two \"AI winters\"**\n",
        "First one in 1960s/early 1970s with the rise of **symbolic AI** (Marvin Minsky, Perceptron), which experts believed would create human-level artificial intelligence within a decade.<br>\n",
        "Second one in the 1980s, a new take on symbolic AI, **expert systems**, but by the early 1990s, these systems had proven expensive to maintain, difficult to scale, and limited in scope, and interest died down. Thus began the second AI winter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXgHtISwB33O"
      },
      "source": [
        "### **Early neural networks**\n",
        "The first successful practical application of neural nets came in 1989 from Bell Labs, when Yann LeCun combined the earlier ideas of convolutional neural networks and backpropagation, and applied them to the problem of classifying handwritten digits. The resulting network, dubbed *LeNet*, was used by the United States Postal Service in the 1990s to automate the reading of ZIP codes on mail envelopes. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGYGEReqhc2r"
      },
      "source": [
        "### **Kernel methods (SVM)**\n",
        "As neural networks started to gain some respect among researchers in the 1990s, thanks to this first success, a new approach to machine learning rose to fame and quickly sent neural nets back to oblivion: **kernel methods**. Kernel methods are a group of classification algorithms, the best known of which is the **support vector machine** (SVM).\n",
        "\n",
        "The modern formulation of an SVM was developed by Vladimir\n",
        "Vapnik and Corinna Cortes in the early 1990s at Bell Labs and\n",
        "published in 1995, although an older linear formulation was\n",
        "published by Vapnik and Alexey Chervonenkis as early as 1963.\n",
        "\n",
        "SVMs aim at solving classification problems by finding good\n",
        "decision boundaries (see figure 1.10) between two sets of points\n",
        "belonging to two different categories. A decision boundary can\n",
        "be thought of as a line or surface separating your training data\n",
        "into two spaces corresponding to two categories. To classify new\n",
        "data points, you just need to check which side of the decision\n",
        "boundary they fall on.\n",
        "\n",
        "SVMs proceed to find these boundaries in two steps:\n",
        "1. The data is mapped to a new high-dimensional representation where the\n",
        "decision boundary can be expressed as a hyperplane (if the data was twodimensional, as in figure 1.10, a hyperplane would be a straight line).\n",
        "2. A good decision boundary (a separation hyperplane) is computed by trying to\n",
        "maximize the distance between the hyperplane and the closest data points from\n",
        "each class, a step called maximizing the margin. This allows the boundary to generalize well to new samples outside of the training dataset.\n",
        "\n",
        "The technique of mapping data to a high-dimensional representation where a classification problem becomes simpler may look good on paper, but in practice it’s\n",
        "often computationally intractable. That’s where the **kernel trick** comes in (the key idea\n",
        "that kernel methods are named after). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUmLjzf_oASh"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=18uGP8nhf3-tD3gXNZK5x4YwvbTdawLax\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUxsFZC0nl6X"
      },
      "source": [
        "Here’s the gist of it: to find good decision hyperplanes in the new representation space, you don’t have to explicitly compute\n",
        "the coordinates of your points in the new space; you just need to compute the distance between pairs of points in that space, which can be done efficiently using a **kernel function**. A kernel function is a computationally tractable operation that maps any\n",
        "two points in your initial space to the distance between these points in your target representation space, completely bypassing the explicit computation of the new representation. Kernel functions are typically crafted by hand rather than learned from\n",
        "data—in the case of an SVM, only the separation hyperplane is learned.\n",
        "\n",
        "\n",
        "At the time they were developed, SVMs exhibited state-of-the-art performance on simple classification problems and were one of the few machine-learning methods backed by extensive theory and amenable to serious mathematical analysis, making them well understood and easily interpretable. Because of these useful properties, SVMs became extremely popular in the field for a \n",
        "long time. \n",
        "\n",
        "But SVMs proved hard to scale to large datasets and didn’t provide good results for perceptual problems such as image classification. Because an SVM is a shallow\n",
        "method, applying an SVM to perceptual problems requires first extracting useful representations manually (a step called **feature engineering**), which is difficult and brittle. \n",
        "\n",
        "*Approaches to machine learning that tend to focus on learning only one or two layers of representations of the data are sometimes called shallow learning.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbQWK0oh1mv8"
      },
      "source": [
        "### **Decision trees, random forests, and gradient boosting machines**\n",
        "\n",
        "**Decision trees** are flowchart-like structures that let you classify input data points or predict output values given inputs (see figure 1.11). They’re easy to visualize and interpret. Decisions trees learned from data began to receive significant research interest\n",
        "in the 2000s, and by 2010 they were often preferred to kernel methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RycmsPOQ1m0W"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1B7rIcK8mD5ovI9t7zUgrfttm23mhAO2a\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LacJFtBq1m4R"
      },
      "source": [
        "In particular, the **Random Forest** algorithm introduced a robust, practical take on decision-tree learning that involves building a large number of specialized decision trees and then ensembling their outputs. Random forests are applicable to a wide range of problems—you could say that they’re almost always the second-best algorithm for any shallow machine-learning task. When the popular machine-learning competition website Kaggle (http://kaggle.com) got started in 2010, random forests quickly became a favorite on the platform—until 2014, when gradient boosting machines took over. \n",
        "\n",
        "A gradient boosting machine, much like a random forest, is a machine-learning\n",
        "technique based on ensembling weak prediction models, generally decision trees. It uses **gradient boosting**, a way to improve any machine-learning model by iteratively training new models that specialize in addressing the weak points of the previous models.\n",
        "Applied to decision trees, the use of the gradient boosting technique results in models\n",
        "that strictly outperform random forests most of the time, while having similar properties. It may be one of the best, if not the best, algorithm for dealing with nonperceptual\n",
        "data today. Alongside deep learning, it’s one of the most commonly used techniques in\n",
        "Kaggle competitions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ohpJVJ21m25"
      },
      "source": [
        "### **Back to neural networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct4MRYVE3EQ3"
      },
      "source": [
        "Around 2010, although neural networks were almost completely shunned by the scientific community at large, a number of people still working on neural networks started to make important breakthroughs: the groups of Geoffrey Hinton at the University of Toronto, Yoshua Bengio at the University of Montreal, Yann LeCun at New York University, and IDSIA in Switzerland.\n",
        "\n",
        "\n",
        " In 2011, Dan Ciresan from IDSIA began to win academic image-classification competitions with GPU-trained deep neural networks—the first practical success of modern deep learning. But the watershed moment came in 2012, with the entry of\n",
        "Hinton’s group in the yearly large-scale image-classification challenge ImageNet. The\n",
        "ImageNet challenge was notoriously difficult at the time, consisting of classifying highresolution color images into 1,000 different categories after training on 1.4 million\n",
        "images. In 2011, the top-five accuracy of the winning model, based on classical\n",
        "approaches to computer vision, was only 74.3%. Then, in 2012, a team led by Alex\n",
        "Krizhevsky and advised by Geoffrey Hinton was able to achieve a top-five accuracy of\n",
        "83.6%—a significant breakthrough. The competition has been dominated by deep\n",
        "convolutional neural networks every year since. By 2015, the winner reached an accuracy of 96.4%, and the classification task on ImageNet was considered to be a completely solved problem.\n",
        "\n",
        "Since 2012, deep convolutional neural networks (convnets) have become the go-to\n",
        "algorithm for all computer vision tasks; more generally, they work on all perceptual\n",
        "tasks. At major computer vision conferences in 2015 and 2016, it was nearly impossible to find presentations that didn’t involve convnets in some form. At the same time,\n",
        "deep learning has also found applications in many other types of problems, such as\n",
        "natural-language processing. It has completely replaced SVMs and decision trees in a\n",
        "wide range of applications. For instance, for several years, the European Organization\n",
        "for Nuclear Research, CERN, used decision tree–based methods for analysis of particle\n",
        "data from the ATLAS detector at the Large Hadron Collider (LHC); but CERN eventually switched to Keras-based deep neural networks due to their higher performance\n",
        "and ease of training on large datasets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wega7Fd03EYP"
      },
      "source": [
        "### **What makes Deep Learning different?**\n",
        "The primary reason deep learning took off so quickly is that it offered better performance on many problems. But that’s not the only reason. Deep learning also makes problem-solving much easier, because it completely automates what used to be the\n",
        "most crucial step in a machine-learning workflow: feature engineering.\n",
        "\n",
        "Previous machine-learning techniques—shallow learning—only involved transforming the input data into one or two successive representation spaces, usually via\n",
        "simple transformations such as high-dimensional non-linear projections (SVMs) or\n",
        "decision trees. But the refined representations required by complex problems generally can’t be attained by such techniques. As such, humans had to go to great lengths\n",
        "to make the initial input data more amenable to processing by these methods: they\n",
        "had to manually engineer good layers of representations for their data. This is called **feature engineering**. Deep learning, on the other hand, completely automates this step: with deep learning, you learn all features in one pass rather than having to engineer them yourself. This has greatly simplified machine-learning workflows, often replacing sophisticated multistage pipelines with a single, simple, end-to-end deep-learning\n",
        "model.\n",
        "\n",
        "The two essential characteristics of how deep learning learns from data:\n",
        "the **incremental, layer-by-layer way in which increasingly complex representations are developed**,\n",
        "and **the fact that these intermediate incremental representations are learned jointly**, each layer\n",
        "being updated to follow both the representational needs of the layer above and the\n",
        "needs of the layer below. Together, these two properties have made deep learning\n",
        "vastly more successful than previous approaches to machine learning.\n",
        "\n",
        "The two techniques you should be the most familiar with in order to be\n",
        "successful in applied machine learning today: *gradient boosting machines*, for **shallowlearning problems**; and *deep learning*, for **perceptual problems**. In technical terms, this means you’ll need to be familiar with **XGBoost** and **Keras**—the two libraries that currently dominate Kaggle competitions. With this book in hand, you’re already one big step closer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_ow5ggE4uAc"
      },
      "source": [
        "**Why deep learning? Why now?**\n",
        "\n",
        "The two key ideas of deep learning for computer vision—convolutional neural networks and backpropagation—were already well understood in 1989. The Long ShortTerm Memory (LSTM) algorithm, which is fundamental to deep learning for\n",
        "timeseries, was developed in 1997 and has barely changed since. So why did deep\n",
        "learning only take off after 2012? What changed in these two decades?\n",
        " In general, three technical forces are driving advances in machine learning:\n",
        " * Hardware\n",
        " * Datasets and benchmarks\n",
        " * Algorithms\n",
        "\n",
        "In addition to hardware and data, until the late 2000s, we were missing a reliable way to train very deep neural networks. As a result, neural networks were still fairly shallow, using only one or two layers of representations; thus, they weren’t able to shine against more-refined shallow methods such as SVMs and random forests. The key issue was that of **gradient propagation** through deep stacks of layers. The feedback signal used to train\n",
        "neural networks would fade away as the number of layers increased.\n",
        "\n",
        "This changed around 2009–2010 with the advent of several simple but important\n",
        "algorithmic improvements that allowed for better gradient propagation:\n",
        "* Better **activation functions**\n",
        "* Better **weight-initialization schemes**, starting with layer-wise pretraining, which was quickly abandoned\n",
        "* Better **optimization schemes**, such as *RMSProp* and *Adam*\n",
        "\n",
        "Only when these improvements began to allow for training models with 10 or more layers did deep learning start to shine.\n",
        "\n",
        "Finally, in 2014, 2015, and 2016, even more advanced ways to help gradient propagation were discovered, such as batch normalization, residual connections, and depthwise separable convolutions. Today we can train from scratch models that are\n",
        "thousands of layers deep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOGusfm9AxZz"
      },
      "source": [
        "### **The democratiziation of deep learning**\n",
        "\n",
        "One of the key factors driving this inflow of new faces in deep learning has been thedemocratization of the toolsets used in the field. In the early days, doing deep learning required significant C++ and CUDA expertise, which few people possessed. Nowadays, basic Python scripting skills suffice to do advanced deep-learning research. This has been\n",
        "driven most notably by the development of Theano and then TensorFlow—two symbolic tensor-manipulation frameworks for Python that support autodifferentiation, greatly simplifying the implementation of new models—and by the rise of user-friendly libraries such as Keras, which makes deep learning as easy as manipulating LEGO bricks. After its\n",
        "release in early 2015, Keras quickly became the go-to deep-learning solution for large numbers of new startups, graduate students, and researchers pivoting into the field. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oAHzWvjAxdE"
      },
      "source": [
        "### **Will it last?**\n",
        "\n",
        "Is there anything special about deep neural networks that makes them the “right”\n",
        "approach for companies to be investing in and for researchers to flock to? Or is deep\n",
        "learning just a fad that may not last? Will we still be using deep neural networks in\n",
        "20 years?\n",
        "\n",
        "Deep learning has several properties that justify its status as an AI revolution, and\n",
        "it’s here to stay. We may not be using neural networks two decades from now, but whatever we use will directly inherit from modern deep learning and its core concepts.\n",
        "These important properties can be broadly sorted into three categories:\n",
        "* *Simplicity* — Deep learning removes the need for feature engineering, replacing\n",
        "complex, brittle, engineering-heavy pipelines with simple, end-to-end trainable\n",
        "models that are typically built using only five or six different tensor operations.\n",
        "* *Scalability* — Deep learning is highly amenable to parallelization on GPUs or\n",
        "TPUs, so it can take full advantage of Moore’s law. In addition, deep-learning\n",
        "models are trained by iterating over small batches of data, allowing them to be\n",
        "trained on datasets of arbitrary size. (The only bottleneck is the amount of\n",
        "parallel computational power available, which, thanks to Moore’s law, is a fastmoving barrier.)\n",
        "* *Versatility and reusability* — Unlike many prior machine-learning approaches, deep-learning models can be trained on additional data without restarting from\n",
        "scratch, making them viable for continuous online learning—an important property for very large production models. Furthermore, trained deep-learning models are repurposable and thus reusable: for instance, it’s possible to take a deep-learning model trained for image classification and drop it into a videoprocessing pipeline. This allows us to reinvest previous work into increasingly complex and powerful models. This also makes deep learning applicable to\n",
        "fairly small datasets.\n",
        "\n",
        "\n",
        "Deep learning has only been in the spotlight for a few years, and we haven’t yet established the full scope of what it can do. With every passing month, we learn about new\n",
        "use cases and engineering improvements that lift previous limitations. Following a scientific revolution, progress generally follows a sigmoid curve: it starts with a period of fast progress, which gradually stabilizes as researchers hit hard limitations, and then further improvements become incremental. Deep learning in 2017 seems to be in the first half of that sigmoid, with much more progress to come in the next few years"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4STTHZg6Axfm"
      },
      "source": [
        "# <font color=\"orange\">**The Mathematical Building Blocks of Neural Networks**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eojtJsH-AxcE"
      },
      "source": [
        "**Note on classes and labels**<br>\n",
        "In machine learning, a category in a classification problem is called a **class**. Data points are called **samples**. The class associated with a specific sample is called a\n",
        "**label**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YibuilFE_yvI",
        "outputId": "372fee61-99fc-4cbb-8817-43b2af3b5496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhM1G_ELFKdi",
        "outputId": "984ba5de-d8ea-470a-e430-2e17517792be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXx71LrdFTZb",
        "outputId": "729a5572-549c-493d-a416-31448821c581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GDPPhr5F3cL"
      },
      "source": [
        "The core building block of neural networks is the **layer**, a data-processing module that you can think of as a filter for data. Some data goes in, and it comes out in a more useful form. Specifically, layers extract **representations** out of the data fed into them—hopefully, representations that are more meaningful for the problem at hand. Most of deep learning consists of chaining together simple layers that will implement a form\n",
        "of progressive **data distillation**. A deep-learning model is like a sieve for data processing, made of a succession of increasingly refined data filters — the layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1c8RkvAF7Fk",
        "outputId": "4d687644-122e-4a7b-ecfa-d539d4789224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_jpfNXLKJKd"
      },
      "source": [
        "### <font color=\"MediumSeaGreen\">**Tensors**</font>\n",
        "***\n",
        "At its core, a tensor is a container for data—almost always numerical data. So, it’s a container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions\n",
        "(note that in the context of tensors, a dimension is often called an axis). The number of axes of a tensor is also called its **rank**.\n",
        "\n",
        "A tensor is defined by three key attributes:\n",
        "* **Number of axes (rank)** — For instance, a 3D tensor has three axes, and a matrix has\n",
        "two axes. This is also called the tensor’s ndim in Python libraries such as Numpy.\n",
        "* **Shape** — This is a tuple of integers that describes how many dimensions the tensor has along each axis. For instance, the previous matrix example has shape\n",
        "(3, 5), and the 3D tensor example has shape (3, 3, 5). A vector has a shape\n",
        "with a single element, such as (5,), whereas a scalar has an empty shape, ().\n",
        "* **Data type** (usually called **dtype** in Python libraries) — This is the type of the data\n",
        "contained in the tensor; for instance, a tensor’s type could be float32, uint8,\n",
        "float64, and so on. On rare occasions, you may see a char tensor. Note that\n",
        "string tensors don’t exist in Numpy (or in most other libraries), because tensors\n",
        "live in preallocated, contiguous memory segments: and strings, being variable\n",
        "length, would preclude the use of this implementation.\n",
        "\n",
        "\n",
        "**Dimensionality** can denote either the number of entries along a specific axis (as in the case of our 5D vector) or the number of axes in a tensor (such as a\n",
        "5D tensor), which can be confusing at times. In the latter case, it’s technically more\n",
        "correct to talk about a tensor of rank 5 (the rank of a tensor being the number of axes),\n",
        "but the ambiguous notation 5D tensor is common regardless. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc2fOg1FKQpH",
        "outputId": "fb3519f7-6359-4da7-c305-586c082a9cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKSQGCvIVH7y"
      },
      "source": [
        "### **Manipulating tensors in Numpy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ppKQ7tzVMMt"
      },
      "source": [
        "Selecting specific elements in a tensor is called **tensor slicing**. Let’s look at the tensor-slicing operations you can do on Numpy arrays. The following example selects digits #10 to #100 (#100 isn’t included) and puts\n",
        "them in an array of shape (90, 28, 28):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ApDgYk1VIqr",
        "outputId": "49b1a76f-25b8-40e4-b6a2-9ac7fb3bdee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# tensor slicing - example 1\n",
        "my_slice = train_images[10:100]\n",
        "print(my_slice.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13YEbrpOVbsM"
      },
      "source": [
        "It’s equivalent to this more detailed notation, which specifies a start index and stop index for the slice along each tensor axis. Note that : is equivalent to selecting the\n",
        "entire axis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97dLXY_aVSa-",
        "outputId": "fa034140-28c2-46e1-c60e-85fdcd1772ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# tensor slicing -example 2\n",
        "my_slice = train_images[10:100, :, :]\n",
        "my_slice.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCArb_DaVsh4",
        "outputId": "33b03c41-5314-445b-aac3-5fcd4e71688d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Also equivalent to previous example\n",
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "my_slice.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCnTTsn4WPXR"
      },
      "source": [
        "In general, you may select between any two indices along each tensor axis. For instance, in order to select 14 × 14 pixels in the bottom-right corner of all images, you\n",
        "do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhUioWwhVsj8",
        "outputId": "2c27798f-fc2c-44e6-f59c-00876cb67515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "my_slice = train_images[:, 14:, 14:]\n",
        "print(my_slice.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Op2yxbHWa4K"
      },
      "source": [
        "It’s also possible to use negative indices. Much like negative indices in Python lists, they indicate a position relative to the end of the current axis. In order to crop the images to patches of 14 × 14 pixels centered in the middle, you do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHBHfgJdWY9O",
        "outputId": "9bc840e9-2696-40d8-c814-799a429a665d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "my_slice = train_images[:, 7:-7, 7:-7]\n",
        "print(my_slice.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 14, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXRbFtIBWfa0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0ET5Ym9Wr0X"
      },
      "source": [
        "### **The notation of data batches**\n",
        "\n",
        "\n",
        "In general, the first axis (axis 0, because indexing starts at 0) in all data tensors you’ll\n",
        "come across in deep learning will be the **samples axis**  (sometimes called the **samples dimension**). In the MNIST example, samples are images of digits. In addition, deep-learning models don’t process an entire dataset at once; rather, they break the data into small batches. Concretely, here’s one batch of our MNIST digits, with batch size of 128:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPaCZ45iWyvv",
        "outputId": "b2cdf29a-2550-45a7-aec6-159590fd9101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch = train_images[:128]\n",
        "print(batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz2UTu3AXYtB",
        "outputId": "b6cb5f7e-0597-4d79-85e9-1b44e0339d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# And here’s the next batch:\n",
        "batch = train_images[128:256]\n",
        "print(batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBSvptiBXSd3"
      },
      "source": [
        "When considering such a **batch tensor**, the first axis (axis 0) is called the **batch axis** or **batch dimension**. This is a term you’ll frequently encounter when using Keras and other\n",
        "deep-learning libraries. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkp3GMsPXhU2"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Real-world examples of data tensors**</font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1_PEIDBXkho"
      },
      "source": [
        "Let’s make data tensors more concrete with a few examples similar to what you’ll encounter later. The data you’ll manipulate will almost always fall into one of the following categories:\n",
        "\n",
        "* **Vector data** — 2D tensors of shape (samples, features)\n",
        "* **Timeseries data** or **sequence data** — 3D tensors of shape (samples, timesteps,\n",
        "features)\n",
        "* **Image data** — 4D tensors of shape (samples, height, width, channels) or (samples,\n",
        "channels, height, width)\n",
        "* **Video data** — 5D tensors of shape (samples, frames, height, width, channels) or\n",
        "(samples, frames, channels, height, width)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esyPXGTpaFbG"
      },
      "source": [
        "### **Vector data**\n",
        "\n",
        "This is the most common case. In such a dataset, each single data point can be encoded as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of vectors), where the first axis is the **samples axis** and the second axis is the **features axis**.\n",
        "\n",
        "\n",
        "Let’s take a look at two examples:\n",
        "* An actuarial dataset of people, where we consider each person’s age, ZIP code,\n",
        "and income. Each person can be characterized as a vector of 3 values, and thus\n",
        "an entire dataset of 100,000 people can be stored in a 2D tensor of shape\n",
        "(100000, 3).\n",
        "\n",
        "* A dataset of text documents, where we represent each document by the counts\n",
        "of how many times each word appears in it (out of a dictionary of 20,000 common words). Each document can be encoded as a vector of 20,000 values (one\n",
        "count per word in the dictionary), and thus an entire dataset of 500 documents\n",
        "can be stored in a tensor of shape (500, 20000). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fAolliraLtZ"
      },
      "source": [
        "### **Timeseries data or sequence data**\n",
        "\n",
        "Whenever time matters in your data (or the notion of sequence order), it makes sense to store it in a 3D tensor with an explicit time axis. Each sample can be encoded as a\n",
        "sequence of vectors (a 2D tensor), and thus a batch of data will be encoded as a 3D\n",
        "tensor (see figure 2.3).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1zenn_ewWQWfloKdLfTVTp716eHO_hiOp\"></img>\n",
        "\n",
        "\n",
        "The time axis is always the second axis (axis of index 1), by convention. Let’s look at a few examples:\n",
        "* A dataset of stock prices. Every minute, we store the current price of the stock,\n",
        "the highest price in the past minute, and the lowest price in the past minute.\n",
        "Thus every minute is encoded as a 3D vector, an entire day of trading is\n",
        "encoded as a 2D tensor of shape (390, 3) (there are 390 minutes in a trading\n",
        "day), and 250 days’ worth of data can be stored in a 3D tensor of shape (250,\n",
        "390, 3). Here, each sample would be one day’s worth of data.\n",
        "\n",
        "* A dataset of tweets, where we encode each tweet as a sequence of 280 characters\n",
        "out of an alphabet of 128 unique characters. In this setting, each character can\n",
        "be encoded as a binary vector of size 128 (an all-zeros vector except for a 1 entry\n",
        "at the index corresponding to the character). Then each tweet can be encoded\n",
        "as a 2D tensor of shape (280, 128), and a dataset of 1 million tweets can be\n",
        "stored in a tensor of shape (1000000, 280, 128). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXiHlCyfbhjt"
      },
      "source": [
        "### **Image data**\n",
        "\n",
        "Images typically have three dimensions: height, width, and color depth. Although grayscale images (like our MNIST digits) have only a single color channel and could\n",
        "thus be stored in 2D tensors, by convention image tensors are always 3D, with a onedimensional color channel for grayscale images. A batch of 128 grayscale images of\n",
        "size 256 × 256 could thus be stored in a tensor of shape (128, 256, 256, 1), and a batch of 128 color images could be stored in a tensor of shape (128, 256, 256, 3)\n",
        "(see figure 2.4).\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=117bgbjE5fzcERGWuAsXjzUaOa_u-WiWh\"></img>\n",
        "\n",
        "\n",
        "\n",
        "There are two conventions for shapes of images tensors: the channels-last convention\n",
        "(used by TensorFlow) and the channels-first convention (used by Theano). The TensorFlow machine-learning framework, from Google, places the color-depth axis at the\n",
        "end: (samples, height, width, color_depth). Meanwhile, Theano places the color\n",
        "depth axis right after the batch axis: (samples, color_depth, height, width). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92ShPzsb07Jo"
      },
      "source": [
        "### **Video data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi_ZALUE1OLY"
      },
      "source": [
        "Video data is one of the few types of real-world data for which you’ll need **5D tensors**.\n",
        "A video can be understood as a sequence of frames, each frame being a color image.\n",
        "Because each frame can be stored in a 3D tensor (height, width, color_depth), a\n",
        "sequence of frames can be stored in a 4D tensor (frames, height, width, color_\n",
        "depth), and thus a batch of different videos can be stored in a 5D tensor of shape\n",
        "(samples, frames, height, width, color_depth).\n",
        "\n",
        "\n",
        " For instance, a 60-second, 144 × 256 YouTube video clip sampled at 4 frames per\n",
        "second would have 240 frames. A batch of four such video clips would be stored in a\n",
        "tensor of shape (4, 240, 144, 256, 3). That’s a total of 106,168,320 values! If the\n",
        "dtype of the tensor was float32, then each value would be stored in 32 bits, so the\n",
        "tensor would represent 405 MB. Heavy! Videos you encounter in real life are much\n",
        "lighter, because they aren’t stored in float32, and they’re typically compressed by a\n",
        "large factor (such as in the MPEG format). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC2lcJgq1kNi"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Tensor operations**</font>\n",
        "***\n",
        "\n",
        "The gears of neural networks: ***tensor operations***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDFVdxdk1wpC"
      },
      "source": [
        "Much as any computer program can be ultimately reduced to a small set of binary\n",
        "operations on binary inputs (AND, OR, NOR, and so on), all transformations learned\n",
        "by deep neural networks can be reduced to a handful of **tensor operations** applied to\n",
        "tensors of numeric data. For instance, it’s possible to add tensors, multiply tensors,\n",
        "and so on.\n",
        "\n",
        "In our initial example, we were building our network by stacking Dense layers on\n",
        "top of each other. A Keras layer instance looks like this:\n",
        "\n",
        "`keras.layers.Dense(512, activation='relu')`\n",
        "\n",
        "This layer can be interpreted as a function, which takes as input a 2D tensor and\n",
        "returns another 2D tensor—a new representation for the input tensor. Specifically, the\n",
        "function is as follows (where W is a 2D tensor and b is a vector, both attributes of the\n",
        "layer):\n",
        "\n",
        "`output = relu(dot(W, input) + b)`\n",
        "\n",
        "Let’s unpack this. We have three tensor operations here: a dot product (dot) between\n",
        "the input tensor and a tensor named W; an addition (+) between the resulting 2D tensor and a vector b; and, finally, a relu operation. relu(x) is max(x, 0)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgfO0L0n2I-m"
      },
      "source": [
        "### **Element-wise operations**\n",
        "\n",
        "Operations that are\n",
        "applied independently to each entry in the tensors being considered. This means\n",
        "these operations are highly amenable to massively parallel implementations (*vectorized*\n",
        "implementations, a term that comes from the *vector processor* supercomputer architecture from the 1970–1990 period).\n",
        "\n",
        "- relu\n",
        "- addition (+)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRiwWteM3GVp"
      },
      "source": [
        "### **Broadcasting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYsw9Wt83MFL"
      },
      "source": [
        "In the Dense layer introduced earlier, we added a 2D\n",
        "tensor with a vector. What happens with addition when the shapes of the two tensors\n",
        "being added differ?\n",
        " When possible, and if there’s no ambiguity, the smaller tensor will be broadcasted to\n",
        "match the shape of the larger tensor. Broadcasting consists of two steps:\n",
        "1. Axes (called *broadcast axes*) are added to the smaller tensor to match the ndim of\n",
        "the larger tensor.\n",
        "2. The smaller tensor is repeated alongside these new axes to match the full shape\n",
        "of the larger tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-p7S5aX7maY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTtYy44o3kb_"
      },
      "source": [
        "Let’s look at a concrete example. Consider X with shape (32, 10) and y with shape\n",
        "(10,). First, we add an empty first axis to y, whose shape becomes (1, 10). Then, we\n",
        "repeat y 32 times alongside this new axis, so that we end up with a tensor Y with shape\n",
        "(32, 10), where Y[i, :] == y for i in range(0, 32). At this point, we can proceed to\n",
        "add X and Y, because they have the same shape.\n",
        "\n",
        " In terms of implementation, no new 2D tensor is created, because that would be\n",
        "terribly inefficient. The repetition operation is entirely virtual: it happens at the algorithmic level rather than at the memory level. But thinking of the vector being repeated 10 times alongside a new axis is a helpful mental model.\n",
        "\n",
        "With broadcasting, you can generally apply two-tensor element-wise operations if one\n",
        "tensor has shape (a, b, … n, n + 1, … m) and the other has shape (n, n + 1, … m). The\n",
        "broadcasting will then automatically happen for axes a through n - 1.\n",
        " The following example applies the **element-wise maximum operation** to two tensors\n",
        "of different shapes via broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFAMBPpZXAT2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.random.random((64, 3, 32, 10)) # x is a random tensor with shape (64, 3, 32, 10)\n",
        "y = np.random.random((32, 10)) # y is a random tensor with shape (32, 10)\n",
        "\n",
        "z = np.maximum(x, y) # The output z has shape (64, 3, 32, 10) like x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QimXazx8G37"
      },
      "source": [
        "### **Tensor dot**\n",
        "\n",
        "The dot operation, also called a **tensor product** (not to be confused with an elementwise product) is the most common, most useful tensor operation. Contrary to\n",
        "element-wise operations, it combines entries in the input tensors.\n",
        " An element-wise product is done with the * operator in Numpy, Keras, Theano,\n",
        "and TensorFlow. dot uses a different syntax in TensorFlow, but in both Numpy and\n",
        "Keras it’s done using the standard dot operator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn_rkxc4XHVV"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# z = np.dot(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95IODsh08Vh3"
      },
      "source": [
        "In mathematical notation, you’d note the operation with a dot (.):\n",
        "\n",
        "$z=x.y$\n",
        "\n",
        "You’ll have noticed that the dot product between two vectors is a scalar and that only\n",
        "vectors with the same number of elements are compatible for a dot product.\n",
        "\n",
        " You can also take the dot product between a matrix x and a vector y, which returns\n",
        "a vector where the coefficients are the dot products between y and the rows of x.<br><br>\n",
        "\n",
        "\n",
        "Note that as soon as one of the **two tensors has an ndim greater than 1**, dot is no longer symmetric, which is to say that dot(x, y) isn’t the same as dot(y, x).\n",
        "\n",
        "\n",
        " Of course, a dot product generalizes to tensors with an arbitrary number of axes.\n",
        "The most common applications may be the dot product between two matrices. You\n",
        "can take the dot product of two matrices x and y (dot(x, y)) if and only if\n",
        "x.shape[1] == y.shape[0]. The result is a matrix with shape (x.shape[0],\n",
        "y.shape[1]), where the coefficients are the vector products between the rows of x\n",
        "and the columns of y.<br><br>\n",
        "\n",
        " More generally, you can take the dot product between higher-dimensional tensors,\n",
        "following the same rules for shape compatibility as outlined earlier for the 2D case:\n",
        "(a, b, c, d) . (d,) -> (a, b, c)<br>\n",
        "(a, b, c, d) . (d, e) -> (a, b, c, e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAy8xVlt-fed"
      },
      "source": [
        "### **Tensor reshaping**\n",
        "\n",
        "Reshaping a tensor means rearranging its rows and columns to match a target shape.\n",
        "Naturally, the reshaped tensor has the same total number of coefficients as the initial\n",
        "tensor. Reshaping is best understood via simple examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s9IkPJ--sJa",
        "outputId": "e59971e3-ecef-4337-cf12-9021d63f46e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = np.array([[0., 1.],\n",
        "              [2., 3.],\n",
        "              [4., 5.]])\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqyZnmf4-3eI"
      },
      "source": [
        "x = x.reshape((6, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYFgt-i8-5xk",
        "outputId": "28924953-4dd5-4381-e515-f3a869b1f3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [4.],\n",
              "       [5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Va6cZo_Tg2",
        "outputId": "4af269ad-7462-47d5-b5f1-0975bec7b33e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = x.reshape((2, 3))\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 2.]\n",
            " [3. 4. 5.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFKYOjcO-_Yj"
      },
      "source": [
        "A special case of reshaping that’s commonly encountered is **transposition**. Transposing a\n",
        "matrix means exchanging its rows and its columns, so that x[i, :] becomes x[:, i]:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyU_TrjdphUQ"
      },
      "source": [
        "## **Momentum**\n",
        "\n",
        "In particular, the concept of momentum, which is used in\n",
        "many of these variants, deserves your attention. Momentum addresses two issues with *SGD*: **convergence speed** and **local minima**. Consider figure 2.13, which shows the curve of a loss as a function of a network parameter.\n",
        "\n",
        "As you can see, around a certain parameter value, there is a local minimum: around\n",
        "that point, moving left would result in the loss increasing, but so would moving right.\n",
        "If the parameter under consideration were being optimized via SGD with a small\n",
        "learning rate, then the optimization process would get stuck at the local minimum\n",
        "instead of making its way to the global minimum.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1PXOzSazkVEpMg0T5-TcWCn3IeEDSxvJ0\"></img>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLcCbdnGyp6W"
      },
      "source": [
        "As you can see, around a certain parameter value, there is a local minimum: around that point, moving left would result in the loss increasing, but so would moving right.\n",
        "If the parameter under consideration were being optimized via SGD with a small learning rate, then the optimization process would get stuck at the local minimum\n",
        "instead of making its way to the global minimum.\n",
        "\n",
        "You can avoid such issues by using momentum, which draws inspiration from physics. A useful mental image here is to think of the optimization process as a small ball\n",
        "rolling down the loss curve. If it has enough momentum, the ball won’t get stuck in a\n",
        "ravine and will end up at the global minimum. Momentum is implemented by moving\n",
        "the ball at each step based not only on the current slope value (current acceleration)\n",
        "but also on the current velocity (resulting from past acceleration). In practice, this\n",
        "means updating the parameter w based not only on the current gradient value but also\n",
        "on the previous parameter update, such as in this naive implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahay7L87zKJD"
      },
      "source": [
        "# past_velocity = 0.\n",
        "# momentum = 0.1 # constant momentum factor\n",
        "# while loss > 0.01: # optimization loop\n",
        "#   w, loss, gradient = get_current_parameters()\n",
        "#   velocity = past_velocity * momentum + learning_rate * gradient\n",
        "#   w=w+ momentum * velocity - learning_rate * gradient\n",
        "#   past_velocity = velocity\n",
        "#   update_parameter(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpwHuz9wzGow"
      },
      "source": [
        "# <font color=\"Orange\">**Neural Networks with Keras Fundamentals**</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc1ZtMyokw86"
      },
      "source": [
        "Some fundamental ideas of Neural Networks:\n",
        "- **Learning** means finding a combination of model parameters that minimizes a loss function for a given set of training data samples and their corresponding targets.\n",
        "- Learning happens by drawing random batches of data samples and their\n",
        "targets, and computing the gradient of the network parameters with\n",
        "respect to the loss on the batch. The network parameters are then moved\n",
        "a bit (the magnitude of the move is defined by the learning rate) in the\n",
        "opposite direction from the gradient.\n",
        "- The entire learning process is made possible by the fact that neural networks are chains of differentiable tensor operations, and thus it’s possible\n",
        "to apply the chain rule of derivation to find the gradient function mapping the current parameters and current batch of data to a gradient value.\n",
        "- Two key concepts you’ll see frequently in future chapters are **loss** and **optimizers**. These are the two things you need to define before you begin feeding data into a network.\n",
        "- The **loss** is the quantity you’ll attempt to minimize during training, so it\n",
        "should represent a measure of success for the task you’re trying to solve.\n",
        "- The **optimizer** specifies the exact way in which the gradient of the loss will\n",
        "be used to update parameters: for instance, it could be the RMSProp optimizer, SGD with momentum, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQrOO4eyz5r3"
      },
      "source": [
        "In this chapter, we will apply what you’ve learned to three new problems\n",
        "covering the three most common use cases of neural networks: \n",
        "- **binary classification** (Classifying movie reviews as positive or negative)\n",
        "- **multiclass classification** (Classifying news wires by topic) \n",
        "- **scalar regression** (Estimating the price of a house, given real-estate data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajsD639_z51c"
      },
      "source": [
        "As you saw in the previous chapters, training a neural network revolves around the following objects:\n",
        "* **Layers**, which are combined into a **network** (or **model**)\n",
        "* The **input data** and corresponding **targets**\n",
        "* The **loss function**, which defines the feedback signal used for learning\n",
        "* The **optimizer**, which determines how learning proceeds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt_bT8rsz57i"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1iY3ZV5UcAH0qu5Jv8OYs7y6TYBdjuiUc\"></img>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6wbUZCz5-F"
      },
      "source": [
        "Let’s take a closer look at layers, networks, loss functions, and optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf9G6G68Dj9X"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Layers**</font>\n",
        "***\n",
        "The fundamental data structure in neural networks is the **layer**, to which you were\n",
        "introduced in chapter 2. A layer is a data-processing module that takes as input one or\n",
        "more tensors and that outputs one or more tensors. Some layers are stateless, but\n",
        "more frequently layers have a state: the layer’s **weights**, one or several tensors learned\n",
        "with stochastic gradient descent, which together contain the network’s **knowledge**.\n",
        "\n",
        "\n",
        " Different layers are appropriate for different tensor formats and different types of data\n",
        "processing. For instance, simple vector data, stored in 2D tensors of shape (samples,\n",
        "features), is often processed by **densely connected** layers, also called **fully connected** or **dense\n",
        "layers** (the Dense class in Keras). Sequence data, stored in 3D tensors of shape (samples,\n",
        "timesteps, features), is typically processed by **recurrent** layers such as an **LSTM** layer.\n",
        "Image data, stored in 4D tensors, is usually processed by 2D **convolution** layers (Conv2D).\n",
        "\n",
        "You can think of layers as the LEGO bricks of deep learning, a metaphor that is\n",
        "made explicit by frameworks like Keras. Building deep-learning models in Keras is\n",
        "done by clipping together compatible layers to form useful *data-transformation pipelines*. The notion of **layer compatibility** here refers specifically to the fact that every layer\n",
        "will only accept input tensors of a certain shape and will return output tensors of a certain shape. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJCHMJ1qqJEZ"
      },
      "source": [
        "from keras import layers\n",
        "\n",
        "layer = layers.Dense(32, input_shape=(784,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx0_9cEODjPo"
      },
      "source": [
        "We’re creating a layer that will only accept as input 2D tensors where the first dimension is 784 (axis 0, the batch dimension, is unspecified, and thus any value would be\n",
        "accepted). This layer will return a tensor where the first dimension has been transformed to be 32.\n",
        "\n",
        "Thus this layer can only be connected to a downstream layer that expects 32-\n",
        "dimensional vectors as its input. When using Keras, you don’t have to worry about\n",
        "compatibility, because the layers you add to your models are dynamically built to\n",
        "match the shape of the incoming layer. For instance, suppose you write the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyexnLv-FhZF"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, input_shape=(784,)))\n",
        "model.add(layers.Dense(32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocJow-mPIHSS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNonnII6IPGY"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Models: networks of layers**</font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qg6oW3DIkfT"
      },
      "source": [
        "A deep-learning model is a directed, acyclic graph of layers. The most common\n",
        "instance is a linear stack of layers, mapping a single input to a single output.\n",
        " But as you move forward, you’ll be exposed to a much broader variety of network\n",
        "topologies. Some common ones include the following:\n",
        "* Two-branch networks\n",
        "* Multihead networks\n",
        "* Inception blocks\n",
        "\n",
        "\n",
        "The topology of a network defines a **hypothesis space**. You may remember that in chapter 1, we defined machine learning as “searching for useful representations of some\n",
        "input data, within a predefined space of possibilities, using guidance from a feedback\n",
        "signal.” By choosing a network topology, you constrain your **space of possibilities**\n",
        "(hypothesis space) to a specific series of tensor operations, mapping input data to output data. What you’ll then be searching for is a good set of values for the weight tensors involved in these tensor operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLJz1xriLi-6"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Loss functions and optimizers: keys to configuring the learning process**</font>\n",
        "***\n",
        "Once the network architecture is defined, you still have to choose two more things:\n",
        "* Loss function (objective function)—The quantity that will be minimized during\n",
        "training. It represents a measure of success for the task at hand.\n",
        "* Optimizer—Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).\n",
        "\n",
        "\n",
        "A neural network that has multiple outputs may have multiple loss functions (one per\n",
        "output). But the gradient-descent process must be based on a single scalar loss value;\n",
        "so, for multiloss networks, all losses are combined (via averaging) into a single scalar\n",
        "quantity.\n",
        "\n",
        "\n",
        " Choosing the right objective function for the right problem is extremely important: your network will take any shortcut it can, to minimize the loss; so if the objective\n",
        "doesn’t fully correlate with success for the task at hand, your network will end up\n",
        "doing things you may not have wanted. Imagine a stupid, omnipotent AI trained via\n",
        "SGD, with this poorly chosen objective function: “maximizing the average well-being\n",
        "of all humans alive.” To make its job easier, this AI might choose to kill all humans\n",
        "except a few and focus on the well-being of the remaining ones—because average\n",
        "well-being isn’t affected by how many humans are left. That might not be what you\n",
        "intended! Just remember that all neural networks you build will be just as ruthless in\n",
        "lowering their loss function—so choose the objective wisely, or you’ll have to face\n",
        "unintended side effects\n",
        "\n",
        "You'll use **binary crossentropy** for a two-class classification\n",
        "problem, **categorical crossentropy** for a many-class classification problem, **meansquared error** for a regression problem, **connectionist temporal classification** (CTC)\n",
        "for a sequence-learning problem, and so on. Only when you’re working on truly new\n",
        "research problems will you have to develop your own objective functions. In the next\n",
        "few chapters, we’ll detail explicitly which loss functions to choose for a wide range of\n",
        "common tasks. \n",
        "\n",
        "* **binary crossentropy/log loss** (two-class classification)\n",
        "* **categorical crossentropy** (many-class classification)\n",
        "* **meansquared error** (for a regression problem)\n",
        "* **connectionist temporal classification** (sequence-learning problem).\n",
        "\n",
        "\n",
        "**Crossentropy** is a quantity from the field of Information Theory that measures the distance between probability distributions or, in this case, between the ground-truth distribution and your predictions.\n",
        "\n",
        "**Categorical crossentropy**, expects the labels to follow\n",
        "a categorical encoding. With integer labels, you should use sparse_categorical_\n",
        "crossentropy.\n",
        "\n",
        "**Categorical crossentropy** minimizes the distance between the probability distributions\n",
        "output by the network and the true distribution of the targets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yG3IPyfPy5H"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Typical Keras workflow**</font>\n",
        "***\n",
        "Typical Keras workflow:\n",
        "1. Define your training data: input tensors and target tensors.\n",
        "2.  Define a network of layers (or **model**) that maps your inputs to your targets.\n",
        "\n",
        "3. Configure the learning process by choosing a loss function, an optimizer, and\n",
        "some metrics to monitor.\n",
        "4.  Iterate on your training data by calling the **fit()** method of your model.\n",
        "\n",
        "\n",
        "\n",
        "There are two ways to define a model: using the **Sequential** class (only for linear\n",
        "stacks of layers, which is the most common network architecture by far) or the **functional API** (for directed acyclic graphs of layers, which lets you build completely arbitrary architectures)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFmyFqTwIR5T"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRLdAkgmRWpx"
      },
      "source": [
        "And here’s the same model defined using the functional API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8kNAztcRT3e"
      },
      "source": [
        "input_tensor = layers.Input(shape=(784,))\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs=input_tensor, outputs=output_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku44HwaVQZje"
      },
      "source": [
        "With the functional API, you’re manipulating the data tensors that the model processes and applying layers to this tensor as if they were functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m14JwyFPLiPA"
      },
      "source": [
        "The **learning process is configured in the compilation step**, where you specify the\n",
        "optimizer and loss function(s) that the model should use, as well as the metrics you\n",
        "want to monitor during training. Here’s an example with a single loss function, which\n",
        "is by far the most common case:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsiuxkBFSRQ_"
      },
      "source": [
        "from keras import optimizers\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-u-AyWwS10r"
      },
      "source": [
        "Finally, the learning process consists of passing Numpy arrays of input data (and the\n",
        "corresponding target data) to the model via the **fit()** method, similar to what you\n",
        "would do in *Scikit-Learn* and several other machine-learning libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM3fCjXQSX1j"
      },
      "source": [
        "model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NwGDxQZS7ZP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1gkLtfFUkGB"
      },
      "source": [
        "## <font color=\"Tomato\">**Classifying movie reviews: a binary classification example**</font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zxugwHCU1r-"
      },
      "source": [
        "In this example, you’ll learn to classify movie reviews using the **IMDB Dataset**\n",
        "into positive or negative, based on the text content of the reviews.\n",
        "\n",
        "Just like the MNIST dataset, the **IMDB dataset** comes packaged with Keras. It has\n",
        "already been preprocessed: the reviews (sequences of words) have been turned into\n",
        "*sequences of integers*, where **each integer stands for a specific word in a dictionary**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqpGwU9UUl-C"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoRG9oXHV5dX"
      },
      "source": [
        "The argument num_words=10000 means you’ll only keep the top 10,000 most frequently occurring words in the training data. Rare words will be discarded. This allows\n",
        "you to work with vector data of manageable size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQgVdg90Vpa9",
        "outputId": "11cb1f58-33fa-4d52-b98a-cc2dad40da7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data[9]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 20,\n",
              " 47,\n",
              " 111,\n",
              " 439,\n",
              " 3445,\n",
              " 19,\n",
              " 12,\n",
              " 15,\n",
              " 166,\n",
              " 12,\n",
              " 216,\n",
              " 125,\n",
              " 40,\n",
              " 6,\n",
              " 364,\n",
              " 352,\n",
              " 707,\n",
              " 1187,\n",
              " 39,\n",
              " 294,\n",
              " 11,\n",
              " 22,\n",
              " 396,\n",
              " 13,\n",
              " 28,\n",
              " 8,\n",
              " 202,\n",
              " 12,\n",
              " 1109,\n",
              " 23,\n",
              " 94,\n",
              " 2,\n",
              " 151,\n",
              " 111,\n",
              " 211,\n",
              " 469,\n",
              " 4,\n",
              " 20,\n",
              " 13,\n",
              " 258,\n",
              " 546,\n",
              " 1104,\n",
              " 7273,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 78,\n",
              " 33,\n",
              " 211,\n",
              " 15,\n",
              " 12,\n",
              " 16,\n",
              " 2849,\n",
              " 63,\n",
              " 93,\n",
              " 12,\n",
              " 6,\n",
              " 253,\n",
              " 106,\n",
              " 10,\n",
              " 10,\n",
              " 48,\n",
              " 335,\n",
              " 267,\n",
              " 18,\n",
              " 6,\n",
              " 364,\n",
              " 1242,\n",
              " 1179,\n",
              " 20,\n",
              " 19,\n",
              " 6,\n",
              " 1009,\n",
              " 7,\n",
              " 1987,\n",
              " 189,\n",
              " 5,\n",
              " 6,\n",
              " 8419,\n",
              " 7,\n",
              " 2723,\n",
              " 2,\n",
              " 95,\n",
              " 1719,\n",
              " 6,\n",
              " 6035,\n",
              " 7,\n",
              " 3912,\n",
              " 7144,\n",
              " 49,\n",
              " 369,\n",
              " 120,\n",
              " 5,\n",
              " 28,\n",
              " 49,\n",
              " 253,\n",
              " 10,\n",
              " 10,\n",
              " 13,\n",
              " 1041,\n",
              " 19,\n",
              " 85,\n",
              " 795,\n",
              " 15,\n",
              " 4,\n",
              " 481,\n",
              " 9,\n",
              " 55,\n",
              " 78,\n",
              " 807,\n",
              " 9,\n",
              " 375,\n",
              " 8,\n",
              " 1167,\n",
              " 8,\n",
              " 794,\n",
              " 76,\n",
              " 7,\n",
              " 4,\n",
              " 58,\n",
              " 5,\n",
              " 4,\n",
              " 816,\n",
              " 9,\n",
              " 243,\n",
              " 7,\n",
              " 43,\n",
              " 50]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFz-W8-NW9n8"
      },
      "source": [
        "Here’s how you can quickly decode one of these reviews back to English\n",
        "words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsMaeC-IWWHk",
        "outputId": "89f63f43-4fc7-45c1-99de-a5fccc40f39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "word_index = imdb.get_word_index() #  dictionary mapping words to an integer index\n",
        "\n",
        "reverse_word_index = dict( # Reverses it, mapping integer indices to words\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Decodes the review. Note that the indices are offset by 3 because 0, 1, and 2 are\n",
        "# reserved indices for “padding,” “start of sequence,” and “unknown.”\n",
        "decoded_review = ' '.join(\n",
        "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
        "\n",
        "print(decoded_review)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvjCNHhLaOmZ",
        "outputId": "04fb2ce0-68ef-446c-ca78-273684a35602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# max word index\n",
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfX12PM1ZNwR"
      },
      "source": [
        "\n",
        "### **Preparing the data**\n",
        "\n",
        "You can’t feed lists of integers into a neural network. You have to turn your lists into\n",
        "tensors. There are two ways to do that:\n",
        "* Pad your lists so that they all have the same length, turn them into an integer\n",
        "tensor of shape *(samples, word_indices)*, and then use as the first layer in\n",
        "your network a layer capable of handling such integer tensors (the **Embedding**\n",
        "layer, which we’ll cover in detail later in the book).\n",
        "* One-hot encode your lists to turn them into vectors of 0s and 1s. This would\n",
        "mean, for instance, turning the sequence [3, 5] into a 10,000-dimensional vector that would be all 0s except for indices 3 and 5, which would be 1s. Then you\n",
        "could use as the first layer in your network a Dense layer, capable of handling\n",
        "floating-point vector data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHjitfPXXCWZ"
      },
      "source": [
        "# Encoding the integer sequences into a binary matrix\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3XJaFDubl3q",
        "outputId": "79382208-9509-4e0e-9c00-bd3ef60da132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ram7yOk1cBmO"
      },
      "source": [
        "# vectorize labels\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC0firQZcISd",
        "outputId": "349b658b-934a-4ff2-b46a-e9e8fe5d50f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-cfAClecRTT"
      },
      "source": [
        "### **Building your network**\n",
        "\n",
        "\n",
        "\n",
        "The input data is vectors, and the labels are scalars (1s and 0s): this is the easiest setup\n",
        "you’ll ever encounter. A type of network that performs well on such a problem is\n",
        "a simple stack of fully connected (Dense) layers with relu activations: Dense(16,\n",
        "activation='relu').\n",
        "\n",
        "The argument being passed to each Dense layer (16) is the number of hidden\n",
        "units of the layer. A **hidden unit** is a dimension in the representation space of the layer. You may remember from chapter 2 that each such Dense layer with a relu activation\n",
        "implements the following chain of tensor operations:\n",
        "\n",
        "$output = relu(dot(W, input) + b)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sq_AvM1c3yi"
      },
      "source": [
        "Having 16 hidden units means the weight matrix W will have shape (input_dimension,\n",
        "16): **the dot product with W will project the input data onto a 16-dimensional representation space** (and then you’ll add the bias vector b and apply the relu operation). You\n",
        "can intuitively understand the dimensionality of your representation space as “how\n",
        "much freedom you’re allowing the network to have when learning internal representations.” Having more hidden units (a higher-dimensional representation space)\n",
        "allows your network to learn more-complex representations, but it makes the network\n",
        "more computationally expensive and may lead to learning unwanted patterns (patterns that will improve performance on the training data but not on the test data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOWccJ9JeMTv"
      },
      "source": [
        "A **relu** (rectified linear unit) is a function meant to zero out negative values\n",
        "(see figure 3.4), whereas a sigmoid “squashes” arbitrary values into the [0, 1] interval\n",
        "(see figure 3.5), outputting something that can be interpreted as a probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLUK1muCeXPV"
      },
      "source": [
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1St5aIduDDPOxDIQiIaYXvWiOwNeJGwcH\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JfdM5wqc4ZR"
      },
      "source": [
        "# Model definition\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcOhjjyReqJD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPCNUbIafA3z"
      },
      "source": [
        "### What are activation functions, and why are they necessary?\n",
        "\n",
        "Without an activation function like **relu** (also called a non-linearity), the Dense layer\n",
        "would consist of two linear operations—a dot product and an addition:\n",
        "\n",
        "$output = dot(W, input) + b$\n",
        "\n",
        "So the layer could only learn linear transformations (affine transformations) of the\n",
        "input data: the **hypothesis space** of the layer would be the set of all possible linear\n",
        "transformations of the input data into a 16-dimensional space. Such a hypothesis\n",
        "space is too restricted and wouldn’t benefit from multiple layers of representations,\n",
        "because a deep stack of linear layers would still implement a linear operation: adding\n",
        "more layers wouldn’t extend the hypothesis space.\n",
        "\n",
        "\n",
        "In order to get access to a much richer hypothesis space that would benefit from\n",
        "deep representations, you need a non-linearity, or activation function. **relu** is the\n",
        "most popular activation function in deep learning, but there are many other candidates, which all come with similarly strange names: **prelu**, **elu**, and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3PEqoD1fC1K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp__IMYOfiiu"
      },
      "source": [
        "Best to use **binary_crossentropy** loss. It isn’t the only viable choice: you could use, for instance,\n",
        "**mean_squared_error**. But crossentropy is usually the best choice when you’re dealing\n",
        "with models that output probabilities. \n",
        "\n",
        "**Crossentropy** is a quantity from the field of Information Theory that measures the distance between probability distributions or, in this\n",
        "case, between the ground-truth distribution and your predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE88KSl5fmxi"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzmOo6rxgM-T"
      },
      "source": [
        "You’re passing your optimizer, loss function, and metrics as strings, which is possible\n",
        "because **rmsprop**, **binary_crossentropy**, and **accuracy** are packaged as part of Keras.\n",
        "Sometimes you may want to configure the parameters of your optimizer or pass a custom loss function or metric function. The former can be done by passing an **optimizer**\n",
        "class instance as the optimizer argument, as shown in listing 3.5; the latter can be\n",
        "done by passing function objects as the loss and/or metrics arguments, as shown:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjoGpFscf--C"
      },
      "source": [
        "# Configuring the optimizer\n",
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43XbyCupgYHN"
      },
      "source": [
        "# Using custom losses and metrics\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKG2j_H3gvEx"
      },
      "source": [
        "### **Training and validating**\n",
        "\n",
        "Set aside a validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lEk3P_Qge0B"
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkXM90RGg02u",
        "outputId": "a76e778e-8a44-4945-b899-912702cc598b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_val.shape)\n",
        "print(partial_x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10000)\n",
            "(15000, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRyVIlHghSEs"
      },
      "source": [
        "You’ll now train the model for 20 epochs (20 iterations over all samples in the\n",
        "**x_train** and **y_train** tensors), in mini-batches of 512 samples. At the same time,\n",
        "you’ll monitor loss and accuracy on the 10,000 samples that you set apart. You do so by\n",
        "passing the validation data as the validation_data argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edzd_EiRhBp9",
        "outputId": "c45823a1-139e-4c4a-ad2c-eb84aca22e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# Training your model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.5276 - acc: 0.7897 - val_loss: 0.4122 - val_acc: 0.8523\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.3210 - acc: 0.9023 - val_loss: 0.3331 - val_acc: 0.8683\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2340 - acc: 0.9231 - val_loss: 0.2861 - val_acc: 0.8867\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.1823 - acc: 0.9413 - val_loss: 0.2774 - val_acc: 0.8901\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.1510 - acc: 0.9514 - val_loss: 0.2764 - val_acc: 0.8892\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.1220 - acc: 0.9635 - val_loss: 0.2937 - val_acc: 0.8859\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.1038 - acc: 0.9693 - val_loss: 0.3039 - val_acc: 0.8832\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0879 - acc: 0.9744 - val_loss: 0.3415 - val_acc: 0.8803\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0700 - acc: 0.9812 - val_loss: 0.3420 - val_acc: 0.8771\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0604 - acc: 0.9835 - val_loss: 0.3721 - val_acc: 0.8760\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0467 - acc: 0.9890 - val_loss: 0.3984 - val_acc: 0.8732\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0389 - acc: 0.9923 - val_loss: 0.4206 - val_acc: 0.8751\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0310 - acc: 0.9944 - val_loss: 0.4573 - val_acc: 0.8748\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0252 - acc: 0.9952 - val_loss: 0.5037 - val_acc: 0.8664\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0225 - acc: 0.9949 - val_loss: 0.5174 - val_acc: 0.8703\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0128 - acc: 0.9991 - val_loss: 0.5534 - val_acc: 0.8695\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0124 - acc: 0.9987 - val_loss: 0.5894 - val_acc: 0.8675\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0102 - acc: 0.9987 - val_loss: 0.6258 - val_acc: 0.8668\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.0064 - acc: 0.9997 - val_loss: 0.6885 - val_acc: 0.8629\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.0075 - acc: 0.9985 - val_loss: 0.7017 - val_acc: 0.8636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z6xtx8Dh3ZY"
      },
      "source": [
        "On CPU, this will take less than 2 seconds per epoch—training is over in 20 seconds.\n",
        "At the end of every epoch, there is a slight pause as the model computes its loss and\n",
        "accuracy on the 10,000 samples of the validation data.\n",
        "\n",
        "\n",
        "Note that the call to model.fit() returns a **History object**. This object has a member history, which is a dictionary containing data about everything that happened\n",
        "during training. Let’s look at it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4DOoBf4hwn_",
        "outputId": "2b15b982-9281-4e73-cf20-7a51d84ecdd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxL0fd8liM_4"
      },
      "source": [
        "The dictionary contains four entries: one per metric that was being monitored during\n",
        "training and during validation. In the following two listing, let’s use Matplotlib to plot\n",
        "the training and validation loss side by side (see figure 3.7), as well as the training and\n",
        "validation accuracy (see figure 3.8). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqANgw2_iRSO"
      },
      "source": [
        "### **Visualizing metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTtQtx1iiIuV",
        "outputId": "4ca16f49-1a3c-4074-dc2c-6e533248d632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plotting training and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss') # bo is blue dot\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss') # b is solid blue line\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqa1Y9xCi3mW",
        "outputId": "996284a7-390d-47b0-e500-14a7efb76870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plotting training and validation accuracy\n",
        "\n",
        "plt.clf() # clears figure\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja6mFKEtj7eu"
      },
      "source": [
        "This is an example of what we warned against earlier: a\n",
        "model that performs better on the training data isn’t necessarily a model that will do\n",
        "better on data it has never seen before. In precise terms, what you’re seeing is **overfitting**: after the second epoch, **you’re overoptimizing on the training data, and you end\n",
        "up learning representations that are specific to the training data and don’t generalize\n",
        "to data outside of the training set**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH1q2uVRjrua",
        "outputId": "97e3251a-9590-4b04-eda0-c786c8d074b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# Retraining from scratch\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=512)\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b04c83efae0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AAo998Nkd7Y",
        "outputId": "4d5c2a91-826e-438c-cb2e-d5088abbbf75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# returns loss and accuracy on x_test\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5935375094413757, 0.8646799921989441]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDA4byRck2cI"
      },
      "source": [
        "### **Using a trained network to generate predictions on new data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUjo0grzkfXX",
        "outputId": "45760b26-05ce-470f-ff31-36e30e2b32ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17760067],\n",
              "       [0.9999198 ],\n",
              "       [0.9157734 ],\n",
              "       ...,\n",
              "       [0.16096908],\n",
              "       [0.1118544 ],\n",
              "       [0.72514415]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biIptVY-k7x0"
      },
      "source": [
        "### Future experiments\n",
        "\n",
        "* You used two hidden layers. Try using one or three hidden layers, and see how\n",
        "doing so affects validation and test accuracy.\n",
        "* Try using layers with more hidden units or fewer hidden units: 32 units, 64 units,\n",
        "and so on.\n",
        "* Try using the **mse** loss function instead of **binary_crossentropy**.\n",
        "* Try using the **tanh activation** (an activation that was popular in the early days of\n",
        "neural networks) instead of **relu**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mbBh7x-mK_t"
      },
      "source": [
        "### **Wrapping up**\n",
        "Here’s what you should take away from this example:\n",
        "\n",
        "* You usually need to do quite a bit of preprocessing on your raw data in order to\n",
        "be able to feed it—as tensors—into a neural network. Sequences of words can\n",
        "be encoded as **binary vectors**, but there are other encoding options, too.\n",
        "* Stacks of **Dense** layers with **relu** activations can solve a wide range of problems\n",
        "(including sentiment classification), and you’ll likely use them frequently.\n",
        "* In a binary classification problem (two output classes), your network should\n",
        "end with a **Dense** layer with one unit and a **sigmoid** activation: the output of\n",
        "your network should be a scalar between 0 and 1, encoding a probability.\n",
        "* With such a scalar sigmoid output on a binary classification problem, the loss\n",
        "function you should use is **binary_crossentropy**.\n",
        "* The **rmsprop optimizer** is generally a good enough choice, whatever your problem. That’s one less thing for you to worry about.\n",
        "* As they get better on their training data, neural networks eventually start overfitting and end up obtaining increasingly worse results on data they’ve never\n",
        "seen before. Be sure to always monitor performance on data that is outside of\n",
        "the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wch54HUDmjpO"
      },
      "source": [
        "## <font color=\"Tomato\">**Classifying newswires: a multiclass classification example**<font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKp3ZWgTmogy"
      },
      "source": [
        "In the previous section, you saw how to classify vector inputs into two mutually exclusive classes using a densely connected neural network. But what happens when you\n",
        "have more than two classes?\n",
        "\n",
        "In this section, you’ll build a network to **classify Reuters newswires into 46 mutually\n",
        "exclusive topics**. Because you have many classes, this problem is an instance of **multiclass classification**; and because each data point should be classified into only one category, the problem is more specifically an instance of **single-label**, **multiclass classification**.\n",
        "If each data point could belong to multiple categories (in this case, topics), you’d be\n",
        "facing a multilabel, multiclass classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvdA-ktym5ou"
      },
      "source": [
        "**The Reuters dataset**\n",
        "\n",
        "You’ll work with the *Reuters* dataset, a set of short newswires and their topics, published\n",
        "by Reuters in 1986. It’s a simple, widely used toy dataset for text classification. There\n",
        "are 46 different topics; some topics are more represented than others, but each topic\n",
        "has at least 10 examples in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7SNHgxuk4To"
      },
      "source": [
        "# Loading dataset\n",
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
        "    num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNRO84aynKrH"
      },
      "source": [
        "As with the IMDB dataset, the argument num_words=10000 restricts the data to the\n",
        "10,000 most frequently occurring words found in the data.\n",
        "\n",
        "You have 8,982 training examples and 2,246 test examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP3SwvxEnE2W",
        "outputId": "d652ba58-7c0b-4505-b99c-b4837fae7377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8982\n",
            "2246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2z4dg9Nnht6"
      },
      "source": [
        "As with the IMDB reviews, each example is a list of integers (**word indices**):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un3Ez8_HnHgD",
        "outputId": "153b9cc3-2c87-413c-8aac-86b742e665a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYt_5F4wnuwp"
      },
      "source": [
        "### **Prepare data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5x_2y1CnbPF"
      },
      "source": [
        "# Vectorize data\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data) # vectorized training data\n",
        "x_test = vectorize_sequences(test_data) # vectorized test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S3YnLZWrKvl",
        "outputId": "c3c38c3b-7296-425e-c412-b79276407ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_labels[0:6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3, 10,  1,  4,  4,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNbIu7KqqHKJ"
      },
      "source": [
        "To vectorize the labels, there are two possibilities: you can cast the label list as an integer tensor, or you can use one-hot encoding. **One-hot encoding** is a widely used format for ***categorical data***, also called categorical encoding. For a more detailed\n",
        "explanation of one-hot encoding, see section 6.1. In this case, one-hot encoding of\n",
        "the labels consists of embedding each label as an all-zero vector with a 1 in the place of\n",
        "the label index. Here’s an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW3SRgFEnznS"
      },
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels) # vectorized train labels\n",
        "one_hot_test_labels = to_one_hot(test_labels) # vectorized test labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1PEoifJq11V"
      },
      "source": [
        "Note that there is a built-in way to do this in Keras, which you’ve already seen in action\n",
        "in the MNIST example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_mKnTdMqvkj"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWZihRaMrz3q"
      },
      "source": [
        "### **Building your network**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpOzuIIdsDXP"
      },
      "source": [
        "This topic-classification problem looks similar to the previous movie-review classification problem: in both cases, you’re trying to classify short snippets of text. But there is\n",
        "a new constraint here: the number of output classes has gone from 2 to 46. The\n",
        "dimensionality of the output space is much larger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thvuhch1r05s"
      },
      "source": [
        "# Model definition\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_QjDjf4sxN0"
      },
      "source": [
        "The best loss function to use in this case is **categorical_crossentropy**. It measures\n",
        "the distance between two probability distributions: here, between the probability distribution output by the network and the true distribution of the labels. By minimizing\n",
        "the distance between these two distributions, you train the network to output something as close as possible to the true labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggou58qwszv9"
      },
      "source": [
        "# Compiling model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te89iJiRtGyx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB4qDYc8tUWk"
      },
      "source": [
        "### Validating your approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkgCYw60tVsv"
      },
      "source": [
        "# Set aside valid set\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t264AXQ9tYyW",
        "outputId": "73d13cf0-1fd9-4695-b364-26cdde7f2e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 2.5871 - accuracy: 0.5238 - val_loss: 1.7028 - val_accuracy: 0.6380\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1.4240 - accuracy: 0.7066 - val_loss: 1.3193 - val_accuracy: 0.7050\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1.0752 - accuracy: 0.7699 - val_loss: 1.1548 - val_accuracy: 0.7490\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.8576 - accuracy: 0.8153 - val_loss: 1.0545 - val_accuracy: 0.7670\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6897 - accuracy: 0.8493 - val_loss: 0.9813 - val_accuracy: 0.7920\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.5524 - accuracy: 0.8839 - val_loss: 0.9335 - val_accuracy: 0.8140\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.4479 - accuracy: 0.9055 - val_loss: 0.9316 - val_accuracy: 0.7980\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3617 - accuracy: 0.9243 - val_loss: 0.9085 - val_accuracy: 0.8060\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.2986 - accuracy: 0.9346 - val_loss: 0.9160 - val_accuracy: 0.8090\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2518 - accuracy: 0.9425 - val_loss: 0.9307 - val_accuracy: 0.8080\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2145 - accuracy: 0.9478 - val_loss: 0.9538 - val_accuracy: 0.8100\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1866 - accuracy: 0.9499 - val_loss: 0.9586 - val_accuracy: 0.8020\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1681 - accuracy: 0.9534 - val_loss: 1.0449 - val_accuracy: 0.7890\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1518 - accuracy: 0.9529 - val_loss: 0.9652 - val_accuracy: 0.8070\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1409 - accuracy: 0.9555 - val_loss: 0.9528 - val_accuracy: 0.8110\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1334 - accuracy: 0.9549 - val_loss: 0.9902 - val_accuracy: 0.8130\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1269 - accuracy: 0.9558 - val_loss: 1.0501 - val_accuracy: 0.8030\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1193 - accuracy: 0.9574 - val_loss: 1.0898 - val_accuracy: 0.7930\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1184 - accuracy: 0.9583 - val_loss: 1.0453 - val_accuracy: 0.8100\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1121 - accuracy: 0.9570 - val_loss: 1.0752 - val_accuracy: 0.7950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWtQpHcBt9HE"
      },
      "source": [
        "**Plot training and validation loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDWZy4THtfLI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# takes in history object and prints training and validation loss\n",
        "def plot_loss(history):\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24OxJ-5ouZsc",
        "outputId": "f11b8b28-04c0-4135-f0a5-0bba1e296ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxEMU_Mtu1Bm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CROTfn-4ucWC"
      },
      "source": [
        "def plot_accuracy(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSDj9Y09upct",
        "outputId": "99c5998c-b0bb-48ab-c049-465b1ff1dde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.clf()\n",
        "plot_accuracy(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84XeTnf8vcs4"
      },
      "source": [
        "The network begins to overfit after nine epochs. Let’s train a new network from\n",
        "scratch for nine epochs and then evaluate it on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBoL-L_7uqpJ",
        "outputId": "da234d57-dcca-4daa-998a-04ef254e499d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=9,\n",
        "          batch_size=512,\n",
        "          validation_data=(x_val, y_val))\n",
        "\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.5812 - accuracy: 0.5256 - val_loss: 1.6941 - val_accuracy: 0.6470\n",
            "Epoch 2/9\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1.3717 - accuracy: 0.7087 - val_loss: 1.2703 - val_accuracy: 0.7260\n",
            "Epoch 3/9\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1.0111 - accuracy: 0.7824 - val_loss: 1.1102 - val_accuracy: 0.7530\n",
            "Epoch 4/9\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.7965 - accuracy: 0.8316 - val_loss: 1.0334 - val_accuracy: 0.7780\n",
            "Epoch 5/9\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.6342 - accuracy: 0.8670 - val_loss: 0.9593 - val_accuracy: 0.7910\n",
            "Epoch 6/9\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.5110 - accuracy: 0.8898 - val_loss: 0.9315 - val_accuracy: 0.8050\n",
            "Epoch 7/9\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4141 - accuracy: 0.9136 - val_loss: 0.9721 - val_accuracy: 0.7820\n",
            "Epoch 8/9\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.3391 - accuracy: 0.9297 - val_loss: 0.9148 - val_accuracy: 0.8130\n",
            "Epoch 9/9\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2797 - accuracy: 0.9405 - val_loss: 0.8983 - val_accuracy: 0.8120\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 0.9863 - accuracy: 0.7863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jw9GoCJvocO",
        "outputId": "e4830102-a5da-4f8b-fb6e-8fa81ac76718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9862919449806213, 0.7862867116928101]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFVTxbxewrNt"
      },
      "source": [
        "**Make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6UEtkIKv1rG"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6Qhl_SWwvKw",
        "outputId": "12b89db1-c190-4731-ed86-76437c2d76b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a_H8XdcwwSw",
        "outputId": "0cda2a19-e69f-48da-f8bd-9d9e5462d649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.sum(predictions[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNa3uVvLwxSl",
        "outputId": "d72b986d-d24d-4537-8944-cb639ffa0135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eEwGjFxwymr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmVWjFnyxD94"
      },
      "source": [
        "### **A different way to handle the labels and the loss**\n",
        "\n",
        "We mentioned earlier that another way to encode the labels would be to cast them as\n",
        "an integer tensor, like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRabJ4t4xEr2"
      },
      "source": [
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsKg7FK4xJel"
      },
      "source": [
        "The only thing this approach would change is the choice of the loss function. The loss\n",
        "function used in listing 3.21, categorical_crossentropy, expects the labels to follow\n",
        "a categorical encoding. With integer labels, you should use **sparse_categorical_\n",
        "crossentropy**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGAPAVlfVObp"
      },
      "source": [
        "The only thing this approach would change is the choice of the loss function. The loss\n",
        "function used in listing 3.21, **categorical_crossentropy**, expects the labels to follow\n",
        "a categorical encoding. With integer labels, you should use **sparse_categorical_\n",
        "crossentropy**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUQ-UiMsxIXn"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apc0AM2ObI7x"
      },
      "source": [
        "This new loss function is still mathematically the same as categorical_crossentropy;\n",
        "it just has a different interface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TMrO0q7b3hE"
      },
      "source": [
        "If you replace the middle intermediate layer with 4 units stead of 46, validation accuracy will peak at ~71%, an 8% drop.\n",
        "\n",
        "\n",
        "This drop\n",
        "is mostly due to the fact that you’re trying to compress a lot of information (***enough\n",
        "information to recover the separation hyperplanes of 46 classes***) into an intermediate\n",
        "space that is too low-dimensional. The network is able to cram most of the necessary\n",
        "information into these eight-dimensional representations, but not all of it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCyR8tuUiVWR"
      },
      "source": [
        "### **Wrapping up**\n",
        "\n",
        "There are two ways to handle labels in multiclass classification:\n",
        "* Encoding the labels via categorical encoding (also known as one-hot encoding) and using categorical_crossentropy as a loss function\n",
        "* Encoding the labels as integers and using the sparse_categorical_crossentropy\n",
        "loss function\n",
        "* If you need to classify data into a large number of categories, you should avoid\n",
        "creating information bottlenecks in your network due to intermediate layers\n",
        "that are too small. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNWKOahkjA43"
      },
      "source": [
        "## <font color=\"Tomato\">**Predicting house prices: a regression example**</font>\n",
        "***\n",
        "\n",
        "We will use the *The Boston Housing Price dataset*.\n",
        "\n",
        "\n",
        "You’ll attempt to predict the median price of homes in a given Boston suburb in the\n",
        "mid-1970s, given data points about the suburb at the time, such as the crime rate, the\n",
        "local property tax rate, and so on. The dataset you’ll use has an interesting difference\n",
        "from the two previous examples. It has relatively few data points: only 506, split\n",
        "between 404 training samples and 102 test samples. And each ***feature*** in the input data\n",
        "(for example, the crime rate) has a different scale. For instance, some values are proportions, which take values between 0 and 1; others take values between 1 and 12, others between 0 and 100, and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQq13He2iciu",
        "outputId": "3eb19e6e-4184-468e-9441-0afda5419602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVMsuvpFl_d-",
        "outputId": "db76ef2f-ed96-44bd-af99-5f4a7203a2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BlC_J52mHDq",
        "outputId": "d1c2b0e1-eb21-41bf-b2ff-fd62578b6bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfZUmoYtmID_",
        "outputId": "8717637f-6b70-413a-9c0c-0a460a6490bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
              "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
              "        18.72   ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSkiDfO4oSXL",
        "outputId": "d245c705-2c20-432f-afa3-40a96eeaefc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "train_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
              "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
              "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
              "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
              "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
              "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
              "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
              "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
              "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
              "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
              "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
              "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
              "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
              "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
              "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
              "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
              "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
              "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
              "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
              "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
              "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
              "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
              "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
              "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
              "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
              "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
              "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
              "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
              "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
              "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
              "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
              "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
              "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
              "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
              "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
              "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
              "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s58BpBRgoXAL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quWVpAgSzZn3"
      },
      "source": [
        "### **Preparing the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGsA7th5sxUS"
      },
      "source": [
        "#### ***Normalizing data***\n",
        "\n",
        "It would be problematic to feed into a neural network values that all take wildly different ranges. The network might be able to automatically adapt to such heterogeneous\n",
        "data, but it would definitely make learning more difficult. A widespread best practice\n",
        "to deal with such data is to do **feature-wise normalization**: for each feature in the input\n",
        "data (a column in the input data matrix), you **subtract the mean of the feature and\n",
        "divide by the standard deviation**, **so that the feature is centered around 0 and has a\n",
        "unit standard deviation**. This is easily done in Numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb6B6Ne9zbTb"
      },
      "source": [
        "# Normalizing data\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t1D5ZKt0UGJ"
      },
      "source": [
        "Note that the quantities used for normalizing the test data are computed using the\n",
        "training data. You should never use in your workflow any quantity computed on the\n",
        "test data, even for something as simple as data normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emjiulDK0UsK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWnidOBD0Xyz"
      },
      "source": [
        "### **Building your network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NHVLZSU0ZxQ"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# We don't want to do this every time we make a new model, so function!\n",
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu',\n",
        "                           input_shape=(train_data.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XjPV7zy1x-E"
      },
      "source": [
        "The network ends with a single unit and no activation (it will be a linear layer). This is\n",
        "a typical setup for scalar regression (a regression where you’re trying to predict a single\n",
        "continuous value). Applying an activation function would constrain the range the output can take; for instance, if you applied a **sigmoid** activation function to the last layer,\n",
        "the network could only learn to predict values between 0 and 1. Here, because the last\n",
        "layer is purely linear, the network is free to learn to predict values in any range.<br><br>\n",
        "\n",
        "\n",
        "Note that you compile the network with the mse loss function—mean squared error,\n",
        "the square of the difference between the predictions and the targets. This is a widely\n",
        "used loss function for regression problems.\n",
        "\n",
        " You’re also monitoring a new metric during training: ***mean absolute error*** (MAE). It’s\n",
        "the absolute value of the difference between the predictions and the targets. For\n",
        "instance, an MAE of 0.5 on this problem would mean your predictions are off by $500\n",
        "on average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxfSk3P80tyy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6ddZOiG2VaR"
      },
      "source": [
        "### **Validating your approach using K-fold validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0ltW7o2t9c"
      },
      "source": [
        "To evaluate your network while you keep adjusting its parameters (such as the number\n",
        "of epochs used for training), you could split the data into a training set and a validation set, as you did in the previous examples. But because you have so few data points,\n",
        "the validation set would end up being very small (for instance, about 100 examples).\n",
        "As a consequence, the validation scores might change a lot depending on which data\n",
        "points you chose to use for validation and which you chose for training: the validation\n",
        "scores might have a high ***variance*** with regard to the validation split. This would prevent you from reliably evaluating your model.\n",
        "\n",
        "Variance measures how far a set of numbers is spread out from their average value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzxeQ312FSWx"
      },
      "source": [
        "The best practice in such situations is to use ***K-fold*** cross-validation (see figure 3.11).\n",
        "It consists of splitting the available data into ***K*** partitions (typically K = 4 or 5), instantiating ***K*** identical models, and training each one on K – 1 partitions while evaluating on\n",
        "the remaining partition. The validation score for the model used is then the **average of\n",
        "the K validation scores** obtained. In terms of code, this is straightforward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrIVe0uEHeVP"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=10kXYyuIEbv2f2ZW_TuyXuDNc37TSbWl9\"></img>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8zF1nB42We0",
        "outputId": "cdf0117c-fa37-4d94-97f4-f6310e7d24ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "k=4\n",
        "print(len(train_data))\n",
        "\n",
        "num_val_samples = len(train_data) // k\n",
        "print(num_val_samples)\n",
        "\n",
        "num_epochs = 100\n",
        "all_scores = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "404\n",
            "101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ5EKDoQIWkG",
        "outputId": "85badbfd-30ec-4edb-fc65-7f9badfd1821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for i in range(k):\n",
        "\n",
        "    print('processing fold #', i)\n",
        "\n",
        "    # prepares validation data from partition #k\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    # prepares the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "        train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    \n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "        train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    model = build_model() # build and compile keras model\n",
        "    model.fit(partial_train_data, partial_train_targets,\n",
        "              epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    # evaluate model on validation data\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_N0c9MWJUlD",
        "outputId": "36773e96-fc73-4b9e-98d1-ef3269bfc203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(all_scores)\n",
        "print(np.mean(all_scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.532926559448242, 2.423518180847168, 2.9132192134857178, 2.4634039402008057]\n",
            "2.5832669734954834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD8OtV2RONVA"
      },
      "source": [
        "The different runs do indeed show rather different validation scores ***(Mean Absolute Error)***, from 2.6 to 3.2.\n",
        "The average (3.0) is a much more reliable metric than any single score—that’s the\n",
        "entire point of K-fold cross-validation. In this case, you’re off by $3,000 on average,\n",
        "which is significant considering that the prices range from \\$10,000 to \\$50,000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqn_U9hvPAwT"
      },
      "source": [
        "Let’s try training the network a bit longer: 500 epochs. To keep a record of how\n",
        "well the model does at each epoch, you’ll modify the training loop to save the perepoch validation score log."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRm9KlVoJVXg",
        "outputId": "81101bd4-071a-4dfb-cfca-fd68023f89bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Saving the validation loss at each fold\n",
        "num_epochs = 200\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "\n",
        "    # prepares validation data from partition #k\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    # prepares the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "        train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    \n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "        train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    model = build_model() # build and compile model\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "        validation_data=(val_data, val_targets),\n",
        "        epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    mae_history = history.history['val_mae']\n",
        "    all_mae_histories.append(mae_history)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HdASbrAWRhx"
      },
      "source": [
        "**History object**<br>\n",
        "Its History.history attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n",
        "\n",
        "\n",
        "For the first fold, let's print the ***Mean Absolute Error*** (MAE) metric on the validation set at each epoch (200 epochs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCXE5Zi1VZO_",
        "outputId": "7cdc6158-4871-4a0b-c332-94cf1469c81c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(all_mae_histories[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k35eu7VHRGg9"
      },
      "source": [
        "You can then compute the average of the per-epoch ***MAE*** **(Mean scores for all folds)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3H3m_YBTlj0"
      },
      "source": [
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIoujdchVSlg",
        "outputId": "4dfc6d01-80bb-464c-cd5a-39a7cda533f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(average_mae_history)\n",
        "print(len(average_mae_history))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.619982600212097, 3.3669437766075134, 3.055215001106262, 2.9292619824409485, 2.7855955958366394, 2.7613282799720764, 2.6783535480499268, 2.7021983861923218, 2.6946849822998047, 2.7415801882743835, 2.5988723635673523, 2.4602808356285095, 2.575784146785736, 2.4400537610054016, 2.5305939316749573, 2.476058304309845, 2.4738600850105286, 2.411781430244446, 2.464357078075409, 2.4809171557426453, 2.398305833339691, 2.445758879184723, 2.4291434288024902, 2.4683979749679565, 2.394391894340515, 2.568010091781616, 2.6078187823295593, 2.4697732627391815, 2.3860210180282593, 2.2960946559906006, 2.574113965034485, 2.389059215784073, 2.38352632522583, 2.4987210631370544, 2.331186592578888, 2.3989044427871704, 2.349738895893097, 2.286318361759186, 2.392315447330475, 2.461774528026581, 2.32744300365448, 2.4412729144096375, 2.3038523197174072, 2.3897128105163574, 2.344736099243164, 2.3730810284614563, 2.4390261471271515, 2.313112735748291, 2.4989964365959167, 2.3955480456352234, 2.4598940014839172, 2.4522831439971924, 2.5390143394470215, 2.533794581890106, 2.5089683532714844, 2.4874752163887024, 2.2769930958747864, 2.4069871306419373, 2.525559425354004, 2.3479228615760803, 2.4109925031661987, 2.282664656639099, 2.4761425256729126, 2.5155147314071655, 2.3255229592323303, 2.262998580932617, 2.369656503200531, 2.4081481099128723, 2.3440551161766052, 2.310223877429962, 2.4701603651046753, 2.4554706811904907, 2.344239056110382, 2.4332231879234314, 2.3431429266929626, 2.3571556210517883, 2.6287525296211243, 2.377107620239258, 2.283518671989441, 2.427785634994507, 2.4610233902931213, 2.334474742412567, 2.2847657799720764, 2.4117106795310974, 2.4141321182250977, 2.368167459964752, 2.4060230255126953, 2.328602910041809, 2.4136118292808533, 2.320499062538147, 2.4824885725975037, 2.407682240009308, 2.5037899017333984, 2.401927649974823, 2.4378342032432556, 2.371349334716797, 2.459998607635498, 2.4340025782585144, 2.751098871231079, 2.4412036538124084, 2.4990130066871643, 2.43892765045166, 2.4818997383117676, 2.4154630303382874, 2.335016965866089, 2.4217164516448975, 2.5785905718803406, 2.4769476652145386, 2.5770785808563232, 2.495415210723877, 2.393013298511505, 2.4955726265907288, 2.5284224152565002, 2.527449667453766, 2.499871850013733, 2.318135440349579, 2.424385130405426, 2.4672539234161377, 2.433069169521332, 2.4544560313224792, 2.4651729464530945, 2.6221452951431274, 2.5190564393997192, 2.5395058393478394, 2.4888174533843994, 2.4565855264663696, 2.4661759734153748, 2.442503869533539, 2.545855224132538, 2.548614263534546, 2.485151946544647, 2.5174002051353455, 2.4540308117866516, 2.534850299358368, 2.459358811378479, 2.499675989151001, 2.4633851051330566, 2.5525810718536377, 2.51921808719635, 2.660194754600525, 2.4518784880638123, 2.5268611311912537, 2.420450270175934, 2.592533826828003, 2.4921141266822815, 2.5233532190322876, 2.453001856803894, 2.4512128233909607, 2.4211599826812744, 2.420489013195038, 2.528837025165558, 2.5415749549865723, 2.5960678458213806, 2.475149691104889, 2.538724422454834, 2.550490081310272, 2.4952961802482605, 2.4399346709251404, 2.51470285654068, 2.480676233768463, 2.593502700328827, 2.4210126399993896, 2.4899776577949524, 2.5869531631469727, 2.4093854427337646, 2.5237980484962463, 2.5341619849205017, 2.503214120864868, 2.610750436782837, 2.5168553590774536, 2.6592700481414795, 2.551506519317627, 2.47044175863266, 2.5112081170082092, 2.416991174221039, 2.5792269110679626, 2.5760369896888733, 2.486489415168762, 2.4448233246803284, 2.517809748649597, 2.735150635242462, 2.49198842048645, 2.5164243578910828, 2.511716842651367, 2.539954721927643, 2.6670783162117004, 2.525926113128662, 2.5436841249465942, 2.544343411922455, 2.546868860721588, 2.6737533807754517, 2.694956123828888, 2.5674501061439514, 2.6054988503456116, 2.513469099998474, 2.7023969292640686, 2.584753453731537, 2.612337112426758, 2.646980404853821, 2.644900858402252]\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLKeNoCZQ8K-"
      },
      "source": [
        "Let's plot the **validation scores** **(MAE)** per epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC2MOu6qQ7re",
        "outputId": "dd4acab3-730b-4e46-939a-3d1e618d1de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3ykZbnw8d81M+m9l012s33Z3tgiRVhAqoCKHBRBUfQ9xwZ6jh7QV+X1oOeI9eBBORQVFRAEaVKkLLDUXbbXbM9uspu+6X0y9/vHUzJJJtnJspNkmev7+eSTyTOTyT1PZp7rvq+7iTEGpZRS0csz1gVQSik1tjQQKKVUlNNAoJRSUU4DgVJKRTkNBEopFeV8Y12AkcrOzjYlJSVjXQyllDqlbNiwoc4YkxPqvlMuEJSUlLB+/fqxLoZSSp1SROTQUPdpakgppaKcBgKllIpyGgiUUirKaSBQSqkop4FAKaWinAYCpZSKchoIlFIqykVNINhd1cLPX9xNfWvXWBdFKaXGlagJBPtqWvn16n3Ut3WPdVGUUmpciZpA4PUIAP5e3YhHKaWCRU0g8NmBoDeggUAppYJFTSBwWwSBwBiXRCmlxpeoCwQB3aNZKaX6iZpA4NM+AqWUCilqAoFH+wiUUiqkiAcCEfGKyCYR+XuI+z4nIrUistn+ujFS5XBbBBoIlFKqn9HYmOYmYBeQOsT9jxhjvhrpQjh9BL3aR6CUUv1EtEUgIkXApcB9kfw74fB5rJfaq30ESinVT6RTQ78Cvg0MN2bzEyKyVUQeE5HiUA8QkS+JyHoRWV9bW3tCBbHjgKaGlFJqgIgFAhG5DKgxxmwY5mHPACXGmPnAS8ADoR5kjLnHGLPUGLM0Jyfk3svH5bQIdPioUkr1F8kWwRnA5SJSBvwFWCUifw5+gDGm3hjjrAJ3H7AkUoXxamexUkqFFLFAYIy51RhTZIwpAa4BVhtjPhP8GBEpCPrxcqxO5YjoW2JCZxYrpVSw0Rg11I+I/BBYb4x5Gvi6iFwO+IFjwOci9Xd10TmllAptVAKBMeY14DX79veDjt8K3DoaZdAlJpRSKrSomVmsE8qUUiq0qAkEXl1iQimlQoq6QKB9BEop1V/UBQLtI1BKqf6iJhA4E8q0j0AppfqLmkDgLDGhfQRKKdVf1AQCt0WgfQRKKdVP1AQCu4tAl6FWSqkBoiYQiAg+j+gSE0opNUDUBAKwtqvUzmKllOovqgKBzyMENBAopVQ/URUIvNoiUEqpQaIqEFh9BBoIlFIqWFQFAm0RKKXUYFEXCLSPQCml+ouqQODzeLRFoJRSA0RVIPB4dIkJpZQaKKoCgbYIlFJqsKgKBNpHoJRSg0VVIPB5BL8uMaGUUv1EVSDwiM4jUEqpgaIqEPi8Oo9AKaUGiqpA4NWZxUopNUhUBQJdYkIppQaLqkDgEU0NKaXUQFEVCHxeHT6qlFIDRVUg8OqEMqWUGiSqAoH2ESil1GBRFQi0j0AppQaLqkCgW1UqpdRgURUIvF5dYkIppQaKrkCgS0wopdQgURUIfLpVpVJKDRLxQCAiXhHZJCJ/D3FfnIg8IiL7RGStiJREsiy6DLVSSg02Gi2Cm4BdQ9z3BaDBGDMN+CXwk0gWRBedU0qpwSIaCESkCLgUuG+Ih1wBPGDffgw4T0QkUuXRZaiVUmqwSLcIfgV8GxhqqM4EoBzAGOMHmoCsgQ8SkS+JyHoRWV9bW3vChdE+AqWUGixigUBELgNqjDEb3u9zGWPuMcYsNcYszcnJOeHn8Xo82keglFIDRLJFcAZwuYiUAX8BVonInwc85ghQDCAiPiANqI9UgbSPQCmlBotYIDDG3GqMKTLGlADXAKuNMZ8Z8LCngc/at6+yHxOxK7X2ESil1GC+0f6DIvJDYL0x5mngfuBPIrIPOIYVMCLG5xF6IxdnlFLqlDQqgcAY8xrwmn37+0HHO4FPjkYZoG+rSmMMERycpJRSp5Som1kMaHpIKaWCRFUg8NiBQDuMlVKqT1QFAqdFENB+AqWUckVVIPBqi0AppQaJykDQ26uBQCmlHFEVCHzaIlBKqUGGDAQi8mjQ7Z8MuO/FSBYqUrwe6+VqH4FSSvUZrkUwPej2BQPuO/EFf8aQtgiUUmqw4QLBcFfLU/JK6tE+AqWUGmS4mcWJIrIIK1gk2LfF/koYjcKdbH0tAt3AXimlHMMFgkrgF/btqqDbzs+nHK/OI1BKqUGGDATGmHOHuk9EYiJTnMjSPgKllBos7OGjYjlPRO4HKiJYpohxl5jQPgKllHIdNxCIyAoRuRM4BDwFrAFmRbpgkaBLTCil1GDDzSP4sYjsBX4EbAUWAbXGmAeMMQ2jVcCTSZeYUEqpwYbrLL4R2AP8FnjGGNMlIqf0FdSry1ArpdQgw6WGCoDbgY8C+0XkT1jDSEd9V7OTxat9BEopNchwo4Z6gReAF0QkDrgMa/7AERF5xRjz6VEq40nj0yUmlFJqkLBq98aYLuBx4HERSQE+FtFSRYj2ESil1GBDBgIR+eZoFmQ09PUR6MxipZRyDNci+BmwGXge6MJaWsJxSlapfdpHoJRSgwwXCBYBnwIuBTYADwOvGHPqJth1iQmllBpsyFFDxpgtxphbjDELgfuBK4CdInL5qJXuJNMlJpRSarBwZhbnYLUO5mEtLVET6UJFikfnESil1CDDdRZ/HrgaiAceA642xpyyQQC0j0AppUIZro/gPmA71hpDFwIfEenrLzbGnHIpInfUkPYRKKWUa7hAMOQy1KcqZ0KZpoaUUqrPcDOLXx/NgowGOw5oZ7FSSgUJez+CDwJ3iQkNBEop5YqqQKBLTCil1GBRGQh0iQmllOpz3EXnRGQG8C1gUvDjjTGrIliuiNAJZUopNVg4q4/+FbgbuBfojWxxIstdYkIDgVJKucIJBH5jzG9H+sQiEo+1v3Gc/XceM8b8YMBjPgf8FDhiH/ofY8x9I/1b4fKKtgiUUmqgcALBMyLyZeAJrFVIATDGHDvO73UBq4wxrSISA7wpIs8bY94d8LhHjDFfHVGpT5DHI4joPAKllAoWTiD4rP39W0HHDDBluF+yVylttX+Msb/G/Ars84i2CJRSKshxA4ExZvKJPrmIeLGWsJ4G3GWMWRviYZ8QkbOBPcA3jDHlIZ7nS8CXACZOnHiixQGsfgLtI1BKqT7hrD4aIyJfF5HH7K+v2qme4zLG9NrLWBcBy0Rk7oCHPAOUGGPmAy8BDwzxPPcYY5YaY5bm5OSE86eH5PN4tEWglFJBwplH8FtgCfAb+2uJfSxsxphG4FXgogHH6+39kMFa5G7JSJ73RHi0j0AppfoJp4/gdGPMgqCfV4vIluP9kr2PQY8xplFEEoALgJ8MeEyBMabS/vFyYFeY5T5hPq8Hv04oU0opVziBoFdEphpj9gOIyBTCm09QADxg9xN4gEeNMX8XkR8C640xTwNft3c88wPHgM+dyIsYCa9H6NU4oJRSrnACwbeAV0XkANYG9pOAG473S8aYrVg7mw08/v2g27cCt4Zd2pPA5xFdYkIppYKEM2roFRGZDsy0D+0Oyuufcjyiw0eVUirYcFtVrjLGrBaRjw+4a5qIYIz5W4TLFhE+rw4fVUqpYMO1CD4MrAY+GuI+A5ySgcCrE8qUUqqf4XYoc9YF+qEx5mDwfSJywpPMxppXRIePKqVUkHDmETwe4thjJ7sgo0VbBEop1d9wfQSzgDlA2oB+glQgPtIFi5RYn4duv44aUkopx3B9BDOBy4B0+vcTtABfjGShIik5zkdrl3+si6GUUuPGcH0ETwFPichKY8w7o1imiEqJ91FX1zbWxVBKqXEjnAllm0TkK1hpIjclZIz5fMRKFUEp8TG0dGqLQCmlHOF0Fv8JyAcuBF7HWkm0JZKFiqSUeJ8GAqWUChJOIJhmjPke0GaMeQC4FFge2WJFTkp8DK1dfh1CqpRStnACQY/9vdHeTyANyI1ckSIrNd7KhmmHsVJKWcIJBPeISAbwPeBpYCdwR0RLFUEpdiBo6ew5ziOVUio6hLPo3H32zdc5zj7Fp4KUeGtzNW0RKKWUZbgJZd8c7heNMb84+cWJvL4WgQYCpZSC4VsEKfb3mcDpWGkhsCaXrYtkoSLJaRFoakgppSzDTSj7fwAisgZYbIxpsX++DXh2VEoXAdoiUEqp/sLpLM4DuoN+7raPnZKcQNCsgUAppYDwZhb/EVgnIk/YP18J/CFiJYqwVE0NKaVUP+GMGvqRiDwPnGUfusEYsymyxYqcOJ+HGK9oakgppWzDjRpKNcY0i0gmUGZ/OfdlGmOORb54J5+I2OsNaYtAKaVg+BbBQ1jLUG/A2prSIfbPp+ycAl1vSCml+gw3augy+/spuy3lUDQQKKVUn+FSQ4uH+0VjzMaTX5zRkRKnqSGllHIMlxr6+TD3GWDVSS7LqEmO91F+rH2si6GUUuPCcKmhc0ezIKNJU0NKKdUnnHkE2MtPz6b/DmV/jFShIi01PoZmTQ0ppRQQRiAQkR8A52AFgueAi4E3sSaanZJS4q0N7AMBg8cjY10cpZQaU+EsMXEVcB5QZYy5AViAtTnNKSsl3ocx0Nat6SGllAonEHQYYwKAX0RSgRqgOLLFiqy+FUg1ECilVDh9BOtFJB24F2tyWSvwTkRLFWG6AqlSSvUZbh7BXcBDxpgv24fuFpEXgFRjzNZRKV2EpCfEAtDQ3n2cRyql1AffcKmhPcDPRKRMRO4QkUXGmLJTPQgAFGcmAHC4XucSKKXUkIHAGPPfxpiVwIeBeuB3IlIqIj8QkRnHe2IRiReRdSKyRUR2iMj/C/GYOBF5RET2ichaESl5H68lbBPSE/B5hIP1baPx55RSalw7bmexMeaQMeYnxphFwKew9iPYFcZzdwGrjDELgIXARSKyYsBjvgA0GGOmAb8EfjKi0p8gn9fDxMxEyuo0ECil1HEDgYj4ROSjIvIg8DywG/j48X7PWFrtH2PsLzPgYVcAD9i3HwPOE5FRGdhfkp3EQQ0ESik1dCAQkQtE5HdABfBFrH2KpxpjrjHGPBXOk4uIV0Q2Yw05fckYs3bAQyYA5QDGGD/QBGSFeJ4vich6EVlfW1sbzp8+rpKsJA7Vt2PMwNiklFLRZbgWwa3A28BpxpjLjTEPGWNGVIU2xvQaYxYCRcAye6mKETPG3GOMWWqMWZqTk3MiTzHI5OxEOnp6qW7uOinPp5RSp6rhFp07aauLGmMaReRV4CJge9BdR7Amp1WIiA9rxnL9yfq7wynJTgLgYF0b+Wnxx3m0Ukp9cIUzs/iEiEiOPRENEUkALgBKBzzsaeCz9u2rgNVmlHI1JVl9gUAppaJZWKuPnqAC4AER8WIFnEeNMX8XkR8C640xTwP3A38SkX3AMeCaCJann8L0BGK9Hsp0CKlSKspFLBDYE88WhTj+/aDbncAnI1WG4Xg9wsSsRG0RKKWiXsRSQ6eCkqxE3alMKRX1ojoQFGUkUtHQoUNIlVJRLcoDQQKtXX4a23W3MqVU9IrqQFCcmQhARUPHGJdEKaXGTlQHgqIMaxXS8gbtJ1BKRa8oDwROi0ADgVIqekV1IEhLiCE13kf5MU0NKaWiV1QHArD6CbRFoJSKZlEfCIoyEijXzmKlVBSL+kBQnGG1CHQugVIqWkV9ICjKSKCzJ0Bdq25kr5SKTlEfCJy5BId08TmlVJSK+kAwryiNpFgv//l8KT29gbEujlJKjbqoDwS5KfH85yfms+FQA796ec9YF0cppUZd1AcCgMsXFHLRnHz+sq5cO43ViOw82sx3n9hGIKDvG3Xq0kBgO2tGNvVt3YMml/3+rYN85r61Y1QqNd69uruGB9ce5li7DjaIJm/vq6PpA7RYpQYC26LiDAA2Hm5wj/l7A9z9+n7e3FdHZ0/vWBVNjWPNndbFoKXTP8YlUaOlrcvPZ+5fy4PrDo11UU4aDQS2mfkpJMZ62RQUCNbsraW6uQvQ9YhUaE4AaO744NQO1fDqWrsIGKht6Rrropw0GghsXo+woCidTeWNvLSzmh89u5N71xxExLpf1yNSobTagUBbBNGjvs1KA77ffUx6Q/QrBQKG/3q+lMP1o1vx1EAQZNHEdHYebearD23k3jcO8s6Bej62cAIAh3VLSxVCi5sa0hZBtDhmTz5teB/9Qq/sqmbebf9gS3ljv+MVDR3c/fp+nth05H2VcaQitnn9qWjxxAz8AUNmUix/vnE5m8sbuXBOPs9tr9S9jVVILdoiiDr1bVZKqOEEWwTbjzTxtYc30d7dy5aKRhYUp7v31bR0AnCgrvX9F3QEtEUQZPmUTM6ans1vP7OYGXkpXL20mLSEGIoyEnXzGhWS20cQhS2Cbn+Abn/0TcLsSw2FbhGUH2vne09uH3KC6n89X0pynI+EGC8H6/qvaFBj9zvsr9VAMGZS4mP40xeWs2RSZr/jxRkJ2kegQmrtit4WwTce3czXHt441sU4IRsPNzD3B//gaOPIP9f1dmroWFvoQPDstkr+9O4h9lS3hLx/b00LZ03PoSQ7ibKBgaDZbhHUtvWb0xTpeSoaCMIwMTOR8mO6QqkaLJqHj26raGJvzejWXE+WTYcbae3ys3lAjj4cTgBo6fTjD1Hrdy7uoSqP7d1+qpu7mJydyOTsRA4N6BSube2yH9dLlR0U7l1zgKnffY7Tf/Qyv31t/4jLGw4NBGEozkykpctPkw4RHFee2nxkTCf1BAImqEUQXe+N3oDhaGMHdafoEEqnz2+oWvtw6lr7XnNjiGtCmb2AZagh586FvyQ7iUlZSRw+1t4vmNQ09z33/po2Gtq6ufOVvcyfkMaqmbkUZyaMuLzh0EAQBmdvY00PjR/VzZ3c9JfNPLl5dEdXBGvv6cVpJI6HFsHh+nbO+/lrozLnpbKpA3/A0NzpPyX7CSrszaj2Vo+8RROcEgrVT1BWZ53/UANMnNZCSVYSk7OS8AcMR4LSUzUtXeSlxgFWh/Hdr++ntdvPTz+5gJ9cNZ/L5heOuLzh0EAQBicKR7LD+NXSGn7yQmnEnv+DxvkwDpWnHQ3BrYCWrrFvEWw83MD+2jbePXAs4n8ruFLkjKIZ7949UM+Hf/oqTe09brA8kRZBfWs3BWnxwOCRQx1BKZ1QOx8etFsLVovAqmDuq2nlvjcO0NjeTW1LF3ML00iO87G6tIY/vF3GxxZOYEZeyojLORIaCMLg7FkQqbkEvQHDD57ewf++vv+UrF2NBWcyz1AjN0ZDcCtgPLQInJrl7qrmiP+t4EpR/YBNncrq2lh3cOTB6M5X9vLs1sqwH7+rspmXd1aH/fg1e2o5VN/OpvIGt7Z+sK5tRJ85YwzH2rqZmpMMDK6IHDpmXehjvDJkiyA7OY7kOB+Ts5MA63Xf/uwunth0hJqWLnJT45iak8Rru2uJ9Xn49kWzwi7fidJAEIbU+BjSE2MiNpfghe1VHD7WTsBwQqMYopHTXxMqRztanBZBWkLMiALBzqPN7sCDhpPYoqlsst47pVUjr+WOVPBnIThnDvDfr+zli39cP6LBFfWtXfzq5T08vO5w2L/zq5f38O+Pb3V/7vYHuPCXa3h+W+hgssdOA721r4627l4WFKXhD5hBQzjBOpev7q5xz6mjpctPd2+AablWIBhYEXFSP4snZlDR0DHoHJTVtTM526pY5qTEkRjrZUtFEwBbyhupb+siJznODTTfu2w2+XbrI5I0EISpOCOR8oYOAgHDOT99lT+/e3IWnDLGcM+a/cR6rX/FwPTT2/vquOaed3TTnAGctX1OdFLPyeBc/AvS4sPuLN5xtIlL7nyD1/bUUtHQzrIfv8xLI6jVDudoo5WS2D1KgcDnsdZfGbjN65HGDpo6ejja1Bn2872wo4qAgQMjGD+/t6aV+rZuuvzWgpD7alrZXd3ChkMNIR/vpIFe2FEFwKpZef2OB/vhMzu54ffvsfI/V/Pq7hr3uDOreGqOVZsf+P47aPcPnD0jh46e3kHnpqy+jUlZ1u+KiHs7Nd7Hmr11GAM5qfF8evlEbj5/Op9cUhTu6XhfNBCEqTgzgYpj7VQ2d1JW3z7km22kKps62VLRxHUrJwGD00/ryo7x7oFjVDeH/6GKBk6LoGkcpIYmpCfQHGaLwKl9bi1vYkt5Ez29hjf31p6U8jityZqWroj1nfT0BujpDVDe0MFpBamAVZsP5rxXSyvDT1E5KaGjTZ20dx//XHb7A+4IHGekzY6jVs26KsRnpb3b71aynP6ND8/MwSOwN0QgOFTfzsLidGK9Ht7dX+8ed/pDijITifV5Bi0zcai+jezkWE4rsHL6wRW7ti4/NS1dbkoIYEFRGqcVpHL9yhL3f5abEsfSkkxuPn8G4ix2FmEaCMJUnJFIRUOHW3s4WXscV9q1pjOmZRHr9QwKBM4Fr+YUHaYXKU3jqEVQmJ5Atz/g1kyH41ysS6ua2WVfKDceHvlY9lCONHYwxb7IlFY1D5uaKa1q5tuPbeHa+95l7YH6IR830A2/f48bH1hP+bF2ZuanEB/j6ZcaMsa47+lwU1S1LV28e6DeTbeU1VlDKv/39f2c/4vXQ37WDtW3uYu2ORf+nfb5DB6C6dhX04oxMHdCqntsak4SJdlJIctZ2dTBnMJUTitIYauduoG+/pDspDgyEmNobBvYIrBq/MUZfR3BT20+wh/fKeMOezBISVZfILj9yrk88eUPMb8ozT2WkxI31KmKGF1rKEzFmYl09wZ4x64dHLZrFRUN7WQkxpIUd2Kn0qk9FaQlUJSRMKgfwg0EId7co+mbj2xmU3kj583K5RsXzDjh13uyNHa8/4W/3i8nHVSYnmD/7Ccu2Tvs7zjpm9KqFjfdt7OymfZuP4mxfee0vdtPb8CQFOvD4zl+rbCls4eWTj9XLy3mwJsH+f1bZXzzkS3cfd0SFgatZeO4d81BntlyFBH407uHWD4lq9/9D609zKyCFBZPzHCPdfsDrDt4jG673BMzE8lKiuvXWdzY3uN2vu4Mo0VQ0dDONx/dQsDAV8+dxs2PbOZAXSu/eW0ff7dbCY9vPMI3L5jR7/eCJ7I5gWfnUevvVbf0tQjWlx1jc3kjqQkxAHx8URHbj+wkPTGGlPgY5k9I46399Rhj3Np3R3cvDe09FKTFIwJPbTpKIGDweMRdXiIzOZaMxNh+GxK1dvnZXd3C+afluUPOf/DUDjrsvUy8HmFabjJLJvWdU5/Xg89r7Z3uyB2DQBCxFoGIFIvIqyKyU0R2iMhNIR5zjog0ichm++v7kSrP++WMHHrNzhfWtXbR1uXnyrve4rand5zw81bZb+L81HiKMxMHtQiaO6xaZ23L2KWG/L0BntteSWdPL/e/dZDvPxX69T6+oYIfPrNzVMrU1NG3tEOo2Z2jobXLj0dwx32H02HsjOwpq29jc3kTWUmx9AZMv1pndXMny3/8CvNue5Fzf/7aoNRLKM7FcEFxOplJsby0s5qq5k4eHKIvq7SqmeVTMrlsfiFv7K3D3xugqb0Hf2+A9m4/33tqO3et3tfvd/ZUt9DdG8BrB6bizASyU+Kobe3iFy/t4d/+usWtncd6PZRWNrP2QP2ws2Gvv38dO4828/NPLuDCOfmANWP5he1VXL9yEssnZ/JciM7ffUGBoLqpE2OMG3iqm62f/++T27jq7ne4/dld3PXqPmK9Hi6dX2CV3b5QL5mUQW1LlzuvAPpaGAVpCcyfkE5Ll9+dJOakb7KSYklPjKGx3eqjCAQMd7xQSlNHD59ePpGEWC/ZyXF0+Xu54xPzWf9/z6f0Py7i5W9+OGTnb35qPFlJscDYtAgimRryA/9qjJkNrAC+IiKzQzzuDWPMQvvrhxEsz/tSnGHV+vYETUB5Y28tda3dvLC9Kqy0QCjVzZ3E+jykJ8ZQnDl4TSOnU7R6DFsEe6pb6ewJcMvFs/j6quk8vrGCv22sGPS4Jzcf4a/ry0M+R2dPLxf+cg2PDnH/SAXP8h6rGd8tnX6S43ykxsfYPx+/HEcbO4jxCsZYlYmr7M7A4J3xfvHiHjp7evnG+TM42tjBbWEEVyfATEiPZ2FxOkUZCZw3K5fnt1cN2l3P3xtgb00rs/JTOHdWDk0dPby0s5qz7ljNr1fvY2tFE70Bw7qyY/3WzHeC1b9fNBOAWfmpZCfFUt/azeMbKnh+W6VbsVk+JZODdW3c9JfN/OSF0pDBrKGtmwN1bXz9vGl8YkkRCbFeCtPieXR9Of6A4ZJ5BVw6v4B9Na1uHv+/X97LVx7cyN6aViakJxAf46GquZOKhg5aOv1MyUmisyfAkcYO/vzuYa5YWMjC4nQO1bczNTeZvNR4JqQnuHn6RRP7diZ8flslz26tpNI+lwXp8W5NfdsR67VXNnWQEucjPsZLRmIsZfXtnPFfq1ly+0v88Z1DfO5DJW4r6taLZ3HfZ5dy9enFZCfHEeMd+nIrIsydkEZaQgxxvuFblZEQsUBgjKk0xmy0b7cAu4AJkfp7kTYhI8HdpGZWvtUR5DRdW7r8vLGn7oSet6q5k7zUOESEiZmJNHX09Fs2oa+PoK9F8PetR/tdOE6mR98rZ2tF/5z1FvvnBUXpfG3VNJZPzuTWv20btE7L/ppWWrr8tHUNrhk/tqGC3dUtbDpJ+fDgi3+khpDe+creYferbu7sISU+hpR4K6Wzp7qVX760Z9gWSmVTJyuC0jArpmYxJTuJjYes87KrsplHN5Tz2ZUl3HT+dL62ajrPbDnK6tLhRxZV2imnwvQEfv2pRbxw89l8/szJtHb5eXlX/98tq2+n2x9gVn4qZ03LwesRvvXYVpo7/fxjR5U7EKKl08/uqhbuf/MgL+2sZmtFI2kJMXzxrCls/N4FnFaQSlZyLPtrWznS2EFbd6/7ux+ekUPA9NWuQ01yc/rbgidLTclJpqG9h5Q4H0smZXDRnHxErIXcAP66oZxnt1Xy8s5qpuclU5CWQFVzp9saWDUzF4C37RTupfMK+OEVcxCBGXlWH8Qfbjid7156GmB9lhNjvazZU8e3H9/KHf8odUc7FaYlMD03mfgYjxsE15c1sHCilWrLSIqltqWLju5ezp2Vy/mn5fFvH5npvpZPLClyRyaF48vnTOWWi/xbehAAAB/lSURBVCM/ZyCUUeksFpESYBEQ6lO1UkS2iMjzIjJniN//koisF5H1tbUnZ4TFSMX5vOSlWE26c2dZb7bVpTXE+jykJcSEbL4Cx01bVDV1kp9qPe9EO/0UPNJgYGexMYbvPrGduyOw+JQxhu8/vZ3/XXOg33HnAjApKxGf18Nvrl1MbmocNz6w3u0obO/2ux+ggSOcegOGe9+wnvNkpbiaO3pItS/AJ3NSWUtnj9v8f6W0hrf219HRHbq119rpJyXeR4rdIrjzlb389yt7WWtPpqoZcB46uns51tbNspJMEmOtWt/sglQWTkx3g+qDaw+REOPlq6umAfAv50wlJc7H67uHf98fbezA6xFyU+JJivORHOdjxZQs8lPjeWxD/9abM7x0Zn4KaYkxLJ6YTmuXn9yUOEqrWnh2ayUZidZr+uuGcm5/die3PL6VdWXHmF+UhoiQaacxrPRH33v89T1WOc+xL8iXzi8gOc7HW/sHV5T22Omd4EDg1NTPnJ5NjNdDbmo8p0/K5PltVRxp7HBTOB09vUzLSSYvNY7qpk52HG3GI3DWjBzAmisAMC03mflF6fz22sV8bdV0AKbnpZBnf+Z8Xg8LitJ5fGMFLZ1+DtW3u62P/LR4fF4PcwrT2FrRyLG2bkqrWtxAnm2fgx9/fB6/uHoh93126fvqO1s+JYtPLZt4wr//fkQ8EIhIMvA4cLMxZmDv0UZgkjFmAfBr4MlQz2GMuccYs9QYszQnJyeyBR6Gc6FeOimDlHgf7d29nFaQykdm5/HCjip+8NR2ttk1B2MMd76yl7m3/SPk8DRnREd1c6f7pgw1g3lgZ3F9WzdNHT0hh8i9Xy1dfjp7AoPGoW8ub3IvAABZyXH87KoF1LV2uTNIgyflDExjvbijikP17STFesPe57WutWvYUS+N7d2U2BeN97tlYLDvP7WD6+5fi783QGllM8YMvQxBS6ef1KAWgfN/e2lnNU9tPsKK/3yl3//+qD05qSgzgZn5KWQmxZKbEsfsglTqWruoa+1iV2ULcwvTSE+0LjIxXg/5afHHTQ0ebewgPzXezd+D1Tn56eUTeW13LevL+mrkpVXNbsclwJWLJjAhPYHfXLsYsDp5zz8tjwnpCfzh7TI8YnWSHqht6ze6Baz3AkCSHdi2H20iOzmWabnJ3P2Zxfz4Y/NYPjnTHWQRbG91CylxPne5BoAp9vj8c2b2fc4vnpfP7uoW/mJPNvvyOVMBmJGfQn5qPFXNnaw9UM9pBamU2Ms2vL2/nlivx/3MXjS3wH29Azmdt8n2RfyV0hoyk2KJj7Fe0/LJmWw83MiT9q5hK6ZYy9R/ZsUk7rluCVcsPGUTHa6IBgIRicEKAg8aY/428H5jTLMxptW+/RwQIyLZkSzT+1Fkrzk0LTfZfYPNn5DG9StLKMlK4uH3rNoTwM9e3M0vXtpDZ0+AN/b2rw3tr21l3m0v8va+OqqaB7cInItqtz/gjjhwUkNOJ1nVcSbr7DjaNKJhgdAXbA7WtdHl72VfTSvbjzSxp7pl0MiTyfYH1hlFsb+2LxDUDKj1bzjUQEKMlwvn5oc1DHZzeSNLb3+Z7zyxLWTfizHWYmfOZJyBQ0jX7KkdVBsP196aFnYcbea9sga3pls6YMmGpo4eNpc30tLVQ3J8Xx8BQJzPw8u7qrn/zYMEjHVRcThDRwvTEvjSWVO4+fzpiAiz8q0hjaWVLeyuamFWQf91ZXJT4/qd0zV7aln1s9fclldVUyebKxopTB/cCXnjWZPJS43jtmd28M1HNvPlBzew/UgTJVmJ7oXu2uWTePPfz2XJpAwm2COglkzKYNnkTIyBjy+awFnTrY/lvAn93wfZyVbAWjk1i8K0eIzB7Qy9aG4BaQkxrJyaxcG6tkGz5vdUtzAtL7nfWPmzZ+SwrCSTC2bnu8cunmt18N6z5gAp8T7+9SMz+d3nlnL5gkLy0uKpbu5k4+EGzpye7Vaqalu6KMm2WrDH49Twv3OJlS7aV9PaLzh9evlEjDHc8Y9SEmK87jnITY3nI3PyBz/hKSiSo4YEuB/YZYz5xRCPybcfh4gss8szsqvXKFpYnE5uShxFGYnuglHzitKYV5TGczedxY1nTmb9oQYqmzq4742DfHRBIQVp8W4+31my+H9f309rl5/HNlbQ2RNwPzgp8TFMzExku90x5ax1n5kUS31bN/7egLtzUW1r17Czjb/35HZu+du2Eb0+5+LZGzDsrW7lU/e+y2W/fpPegGFBUf8LQKZdY3WWIQ6eETowSDnrp+SnxlPb0nXcTTactXIeXlfOd/62fdD9rV3W0MpJduAMTg1tP9LE9b9bNyi9FS4n1/6Htw+6x3ZV9m8R/Pa1/XzsN2+xv6aNlHgfyXaLQAS+fM40Kho62FrRhIg1oMDhBoL0BC6eV8D1K0sA3Av/K6XVtHb5mZnfPxDkpfRvEfzP6n0cqGvjVy/v5Y29taz6+WtUNHRw7fJJg15PYqyPb184i+1Hmnl2WyXPbavi1d21zCpI7fc4EUFE3Jr4kkkZnD0jG59HuPGsKdxy8SyWT850a8OObLtFsGxyJjPscjsVG8cZ06wg8tWHNnLXq/vclt7e6lZmDlhMbWpOMo/+80o39QRWYFkyKYMuf4BlJZl4PcKqWXnEx3jJT42np9fQ02s4Y2o28TFe0uyhos4yDcdzxrQsXvrG2Xx6+UR36GZBWt9yz0UZiVw0N5/OngBLSzKI9X3wpl9FcjD4GcB1wDYR2Wwf+w4wEcAYczdwFfAvIuIHOoBrzDje/eW6FZO45vSJeD3ipnHmTehrKq+alctvXtvP957cTpc/wGdXTiIQMGw63Mimww1cdfc7XL20yN2Y+h/branueUEfnAXF6Wywm/FOWmhabjLrDh6jrrXbbREYY11gnRpcsJbOHrZUNCFYfRQv7aymtKqFbwwYi+14aO1hlk3O6Fdbf2xDBbUtXVw0J5+AMayY2n+cuc/rISMxxp1pub+2jaKMBBraugelMWpbrPVTclLi8AcMjR09/T7oAx1p7EQELpqTz9t2brk3YDDG4PN63PNSlJGAR/pSQ8YYfvzcLmBkSxU4Ont63RbOSzurifV5mJmXQmlVMwfr2thf08r5s/PYdLgBY6w8dUq8D69HSIr1MqsglWuWFfPLl/eQEufjsgWFPL6hgo7uXhJivRy1X9fA4YPZyXFkJ8fxzBarn8lpIThy7QBqjGFXZQvryo6RlxrHo+vLeWbLUSZmJnLPdUuZaFdOBvrYogkkxnpZMimD37y2nz+8XcasIVazvPGsKeSmxDMtN5lpucmcMTWbXPv9+cj/WTno8XML0zhnZg6XzCugvrWb13bX9ns/A8zMS+HqpUVsOtzIT/+xm6KMBM6clk19WzfTw1xV85J5BWw41MCyyf0DkRN0Yr0eTi+x7stLjaOpo2fIVNBAIuKWY05hKjW7awe1rj5/xmSe21bVr6P/gySSo4beNMaIMWZ+0PDQ54wxd9tBAGPM/xhj5hhjFhhjVhhj3o5UeU4GEXFrAxfOyefyBYVMD3qzLZqYQXpiDC/vqqEwLZ7FEzNYNDGdI40d/PLlvQSM4eF15fQGDJ9cUkSb3QkZfGFYUJTG0aZOapo73Que8zdqWjr7pWCqmkIvULf2gDXszx+wZnk+tO4w975xIGTOvbKpg+88sY0H3j7kph+8HuGR98oRgR99bC73XL/UzZ8Gy0rum0x0oLaVqTnW8LzqAamh2tYuclLiyLU72wemjgaVqbGDnOQ45hWlUdnUSUtnD//3yW1c/7t1QF+ATE+MJT0x1p1UtmZvHW/vrychxktZ/cgXCAzu5A4Y6wI2d0KaFUQf2cw//3kDTR09bD/SxOklGXg9QlaSVYP8yqpp3Hz+dPJS4/nE4iK+smoaF8/Np7s3wNqDViP3aGMHuSmhhxHOyk9xO94HtghyU+Lo7g3Q2N7DA2+XER/j4cEbVxDn85AY6+V3nzt9yCAA4PEIF88rIDc1nu9cchrfOH8GHx9iDZvJ2UncZKesRMQNAkNJS4zhDzcsoygj0e30Hdgi8HiEO65awAs3n838ojRuf3aXO6rHGclzPFcsLOTsGVbACZZnf3aWTMogwe6ncAJRuIEg2Fy7YjcwWC8tyeT3N5zOZz9UMuLnPBXozOITtHhiRr9Zl2BdQM+ZkcOTm4/y0QWFeDzijlNes6eWa04vZnZhKt3+APMmpPFXezRH8AfHycVvqWjC57Vyp04gqG7uYr89/ru0qsWdRDTQm/v6+iQO1bezv6aV9m6rtus05R1O/0VZfRtxPg/xMR6mZCezs7KZ+UVpbmdgKNnJ1hjyQMBwoLaNZZMz6fL3UtPcSWdPL00dPeTZtdkPTc0i1554VdvSxaxhUquVTZ0UpicwPde6sOyraWXNnjqqnedt71v1Mz0hxh0++mppDYmxXq5dPpHfv1WGvzeAz+uhy9/L6l01HDrWzpnTst0Pu2Pn0WYCxrgTwpZPzmTtwWPMKUxlVn4KD687zOZ2a1TPQ2sP09bdy9VLi7n9ynluzfHL50xzn+/nVy8ArBZGrM/Dmj11nDMzl/KGdncW8kCz8lN4c18dxZkJg4Kuc2Grau7kuW2VXDqvkGm5yfz1n1eSnhg75HOGEuvzcNP508N+/Eg4AWyo8ng9wu1XzuWKu97iaw9vAgh7nf3s5Dj++Pllg44X2X/rzOl9XYtOhSPc1FCwOYVWa6wwbfBrONceCfVB9MFLdo2xi+cV4PUIVy6yRhLMnZDqrix69enFXL+yhBvPmsKC4nS3dRE8k3BOYRpej7C1otGdTOZ8WA7Vt3GksYMz7ZxrVVMnDW3dbl+C4+39de7qiKVVze6wzlD7Kayxh/sdrGuzcvkp8e48iXNmDD9CKys5jrrWLqqaO+no6WVKTjL5qVY++7+eL+WyX79Jl98KCLkpceTYQSV4uYxAwHDNPe/ws3/sdo8dbeqgMD3eDYBrDx7jSKO1I1ZpVYvbIkhLiHFnd4K161RxRiLTc1P67fz05KYj/MuDG/mv50u55W/WssV3vFDK79+y+gG+/fgWvvXYVnfJYed/5wQCsNJQibFe7n/T6ntYUJzOzPwUd+hoKPExXpZOymDtwXoCAcOOI83MHpCbdzgX0Zl5g+93Zi5bHdR+Ftnj2OcUpoVMDY6VOYWp/Obaxe7s3VDmF6XzyJdW8oOPzubXn1o0KI00Urmp8fzx88v4/BmT3WPFmQnEeOWEAsEZ07L5+KIJbr9GtNBAcJJ9ZHYe7956nrsyY5zPy4LiNGbkJbMoaORNfIyXxRPTyUiMcUdvACTEepmRl8Lm8r5AMCUnGRHc5XAXT8ogIcZLZVMn1/9uHV95cKP7+zUtneypbuXji4uI9XpYHTRqpfxYOxUN7by5ty/v/ua+OkSstEVFQzt5qXFu5+WHj1MDyk6Kpa61y51+PyU7iTx7ON+LO6qobelyh6LmpMS5AS+4L2J1aQ3vHjjG4xsrMMbqB6hs7KQgLYFie4XH4FnM2440BaWGYkhPjHX7CCoa2inKSHCHlTqjr/ZWtxLn83DrxVan6eMbKtxceUd3L7sqW9hT3eKuJX/5gkL+48q5XLloAnMmpFGYFs8tF89ixZQs6lq7SYz1hn2RWTopg12VzWw/2kRLl58FIdb9Adz3y2kFg2vITg3X6XgemDoaL0SES+YV9Hs/h7JsciY3nDGZjy44Odsunj0jx00LAdxwxmQe/T8r+x0LV0p8DL/4p4VjsszDWNLU0EkmIoPeRL/+1GIMpt8wOYCbz5/B4RC57IXFaTy7tZJldudXRlIMU7KTeGuflVedlptMQVo82yqa3Knv1kUwka3l1s/LJ2dSlJnQb6eow/XtrNlTx5Obj/D2LauobOqksb2Hc2fm8OruWrYfaeaC2Xl8ckkxCTHefoErlKzkOJo7/W4H9qSsRHJT4+n2B9xWyHtl1oipnJQ4kuJ8/eYSGGO46zVrPZvKJiuA5aXG0dHTS0GaNSZ+ak4yuyqbEbHGeW+raHQvwk6LYHdVC8YYKho6WDElixJ744+yujaYac2knZSVyDXLJvLLoM1MDtW38+ruGncZhVd315KeGENSnI/rVvSNwHn71vMAK6W1urSGuXarLRyLJ2UQMPDHdw7Z/9vQ53RmvtWhGuri6KTUnP//jNzxGQjGi7SEGDclq8KjLYJRkJ8W3284mmPFlCyuPr140PEFRek0d/rZeqSJ+BgPcT4vT331TO769GK+d9lspucmk58Wz7qgSUJPbLRGIu12pu3npzApMxF/wODzCFlJsRw+1s7m8gZ6A4ZH3yvn6c3W6pOfsS963b0BclLiyEiK5bqVJcdd9TLLHkO+8VADsV4PBWkJbhrD8Z4diHKSrVptbmq821n8XlkDmw43uhOEXttd46ZznDyzkx6akp3E4okZbK2wWgQ+j5AY6yUnOY7ali7qWrtp7fJTlJFATnIcSbF9HcZl9W2UZCWRlhDDZfML8QcMy+3RJ86MZ7BaG6H+T46zplupsoGTqobjXJCe3nyUpGFaEjFeD3dctSBkztwZEtnU0UN+ajxpiUOno5Q6ERoIxiEnffDO/np3THRynI9L5xfwhTMnIyLuqIaspFiWTc7kb5uOYIxhT3ULE9ITSI2PcSdclWQnMTk7iR1Hm9lf24YI/P7tMh54p4xPLinqtyxubmr4TWJnxMyGww0UZybg9Yib852em4xHYP0hOxDYrSTnwg3WZuIi8OVzpzEzL4XXdtf2WzPHeR6wguP8ojT21rSyu6qFtIQYRITTClLp7g24SxsUZSQiIpRkJ1Fmr1l/uL7dXbrgi2dNYeWULH51zULiYzxsOtzIhPQE9zwXDrMt4NScJP7jyrkjGjmSlhDDjLxkunsDzCsKvyUxkDO+fcY4TQupU5sGgnFoem4yCTFeWrv87gVqIGfm44emZXPVkiIO1rWxpaKJ3VUt7pA8Z67DtBxrJrSzMNenlk3kWFs3mUmxfPeS2aQnxrpryzj56HDkpFgtgvJjHe5mG84IqAtm5zEhI4G61m5E+loPOal9gWB3dQvFGYkkx/k4Z2YO6w8dc9eZdy7I0+3XMq8ojXkT0ugNGF4preGiudawI2ejkRfsORlF9iqxJdlJlNW1UdnUQXdvwA2KM/NTePhLKyhIS2BRsRUAF05Md5+nIMTsXIeIcN2KSe55DZcTaIfqHwiHE2BnhjncUqmR0EAwDvm8HvfCNFQgyLdTGGdNy+Yjs/PwiLWmz4HaNrfW6My8nZab3O/i9a8XzODiufn87JML3DSD08E6kk0xnBYB4F5oizIS+NHH5vKFMye7wSEzMdYdO5+b0hcI9lS1uKmQS+YV0NNr7d8c45WgGatZfGhqFueflseyyZnMnZDKdy85jduvnAvA5GwraDodqc4685OzkigP2lHO6TcIdnqJdYFeVJzO3EIr3TNcauhEOcOMFxadeCBwWwRhDrdUaiQ0EIxTzpIOQwWCpZMymJmXwrmzcklPjGXRxAz+8l453b0Bd9r+jLwURKxJMs46RlNykshKjuO3n1nCh4OGh062L9ojSg0l980OdpbcEBGuXT6JrOQ4NxAEd57npsTT0uWnrrWLg3VtzMy3Uz/F6VwwO4+GdmvugdM/kZkUy0NfXEFxZiLpibH8/Wtn8cWzp7gd716PMLswlS5/gJR4nxvYlpZk0Bsw/P6tMuv1Be0T63D2rF05NYs5E5xA8P6GM4Zy8bwCvnruNHdFzhPhTOwaryOG1KlNA8E45aQRUocIBKcVpPKPb5ztXmTPnZnjLp/s1BonZiWy+l/P4cI5ee7M06FqpVPtXHzeCFJDyXE+dy7EpBAzW51WRnAgWGyPgf/TO4fwB0y/Gu63L5yJR0JP5hnOXHsSkLM9IMCZ07LJTo7jjb11xMd4Qr6uJZMy2fS9jzCnMI0zp2Vz1vTsQVs2ngzJcT7+7cKZJzSc0eFsNjNdRwypCNDho+OUM8wwdZgJS8HOmZnLz17cg0f6T613asJTspOI8QrLBywa5vjM8knMyk8hY5g1gAYSEbKTYjna1NlvQ26HsyRwTtDs5CWTMkiN9/HHd8qA/qmO6Xkp3Hb5nEGzn4/Hqc07/QNgpdeuXFjIfW8epCQracgRUE4LIjMplj99YfmI/u5oumhuvtsvotTJpi2CcaooI4EL5+SFPcNxdkEqOSlxlGQnhZzQk5Ucx6v/dg6fXDJ4uCpYF8TzTgt/N6Xg5/V6hAkZg2vxoVoEPq+Hs2fk0NDeg9cj7vrzjutXlgxaT+Z4nPx+cUb/VsnHF1vr6YRqrSil+miLYJwSEf73uqVhP97jEW69eBbDrd1alHHyL4i5KXG0dCaEXEjNWu4h2V0SwbFqVi5/31rJ5Oykk7I/6/S8ZJZMyuDM6f3TOrMLU7nm9OJ+69AopQaTcbzqc0hLly4169evH+tiKNvuqhZau3pYMil0yimU+tYulv7oZS6ZW8Bd9q5YSqnIEpENxpiQtUttEaj35URGsWQlx/G9S2ePaIauUipyNBCoMfH5Mycf/0FKqVGhncVKKRXlNBAopVSU00CglFJRTgOBUkpFOQ0ESikV5TQQKKVUlNNAoJRSUU4DgVJKRblTbokJEakFDp3Ar2YDdSe5OCeDlmvkxmvZtFwjM17LBeO3bO+nXJOMMTmh7jjlAsGJEpH1Q62zMZa0XCM3Xsum5RqZ8VouGL9li1S5NDWklFJRTgOBUkpFuWgKBPeMdQGGoOUaufFaNi3XyIzXcsH4LVtEyhU1fQRKKaVCi6YWgVJKqRA0ECilVJT7wAcCEblIRHaLyD4RuWWMy1IsIq+KyE4R2SEiN9nHbxORIyKy2f66ZAzKViYi2+y/v94+likiL4nIXvt7xiiXaWbQOdksIs0icvNYnS8R+Z2I1IjI9qBjIc+RWO6033dbRSRie3IOUa6fikip/befEJF0+3iJiHQEnbu7R7lcQ/7vRORW+3ztFpELR7lcjwSVqUxENtvHR/N8DXV9iPx7zBjzgf0CvMB+YAoQC2wBZo9heQqAxfbtFGAPMBu4Dfi3MT5XZUD2gGN3ALfYt28BfjLG/8sqYNJYnS/gbGAxsP145wi4BHgeEGAFsHaUy/URwGff/klQuUqCHzcG5yvk/87+HGwB4oDJ9ufWO1rlGnD/z4Hvj8H5Gur6EPH32Ae9RbAM2GeMOWCM6Qb+AlwxVoUxxlQaYzbat1uAXcCEsSpPGK4AHrBvPwBcOYZlOQ/Yb4w5kVnlJ4UxZg1wbMDhoc7RFcAfjeVdIF1ECkarXMaYF40xfvvHd4GiSPztkZZrGFcAfzHGdBljDgL7sD6/o1ouERHgauDhSPzt4QxzfYj4e+yDHggmAOVBP1cwTi68IlICLALW2oe+ajfvfjfaKRibAV4UkQ0i8iX7WJ4xptK+XQXkjUG5HNfQ/8M51ufLMdQ5Gk/vvc9j1Rwdk0Vkk4i8LiJnjUF5Qv3vxsv5OguoNsbsDTo26udrwPUh4u+xD3ogGJdEJBl4HLjZGNMM/BaYCiwEKrGapqPtTGPMYuBi4CsicnbwncZqi47JWGMRiQUuB/5qHxoP52uQsTxHQxGR7wJ+4EH7UCUw0RizCPgm8JCIpI5ikcbl/y7Ip+hf4Rj18xXi+uCK1Hvsgx4IjgDFQT8X2cfGjIjEYP2THzTG/A3AGFNtjOk1xgSAe4lQk3g4xpgj9vca4Am7DNVOU9P+XjPa5bJdDGw0xlTbZRzz8xVkqHM05u89EfkccBlwrX0BwU691Nu3N2Dl4meMVpmG+d+Nh/PlAz4OPOIcG+3zFer6wCi8xz7ogeA9YLqITLZrldcAT49VYez84/3ALmPML4KOB+f1PgZsH/i7ES5XkoikOLexOhq3Y52rz9oP+yzw1GiWK0i/WtpYn68BhjpHTwPX2yM7VgBNQc37iBORi4BvA5cbY9qDjueIiNe+PQWYDhwYxXIN9b97GrhGROJEZLJdrnWjVS7b+UCpMabCOTCa52uo6wOj8R4bjd7wsfzC6lnfgxXJvzvGZTkTq1m3Fdhsf10C/AnYZh9/GigY5XJNwRqxsQXY4ZwnIAt4BdgLvAxkjsE5SwLqgbSgY2NyvrCCUSXQg5WP/cJQ5whrJMdd9vtuG7B0lMu1Dyt/7LzP7rYf+wn7f7wZ2Ah8dJTLNeT/Dviufb52AxePZrns438A/nnAY0fzfA11fYj4e0yXmFBKqSj3QU8NKaWUOg4NBEopFeU0ECilVJTTQKCUUlFOA4FSSkU5DQRK2USkV/qvdnrSVqu1V7Ecy/kOSg3JN9YFUGoc6TDGLBzrQig12rRFoNRx2OvT3yHWfg3rRGSafbxERFbbC6i9IiIT7eN5Yu0BsMX++pD9VF4Ruddea/5FEUmwH/91ew36rSLylzF6mSqKaSBQqk/CgNTQPwXd12SMmQf8D/Ar+9ivgQeMMfOxFnW70z5+J/C6MWYB1rr3O+zj04G7jDFzgEasWatgrTG/yH6ef47Ui1NqKDqzWCmbiLQaY5JDHC8DVhljDtiLglUZY7JEpA5riYQe+3ilMSZbRGqBImNMV9BzlAAvGWOm2z//OxBjjLldRF4AWoEngSeNMa0RfqlK9aMtAqXCY4a4PRJdQbd76eujuxRrzZjFwHv2KphKjRoNBEqF55+Cvr9j334ba0VbgGuBN+zbrwD/AiAiXhFJG+pJRcQDFBtjXgX+HUgDBrVKlIokrXko1SdB7E3LbS8YY5whpBkishWrVv8p+9jXgN+LyLeAWuAG+/hNwD0i8gWsmv+/YK12GYoX+LMdLAS40xjTeNJekVJh0D4CpY7D7iNYaoypG+uyKBUJmhpSSqkopy0CpZSKctoiUEqpKKeBQCmlopwGAqWUinIaCJRSKsppIFBKqSj3/wEHsTxqcY9O/wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5c1Mt7RiwU_"
      },
      "source": [
        "### <font color=\"DodgerBlue\">**Visualizing metrics using Seaborn**</font>\n",
        "\n",
        "If you want to customize the *seaborn* styles, you can pass a dictionary of parameters to the **rc** argument of axes_style() and set_style(). Note that you can only override the parameters that are part of the style definition through this method. (However, the higher-level set_theme() function takes a dictionary of any matplotlib parameters).\n",
        "\n",
        "As per the docs, you can get seaborn's current rc settings with seaborn.axes_style()\n",
        "\n",
        "[Seaborn rc argument options](https://stackoverflow.com/questions/30729473/seaborn-legend-with-background-color)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dURGchTuYTGU",
        "outputId": "cf0cafaa-3c39-448c-c3ac-f159824bca3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.clf() # clears figure\n",
        "\n",
        "ax = sns.lineplot(x=range(1, len(average_mae_history) + 1), y=average_mae_history)\n",
        "\n",
        "# The Axes contains most of the figure elements: \n",
        "# Axis, Tick, Line2D, Text, Polygon, etc., and sets the coordinate system.\n",
        "ax.set(xlabel=\"Epochs\", ylabel = \"Validation MAE\")\n",
        "\n",
        "# Set the aesthetic style of the plots.\n",
        "sns.set_style('whitegrid', {'axes.labelcolor': 'white', 'axes.grid': True, \n",
        "                            \"figure.facecolor\":  (1.0, 0.0, 0.0, 0.0),\n",
        "                            'xtick.color': 'white',\n",
        "                            'ytick.color': 'white'})\n",
        "ax.plot()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkD1n7pfVKxU"
      },
      "source": [
        "It may be a little difficult to see the plot, due to scaling issues and relatively high variance. Let’s do the following:\n",
        "\n",
        "* Omit the first 10 data points, which are on a different scale than the rest of the curve.\n",
        "* Replace each point with an exponential moving average of the previous points,\n",
        "to obtain a smooth curve.<br><br>\n",
        "***\n",
        "<br>\n",
        "\n",
        "\n",
        "Look into **Exponential Moving Average (EMA)** to understand how this works:\n",
        "\n",
        "An exponential moving average (EMA) is a type of moving average (MA) that places a greater weight and significance on the most recent data points. The exponential moving average is also referred to as the exponentially weighted moving average. An **exponentially weighted moving average reacts more significantly to recent price changes than a simple moving average (SMA)**, which applies an equal weight to all observations in the period."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpYMh86BVBzn"
      },
      "source": [
        "# Plotting validation scores, excluding the first 10 data points\n",
        "def smooth_curve(points, factor=0.9):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftVMRt3gl738"
      },
      "source": [
        "smooth_mae_history = smooth_curve(average_mae_history[10:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2An15mDqQwD",
        "outputId": "859d45fe-3657-4dcf-fea8-7bfc784fe357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.clf() # clears figure\n",
        "\n",
        "ax = sns.lineplot(range(1, len(smooth_mae_history) + 1), y=smooth_mae_history)\n",
        "ax.set(xlabel=\"Epochs\", ylabel = \"Validation MAE\")\n",
        "ax.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdXs2vG6qw6R"
      },
      "source": [
        "According to this plot, validation **MAE** stops improving significantly after 80 epochs.\n",
        "Past that point, you start overfitting.\n",
        "\n",
        "\n",
        "Once you’re finished tuning other parameters of the model (in addition to the\n",
        "number of epochs, you could also adjust the size of the hidden layers), you can train a\n",
        "final production model on all of the training data, with the best parameters, and then\n",
        "look at its performance on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccdbols0qFge",
        "outputId": "1c356940-5f78-4051-b057-1fb79cacc184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = build_model() # get a fresh, compiled model\n",
        "model.fit(train_data, train_targets, # train on entirety of data\n",
        "    epochs=80, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 16.9136 - mae: 2.5886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCEIGAUWrLRL",
        "outputId": "d0d36aed-42e6-407b-b6c2-7bfb67d0606c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.588634729385376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSngcSTurm9S"
      },
      "source": [
        "You’re still off by about $2,590."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z5q8Vz4r6JI"
      },
      "source": [
        "### **Wrapping up**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rkFaeilsOkp"
      },
      "source": [
        "Here’s what you should take away from this example:\n",
        "* Regression is done using different loss functions than what we used for classification. *Mean squared error* (***MSE***) is a loss function commonly used for regression.\n",
        "\n",
        "* Similarly, evaluation metrics to be used for regression differ from those used for\n",
        "classification; naturally, the concept of accuracy doesn’t apply for regression. A\n",
        "common regression metric is *mean absolute error* (***MAE***).\n",
        "* When features in the input data have values in different ranges, each feature\n",
        "should be scaled independently as a preprocessing step.\n",
        "\n",
        "* When there is little data available, using K-fold validation is a great way to reliably evaluate a model.\n",
        "\n",
        "* When little training data is available, it’s preferable to use a small network with\n",
        "few hidden layers (typically only one or two), in order to avoid severe overfitting. \n",
        "\n",
        "* As training progresses, neural networks eventually begin to overfit and\n",
        "obtain worse results on never-before-seen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGIeZZJLrfJd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJF7BJDvrcvy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTR5nh_MwZ9S"
      },
      "source": [
        "# <font color=\"Orange\">**Fundamentals of Machine Learning**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z3c6Amvwhdt"
      },
      "source": [
        "This chapter covers:\n",
        "* Forms of machine learning beyond classification\n",
        "and regression\n",
        "* Formal evaluation procedures for machine learning models\n",
        "* Preparing data for deep learning\n",
        "* Feature engineering\n",
        "* Tackling overfitting\n",
        "* The universal workflow for approaching machinelearning problems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pij-1zDOwn28"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAVqVZwaw5Gw"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Four branches of machine learning**</font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6n1h8O5xdxB"
      },
      "source": [
        "**Supervised learning**\n",
        "\n",
        "This is by far the most common case. It consists of learning to map input data to\n",
        "known targets (also called annotations), given a set of examples (often annotated by\n",
        "humans). All four examples you’ve encountered in this book so far were canonical\n",
        "examples of supervised learning. Generally, almost all applications of deep learning\n",
        "that are in the spotlight these days belong in this category, such as optical character\n",
        "recognition, speech recognition, image classification, and language translation.\n",
        "\n",
        "Although supervised learning mostly consists of **classification** and **regression**, there\n",
        "are more exotic variants as well, including the following (with examples):\n",
        "* ***Sequence generation***—Given a picture, predict a caption describing it. Sequence\n",
        "generation can sometimes be reformulated as a series of classification problems\n",
        "(such as repeatedly predicting a word or token in a sequence).\n",
        "\n",
        "* ***Syntax tree prediction***—Given a sentence, predict its decomposition into a syntax\n",
        "tree.\n",
        "\n",
        "* ***Object detection***—Given a picture, draw a bounding box around certain objects\n",
        "inside the picture. This can also be expressed as a classification problem (given\n",
        "many candidate bounding boxes, classify the contents of each one) or as a joint\n",
        "classification and regression problem, where the bounding-box coordinates are\n",
        "predicted via vector regression.\n",
        "\n",
        "* ***Image segmentation***—Given a picture, draw a pixel-level mask on a specific object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xBuXNlQzD_g"
      },
      "source": [
        "**Unupervised learning**\n",
        "\n",
        "\n",
        "This branch of machine learning consists of finding interesting transformations of the\n",
        "input data without the help of any targets, for the purposes of ***data visualization, data\n",
        "compression, or data denoising, or to better understand the correlations present in\n",
        "the data at hand***. \n",
        "\n",
        "Unsupervised learning is the bread and butter of **data analytics**, and\n",
        "it’s often a necessary step in better understanding a dataset before attempting to solve\n",
        "a supervised-learning problem. **Dimensionality reduction** and **clustering** are well-known\n",
        "categories of unsupervised learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AobTqjRBzdGC"
      },
      "source": [
        "**Self-supervised learning**\n",
        "\n",
        "This is a specific instance of supervised learning, but it’s different enough that it\n",
        "deserves its own category. Self-supervised learning is supervised learning without human-annotated labels—you can think of it as supervised learning without any\n",
        "humans in the loop. There are still labels involved (because the learning has to be\n",
        "supervised by something), but they’re generated from the input data, typically using a\n",
        "heuristic algorithm.\n",
        "\n",
        "\n",
        "For instance, **autoencoders** are a well-known instance of self-supervised learning,\n",
        "where the generated targets are the input, unmodified. In the same way, trying to predict the next frame in a video, given past frames, or the next word in a text, given previous words, are instances of self-supervised learning (**temporally supervised learning**, in this\n",
        "case: supervision comes from future input data). Note that the distinction between\n",
        "supervised, self-supervised, and unsupervised learning can be blurry sometimes—these\n",
        "categories are more of a continuum without solid borders. **Self-supervised learning can\n",
        "be reinterpreted as either supervised or unsupervised learning, depending on whether\n",
        "you pay attention to the learning mechanism or to the context of its application.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy4RbuTn02ou"
      },
      "source": [
        "**NOTE:** \n",
        "\n",
        "In this book, we’ll focus specifically on supervised learning, because\n",
        "it’s by far the dominant form of deep learning today, with a wide range of\n",
        "industry applications. We’ll also take a briefer look at self-supervised learning\n",
        "in later chapters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsOECQby09Op"
      },
      "source": [
        "**Reinforcement learning**\n",
        "\n",
        "Long overlooked, this branch of machine learning recently started to get a lot of\n",
        "attention after Google DeepMind successfully applied it to learning to play Atari\n",
        "games (and, later, learning to play Go at the highest level).\n",
        "In reinforcement learning,\n",
        "an **agent** receives information about its environment and learns to choose actions that\n",
        "will maximize some reward. For instance, a neural network that “looks” at a videogame screen and outputs game actions in order to maximize its score can be trained\n",
        "via reinforcement learning.\n",
        "\n",
        "Currently, reinforcement learning is mostly a research area and hasn’t yet had significant practical successes beyond games. In time, however, we expect to see reinforcement learning take over an increasingly large range of real-world applications:\n",
        "self-driving cars, robotics, resource management, education, and so on. It’s an idea\n",
        "whose time has come, or will come soon. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162QXT-K1SmC"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Classification and regression glossary**</font>\n",
        "***\n",
        "Classification and regression involve many specialized terms. You’ve come across\n",
        "some of them in earlier examples, and you’ll see more of them in future chapters.\n",
        "They have precise, machine-learning-specific definitions, and you should be familiar\n",
        "with them:\n",
        "* **Sample** or **input**—One data point that goes into your model. Samples are drawn from the dataset to create the training and testing sets.\n",
        "\n",
        "* **Training example**—Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples. In supervised learning, each example is a pair consisting of an *input object* or *sample* (typically a vector) and a desired output value (also called the supervisory signal).\n",
        "\n",
        "* **Prediction** or **output**—What comes out of your model.\n",
        "\n",
        "* **Target**—The truth. What your model should ideally have predicted, according\n",
        "to an external source of data.\n",
        "\n",
        "* **Prediction error** or **loss value**—A measure of the distance between your\n",
        "model’s prediction and the target.\n",
        "\n",
        "* **Classes**—A set of possible labels to choose from in a classification problem.\n",
        "For example, when classifying cat and dog pictures, “dog” and “cat” are the\n",
        "two classes.\n",
        "\n",
        "* **Label**—A specific instance of a class annotation in a classification problem.\n",
        "For instance, if picture #1234 is annotated as containing the class “dog,”\n",
        "then “dog” is a label of picture #1234.\n",
        "\n",
        "* **Ground-truth** or **annotations**—All targets for a dataset, typically collected by\n",
        "humans.\n",
        "\n",
        "* **Binary classification**—A classification task where each input sample should\n",
        "be categorized into two exclusive categories.\n",
        "\n",
        "* **Multiclass classification**—A classification task where each input sample\n",
        "should be categorized into more than two categories: for instance, classifying\n",
        "handwritten digits.\n",
        "\n",
        "* **Multilabel classification**—A classification task where each input sample can\n",
        "be assigned multiple labels. For instance, a given image may contain both a\n",
        "cat and a dog and should be annotated both with the “cat” label and the\n",
        "“dog” label. The number of labels per image is usually variable.\n",
        "\n",
        "* **Scalar regression**—A task where the target is a continuous scalar value. Predicting house prices is a good example: the different target prices form a continuous space.\n",
        "\n",
        "* **Vector regression**—A task where the target is a set of continuous values: for\n",
        "example, a continuous vector. If you’re doing regression against multiple values (such as the coordinates of a bounding box in an image), then you’re\n",
        "doing vector regression.\n",
        "\n",
        "* **Mini-batch** or **batch**—A small set of samples (typically between 8 and 128)\n",
        "that are processed simultaneously by the model. The number of samples is\n",
        "often a power of 2, to facilitate memory allocation on GPU. ***When training, a\n",
        "mini-batch is used to compute a single gradient-descent update applied to\n",
        "the weights of the model***. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjI1m8nc6m4G"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Evaluating machine-learning models**</font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfwddVaX7RzF"
      },
      "source": [
        "In the three examples presented in chapter 3, we split the data into a training set, a\n",
        "validation set, and a test set. The reason not to evaluate the models on the same data\n",
        "they were trained on quickly became evident: after just a few epochs, all three models\n",
        "began to **overfit**. **That is, their performance on never-before-seen data started stalling\n",
        "(or worsening) compared to their performance on the training data—which always\n",
        "improves as training progresses.**\n",
        "\n",
        "\n",
        "In machine learning, the goal is to achieve models that generalize—that perform\n",
        "well on never-before-seen data—and overfitting is the central obstacle. You can only\n",
        "control that which you can observe, so it’s crucial to be able to reliably measure the\n",
        "generalization power of your model. The following sections look at strategies for mitigating overfitting and maximizing generalization. **In this section, we’ll focus on how\n",
        "to measure generalization: how to evaluate machine-learning models.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZqRqiWo753l"
      },
      "source": [
        "### **Training, validation, and test sets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB__qZjw8Bf6"
      },
      "source": [
        "Evaluating a model always boils down to splitting the available data into three sets:\n",
        "training, validation, and test. You train on the training data and evaluate your model\n",
        "on the validation data. Once your model is ready for prime time, you test it one final\n",
        "time on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb-Egi-18WAV"
      },
      "source": [
        "You may ask, why not have two sets: a training set and a test set? You’d train on the\n",
        "training data and evaluate on the test data. Much simpler!\n",
        "\n",
        "The reason is that developing a model always involves tuning its configuration: for\n",
        "example, choosing the number of layers or the size of the layers (called the **hyperparameters** of the model, to distinguish them from the **parameters**, which are the **network’s weights**). You do this tuning by using as a ***feedback signal*** the performance of\n",
        "the model on the validation data. In essence, this **tuning** is a form of **learning**: a **search\n",
        "for a good configuration in some parameter space**. As a result, tuning the configuration of the model based on its performance on the validation set can quickly result in\n",
        "**overfitting to the validation set**, even though your model is never directly trained on it.\n",
        "\n",
        "\n",
        "Central to this phenomenon is the notion of **information leaks**. Every time you tune\n",
        "a hyperparameter of your model based on the model’s performance on the validation\n",
        "set, some information about the validation data leaks into the model. If you do this\n",
        "only once, for one parameter, then very few bits of information will leak, and your validation set will remain reliable to evaluate the model. But if you repeat this many\n",
        "times—running one experiment, evaluating on the validation set, and modifying your\n",
        "model as a result—then you’ll leak an increasingly significant amount of information\n",
        "about the validation set into the model.\n",
        "\n",
        "\n",
        "At the end of the day, you’ll end up with a model that performs artificially well on\n",
        "the validation data, because that’s what you optimized it for. You care about performance on completely new data, not the validation data, so you need to use a completely different, never-before-seen dataset to evaluate the model: the test dataset. Your\n",
        "model shouldn’t have had access to any information about the test set, even indirectly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E74SGy_9ikT"
      },
      "source": [
        "If anything about the model has been tuned based on test set performance, then your\n",
        "measure of generalization will be flawed.\n",
        " Splitting your data into training, validation, and test sets may seem straightforward,\n",
        "but there are a few advanced ways to do it that can come in handy when little data is\n",
        "available. Let’s review three classic evaluation recipes: simple **hold-out validation**, **Kfold validation**, and **iterated K-fold validation with shuffling**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2UMZU1394b4"
      },
      "source": [
        "#### ***SIMPLE HOLD-OUT VALIDATION***\n",
        "Set apart some fraction of your data as your test set. Train on the remaining data, and\n",
        "evaluate on the test set. As you saw in the previous sections, in order to prevent information leaks, you shouldn’t tune your model based on the test set, and therefore you\n",
        "should **also** reserve a validation set.\n",
        "\n",
        "\n",
        "Once you’ve tuned your\n",
        "hyperparameters, it’s common to\n",
        "train your final model from scratch\n",
        "on all non-test data available.\n",
        "\n",
        "\n",
        "This is the simplest evaluation protocol, and it suffers from one flaw: if little data is\n",
        "available, then your validation and test sets may contain too few samples to be statistically representative of the data at hand. This is easy to recognize: if different random\n",
        "shuffling rounds of the data before splitting end up yielding very different measures\n",
        "of model performance, then you’re having this issue. K-fold validation and iterated\n",
        "K-fold validation are two ways to address this, as discussed next. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Bi-2k_-WKz"
      },
      "source": [
        "#### ***K-FOLD VALIDATION***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om55a6Ls-dgY"
      },
      "source": [
        "With this approach, you split your data into K partitions of equal size. For each partition i, train a model on the remaining K – 1 partitions, and evaluate it on partition i.\n",
        "Your final score is then the averages of the K scores obtained. This method is helpful\n",
        "when the performance of your model shows significant variance based on your traintest split. Like hold-out validation, this method doesn’t exempt you from using a distinct validation set for model calibration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsG0ACbb-wnq"
      },
      "source": [
        "#### ***ITERATED K-FOLD VALIDATION WITH SHUFFLING***\n",
        "This one is for situations in which you have relatively little data available and you need\n",
        "to evaluate your model as precisely as possible. I’ve found it to be extremely helpful in\n",
        "Kaggle competitions. It consists of applying K-fold validation multiple times, shuffling\n",
        "the data every time before splitting it K ways. The final score is the average of the\n",
        "scores obtained at each run of K-fold validation. Note that you end up training and\n",
        "evaluating P × K models (where P is the number of iterations you use), which can very\n",
        "expensive. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWvIGMJT_AiR"
      },
      "source": [
        "### **Things to keep in mind**\n",
        "Keep an eye out for the following when you’re choosing an evaluation protocol:\n",
        "* **Data representativeness**—You want both your training set and test set to be representative of the data at hand. For instance, if you’re trying to classify images of\n",
        "digits, and you’re starting from an array of samples where the samples are\n",
        "ordered by their class, taking the first 80% of the array as your training set and\n",
        "the remaining 20% as your test set will result in your training set containing\n",
        "only classes 0–7, whereas your test set contains only classes 8–9. This seems like\n",
        "a ridiculous mistake, but it’s surprisingly common. For this reason, you usually\n",
        "should **randomly shuffle your data before splitting it** into training and test sets.\n",
        "\n",
        "* **The arrow of time**—If you’re trying to predict the future given the past (for example, tomorrow’s weather, stock movements, and so on), you should not randomly shuffle your data before splitting it, because doing so will create a\n",
        "temporal leak: your model will effectively be trained on data from the future. In\n",
        "such situations, **you should always make sure all data in your test set is posterior\n",
        "to the data in the training set**.\n",
        "\n",
        "* **Redundancy in your data**—If some data points in your data appear twice (fairly\n",
        "common with real-world data), then shuffling the data and splitting it into a\n",
        "training set and a validation set will result in redundancy between the training\n",
        "and validation sets. In effect, you’ll be testing on part of your training data,\n",
        "which is the worst thing you can do! **Make sure your training set and validation\n",
        "set are disjoint.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEH7AT9A_2ko"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Data preprocessing, feature engineering, and feature learning**</font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnzuv27P_9Gd"
      },
      "source": [
        "### **Data preprocessing for neural networks**\n",
        "\n",
        "\n",
        "Data preprocessing aims at making the raw data at hand more amenable to neural\n",
        "networks. This includes **vectorization, normalization, handling missing values, and\n",
        "feature extraction**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obmWY6vHAOaw"
      },
      "source": [
        "#### *VECTORIZATION*\n",
        "All inputs and targets in a neural network must be tensors of floating-point data (or, in\n",
        "specific cases, tensors of integers). Whatever data you need to process—sound,\n",
        "images, text—you must first turn into tensors, a step called **data vectorization**. For\n",
        "instance, in the two previous text-classification examples, we started from text represented as lists of integers (standing for sequences of words), and we used one-hot\n",
        "encoding to turn them into a tensor of float32 data. In the examples of classifying\n",
        "digits and predicting house prices, the data already came in vectorized form, so you\n",
        "were able to skip this step. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrOtht30ARkD"
      },
      "source": [
        "#### *VALUE NORMALIZATION*\n",
        "\n",
        "In the digit-classification example, you started from image data encoded as integers in\n",
        "the 0–255 range, encoding grayscale values. Before you fed this data into your network, you had to cast it to float32 and divide by 255 so you’d end up with floatingpoint values in the 0–1 range. Similarly, when predicting house prices, you started\n",
        "from features that took a variety of ranges—some features had small floating-point values, others had fairly large integer values. Before you fed this data into your network,\n",
        "you had to normalize each feature independently so that it had a standard deviation\n",
        "of 1 and a mean of 0.\n",
        "\n",
        "\n",
        "In general, **it isn’t safe to feed into a neural network data that takes relatively large values** (for example, multidigit integers, which are much larger than the initial values taken\n",
        "by the weights of a network) or data that is heterogeneous (for example, data where one\n",
        "feature is in the range 0–1 and another is in the range 100–200). **Doing so can trigger\n",
        "large gradient updates that will prevent the network from converging**. To make learning\n",
        "easier for your network, your data should have the following characteristics:\n",
        "\n",
        "* Take small values—Typically, most values should be in the 0–1 range.\n",
        "* Be homogenous—That is, all features should take values in roughly the same\n",
        "range.\n",
        "\n",
        "\n",
        "Additionally, the following stricter normalization practice is common and can help,\n",
        "although it isn’t always necessary (for example, you didn’t do this in the digit-classification\n",
        "example):\n",
        "* Normalize each feature independently to have a mean of 0.\n",
        "* Normalize each feature independently to have a standard deviation of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuCOCAHHxAXX"
      },
      "source": [
        "# # This is easy to do with Numpy arrays\n",
        "\n",
        "x -= x.mean(axis=0) # Assuming x is a 2D data matrix of shape (samples, features) \n",
        "x /= x.std(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F60yGydYBlXu"
      },
      "source": [
        "#### *HANDLING MISSING VALUES*\n",
        "You may sometimes have missing values in your data. For instance, in the house-price\n",
        "example, the first feature (the column of index 0 in the data) was the per capita crime\n",
        "rate. What if this feature wasn’t available for all samples? You’d then have missing values in the training or test data.\n",
        "\n",
        " In general, with neural networks, it’s safe to input missing values as 0, with the condition that 0 isn’t already a meaningful value. The network will learn from exposure to\n",
        "the data that the value 0 means missing data and will start ignoring the value.\n",
        "\n",
        " Note that if you’re expecting missing values in the test data, but the network was\n",
        "trained on data without any missing values, the network won’t have learned to ignore\n",
        "missing values! In this situation, you should artificially generate training samples with\n",
        "missing entries: copy some training samples several times, and drop some of the features that you expect are likely to be missing in the test data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9H7iQLRB_W1"
      },
      "source": [
        "### **Feature engineering**\n",
        "Feature engineering is the process of using your own knowledge about the data and about\n",
        "the machine-learning algorithm at hand (in this case, a neural network) to make the\n",
        "algorithm work better by applying\n",
        "hardcoded (nonlearned) transformations to the data before it goes\n",
        "into the model. In many cases, it isn’t\n",
        "reasonable to expect a machinelearning model to be able to learn\n",
        "from completely arbitrary data. The\n",
        "data needs to be presented to the\n",
        "model in a way that will make the\n",
        "model’s job easier.\n",
        "\n",
        "\n",
        "\n",
        "Feature engineering: making a problem easier by expressing\n",
        "it in a simpler way. It usually requires understanding the problem in depth.\n",
        "\n",
        "Before deep learning, feature engineering used to be critical, because classical\n",
        "shallow algorithms didn’t have hypothesis spaces rich enough to learn useful features\n",
        "by themselves. The way you presented the data to the algorithm was essential to its success. For instance, before convolutional neural networks became successful on the\n",
        "MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an\n",
        "image, a histogram of pixel values, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFrz6pmQCz7r"
      },
      "source": [
        "Fortunately, modern deep learning removes the need for most feature engineering, because neural networks are capable of automatically extracting useful features\n",
        "from raw data. Does this mean you don’t have to worry about feature engineering as\n",
        "long as you’re using deep neural networks? No, for two reasons:\n",
        "\n",
        "* Good features still allow you to solve problems more elegantly while using fewer\n",
        "resources. For instance, it would be ridiculous to solve the problem of reading a\n",
        "clock face using a convolutional neural network.\n",
        "* Good features let you solve a problem with far less data. The ability of deep learning models to learn features on their own relies on having lots of training\n",
        "data available; if you have only a few samples, then the information value in\n",
        "their features becomes critical. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARB4At0NDF5P"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Overfitting and underfitting**</font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1ANlVerDHnR"
      },
      "source": [
        "The fundamental issue in machine learning is the tension between optimization\n",
        "and generalization. **Optimization** refers to the process of adjusting a model to get the\n",
        "best performance possible on the training data (the learning in machine learning),\n",
        "whereas **generalization** refers to how well the trained model performs on data it has\n",
        "never seen before. The goal of the game is to get good generalization, of course, but\n",
        "you don’t control generalization; you can only adjust the model based on its training\n",
        "data.\n",
        "\n",
        "At the beginning of training, optimization and generalization are correlated: the\n",
        "lower the loss on training data, the lower the loss on test data. While this is happening,\n",
        "your model is said to be underfit: there is still progress to be made; the network hasn’t\n",
        "yet modeled all relevant patterns in the training data. But after a certain number of\n",
        "iterations on the training data, generalization stops improving, and validation metrics\n",
        "stall and then begin to degrade: the model is starting to **overfit**. That is, it’s **beginning\n",
        "to learn patterns that are specific to the training data but that are misleading or irrelevant when it comes to new data**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_N2HJ8bDp23"
      },
      "source": [
        "To prevent a model from learning misleading or irrelevant patterns found in the\n",
        "training data, the **best solution is to get more training data**. A model trained on more data\n",
        "will naturally generalize better. When that isn’t possible, the next-best solution is to\n",
        "**modulate the quantity of information that your model is allowed to store or to add\n",
        "constraints on what information it’s allowed to store**. If a network can only afford to\n",
        "memorize a small number of patterns, the optimization process will force it to focus\n",
        "on the most prominent patterns, which have a better chance of generalizing well.\n",
        "\n",
        "The processing of fighting overfitting this way is called **regularization**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4URUVpEVEYwr"
      },
      "source": [
        "#### **Reducing the network’s size**\n",
        "\n",
        "The simplest way to prevent overfitting is to reduce the size of the model: the number\n",
        "of learnable parameters in the model (which is determined by the number of layers\n",
        "and the number of units per layer). In deep learning, the number of learnable parameters in a model is often referred to as the model’s **capacity**. Intuitively, a model with\n",
        "more parameters has more **memorization capacity** and therefore can easily learn a perfect dictionary-like mapping between training samples and their targets—a mapping\n",
        "without any generalization power.\n",
        "\n",
        " For instance, a model with 500,000 binary parameters could easily be made to learn the class of every digit in the MNIST training set.\n",
        "\n",
        "\n",
        "If the network has limited memorization resources, it won’t be\n",
        "able to learn this mapping as easily; thus, in order to minimize its loss, it will have to\n",
        "resort to learning compressed representations that have predictive power regarding\n",
        "the targets—precisely the type of representations we’re interested in. At the same\n",
        "time, keep in mind that you should use models that have enough parameters that they\n",
        "don’t underfit: your model shouldn’t be starved for memorization resources. There is\n",
        "a compromise to be found between too much capacity and not enough capacity.\n",
        "\n",
        "\n",
        "Unfortunately, there is no magical formula to determine the right number of layers or the right size for each layer. You must evaluate an array of different architectures (on your validation set, not on your test set, of course) in order to find the\n",
        "correct model size for your data. The general workflow to find an appropriate model\n",
        "size is to **start with relatively few layers and parameters, and increase the size of the layers or add new layers until you see diminishing returns with regard to validation loss**.\n",
        "\n",
        "The more **capacity**\n",
        "the network has, the more quickly it can model the training data (resulting in a low\n",
        "training loss), but the more susceptible it is to overfitting (resulting in a large difference between the training and validation loss). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRXxni7rGfBr"
      },
      "source": [
        "#### **Adding weight regularization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePBRp9qgGnWP"
      },
      "source": [
        "You may be familiar with the principle of ***Occam’s razor***: given two explanations for\n",
        "something, the explanation most likely to be correct is the simplest one—the one that\n",
        "makes fewer assumptions. This idea also applies to the models learned by neural networks: given some training data and a network architecture, multiple sets of weight\n",
        "values (multiple models) could explain the data. Simpler models are less likely to overfit than complex ones.\n",
        "\n",
        "A ***simple model*** in this context is a model where the **distribution of parameter values\n",
        "has less entropy** (or a model with fewer parameters, as you saw in the previous section). Thus a common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights to take only small values, which makes the\n",
        "distribution of weight values more regular. This is called **weight regularization**, and it’s\n",
        "done by adding to the loss function of the network a ***cost*** associated with having large\n",
        "weights. This cost comes in two flavors:\n",
        "\n",
        "* ***L1 regularization***—The cost added is proportional to the absolute value of the\n",
        "weight coefficients (the L1 norm of the weights).\n",
        "* ***L2 regularization***—The cost added is proportional to the square of the value of the\n",
        "weight coefficients (the L2 norm of the weights). L2 regularization is also called **weight decay** in the context of neural networks. Don’t let the different name confuse you: weight decay is mathematically the same as L2 regularization.\n",
        "\n",
        "In Keras, weight regularization is added by passing **weight regularizer instances** to layers\n",
        "as keyword arguments. Let’s add L2 weight regularization to the movie-review classification network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUR2ttCCBfyk"
      },
      "source": [
        "# L2 regularization/weight decay\n",
        "from keras import regularizers\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
        "                       activation='relu', input_shape=(10000,)))\n",
        "\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
        "                       activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7yWPwbDIlDC"
      },
      "source": [
        "l2(0.001) means every coefficient in the weight matrix of the layer will add 0.001 *\n",
        "weight_coefficient_value to the total loss of the network. Note that because this\n",
        "penalty is only added at training time, the loss for this network will be much higher at\n",
        "training than at test time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ynCwIL1JYVX"
      },
      "source": [
        "#### **Adding dropout**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYNCdmI9JgBG"
      },
      "source": [
        "***Dropout*** is one of the most effective and most commonly used regularization techniques for neural networks, developed by Geoff Hinton (backprop paper) and his students at the University of Toronto. \n",
        "\n",
        "Dropout, applied to a layer, consists of randomly dropping out\n",
        "(setting to zero) a number of output features of the layer during training. Let’s say a\n",
        "given layer would normally return a vector [0.2, 0.5, 1.3, 0.8, 1.1] for a given input\n",
        "sample during training. After applying dropout, this vector will have a few zero entries\n",
        "distributed at random: for example, [0, 0.5, 1.3, 0, 1.1]. The dropout rate is the fraction\n",
        "of the features that are zeroed out; it’s usually set between 0.2 and 0.5. At test time, no\n",
        "units are dropped out; instead, the layer’s output values are scaled down by a factor\n",
        "equal to the dropout rate, to balance for the fact that more units are active than at\n",
        "training time.\n",
        "\n",
        "Consider a Numpy matrix containing the output of a layer, layer_output, of\n",
        "shape (batch_size, features). At training time, we zero out at random a fraction of\n",
        "the values in the matrix:\n",
        "\n",
        "\n",
        "*layer_output *= np.random.randint(0, high=2, size=layer_output.shape)*<br><br>\n",
        "\n",
        "\n",
        "\n",
        "At test time, we scale down the output by the dropout rate. Here, we scale by 0.5\n",
        "(because we previously dropped half the units):\n",
        "\n",
        "\n",
        "*layer_output *= 0.5*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7FkyItoKobZ"
      },
      "source": [
        "Note that this process can be implemented by doing both operations at training time\n",
        "and leaving the output unchanged at test time, which is often the way it’s implemented in practice (see figure 4.8):\n",
        "\n",
        "\n",
        "*layer_output *= np.random.randint(0, high=2, size=layer_output.shape)*\n",
        "\n",
        "\n",
        "*layer_output /= 0.5* # scaling up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UmNmf1fLJyH"
      },
      "source": [
        "Randomly removing a different\n",
        "subset of neurons on each example would prevent conspiracies and thus reduce overfitting.\n",
        "\n",
        " The core idea is that introducing noise in the output values of a layer can\n",
        "break up happenstance patterns that aren’t significant (what Hinton refers to as conspiracies), which the network will start memorizing if no noise is present.\n",
        "\n",
        " In Keras, you can introduce dropout in a network via the Dropout layer, **which is\n",
        "applied to the output of the layer right before it:**\n",
        "\n",
        "*model.add(layers.Dropout(0.5))*\n",
        "\n",
        "Let’s add two Dropout layers in the IMDB network to see how well they do at reducing\n",
        "overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFu2-BKVISGq"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbhd3bpmMA3B"
      },
      "source": [
        "#### **Recap**\n",
        "\n",
        "To recap, these are the most common ways to prevent overfitting in neural networks:\n",
        "* Get more training data.\n",
        "* Reduce the capacity of the network.\n",
        "* Add weight regularization.\n",
        "* Add dropout. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSRG28MUNEfN"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**The universal workflow of machine learning**</font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwrH1EgkLfg9"
      },
      "source": [
        "Keep in mind that machine learning can only be used to memorize patterns that\n",
        "are present in your training data. You can only recognize what you’ve seen before.\n",
        "Using machine learning trained on past data to predict the future is making the\n",
        "assumption that the future will behave like the past. That often isn’t the case.<br><br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1. **Defining the problem and assembling a dataset**\n",
        "    - What will your input data be? What are you trying to predict? You can only learn\n",
        "to predict something if you have available training data: for example, you can\n",
        "only learn to classify the sentiment of movie reviews if you have both movie\n",
        "reviews and sentiment annotations available. As such, data availability is usually\n",
        "the limiting factor at this stage (unless you have the means to pay people to collect data for you).\n",
        "    - What type of problem are you facing? Is it binary classification? Multiclass classification? Scalar regression? Vector regression? Multiclass, multilabel classification? Something else, like clustering, generation, or reinforcement learning?\n",
        "Identifying the problem type will guide your choice of model architecture, loss\n",
        "function, and so on.\n",
        "    - You hypothesize that your outputs can be predicted given your inputs.\n",
        "    - You hypothesize that your available data is sufficiently informative to learn the\n",
        "relationship between inputs and outputs. \n",
        "\n",
        " One class of unsolvable problems you should be aware of is nonstationary problems.\n",
        "Suppose you’re trying to build a recommendation engine for clothing, you’re training\n",
        "it on one month of data (August), and you want to start generating recommendations\n",
        "in the winter. One big issue is that the kinds of clothes people buy change from season\n",
        "to season: clothes buying is a nonstationary phenomenon over the scale of a few\n",
        "months. What you’re trying to model changes over time. In this case, the right move is\n",
        "to constantly retrain your model on data from the recent past, or gather data at a\n",
        "timescale where the problem is stationary. For a cyclical problem like clothes buying, a\n",
        "few years’ worth of data will suffice to capture seasonal variation—but remember to\n",
        "make the time of the year an input of your model!<br>\n",
        "\n",
        "\n",
        "\n",
        "2. **Choosing a measure of success**<br>\n",
        "    * To control something, you need to be able to observe it. To achieve success, you must\n",
        "define what you mean by success—accuracy? Precision and recall? Customer-retention\n",
        "rate? **Your metric for success will guide the choice of a loss function**: what your model\n",
        "will optimize. It should directly align with your higher-level goals, such as the success\n",
        "of your business. \n",
        "\n",
        "    * For *balanced-classification* problems, where every class is equally likely, **accuracy** and **area under the receiver operating characteristic curve (ROC AUC)** are common metrics. For *class-imbalanced problems*, you can use **precision and recall**. For *ranking problems* or *multilabel classification*, you can use **mean average precision**. And it isn’t uncommon\n",
        "to have to define your own **custom metric** by which to measure success. To get a sense\n",
        "of the diversity of machine-learning success metrics and how they relate to different\n",
        "problem domains, it’s helpful to browse the data science competitions on Kaggle\n",
        "(https://kaggle.com); they showcase a wide range of problems and evaluation metrics.<br> \n",
        "\n",
        "\n",
        "\n",
        "3. **Deciding on an evaluation protocol**<br>\n",
        "Once you know what you’re aiming for, you must establish how you’ll measure your\n",
        "current progress. We’ve previously reviewed three common evaluation protocols:\n",
        "    * Maintaining a hold-out validation set—The way to go when you have plenty of\n",
        "data\n",
        "    * Doing K-fold cross-validation—The right choice when you have too few samples\n",
        "for hold-out validation to be reliable\n",
        "    * Doing iterated K-fold validation—For performing highly accurate model evaluation when little data is available\n",
        "Just pick one of these. In most cases, the first will work well enough. \n",
        "\n",
        "\n",
        "4.  **Preparing your data**\n",
        "    * As you saw previously, your data should be formatted as tensors.\n",
        "    * The values taken by these tensors should usually be scaled to small values: for\n",
        "example, in the [-1, 1] range or [0, 1] range.\n",
        "    * If different features take values in different ranges (heterogeneous data), then\n",
        "the data should be normalized.\n",
        "    * You may want to do some feature engineering, especially for small-data problems.\n",
        "\n",
        " Once your tensors of input data and target data are ready, you can begin to train models. \n",
        "\n",
        "\n",
        "5. **Developing a model that does better than a baseline**\n",
        "\n",
        " Your goal at this stage is to achieve ***statistical power***: that is, to develop a small model\n",
        "that is capable of beating a dumb baseline. In the MNIST digit-classification example,\n",
        "anything that achieves an accuracy greater than 0.1 can be said to have statistical\n",
        "power; in the IMDB example, it’s anything with an accuracy greater than 0.5.\n",
        "\n",
        " **Note that it’s not always possible to achieve statistical power. If you can’t beat a random baseline after trying multiple reasonable architectures, it may be that the answer\n",
        "to the question you’re asking isn’t present in the input data.** Remember that you make\n",
        "two hypotheses:\n",
        "    * You hypothesize that your outputs can be predicted given your inputs.\n",
        "    * You hypothesize that the available data is sufficiently informative to learn the\n",
        "relationship between inputs and outputs.\n",
        "It may well be that these hypotheses are false, in which case you must go back to the\n",
        "drawing board.\n",
        "\n",
        " Assuming that things go well, you need to make **three key choices** to build your\n",
        "first working model:\n",
        "* **Last-layer activation**—This establishes useful constraints on the network’s output. For instance, the IMDB classification example used sigmoid in the last\n",
        "layer; the regression example didn’t use any last-layer activation; and so on.\n",
        "* **Loss function**—This should match the type of problem you’re trying to solve. For\n",
        "instance, the IMDB example used binary_crossentropy, the regression example used mse, and so on.\n",
        "* **Optimization configuration**—What optimizer will you use? What will its learning\n",
        "rate be? In most cases, it’s safe to go with rmsprop and its default learning rate.\n",
        "\n",
        " Regarding the choice of a loss function, **note that it isn’t always possible to directly\n",
        "optimize for the metric that measures success on a problem. Sometimes there is no\n",
        "easy way to turn a metric into a loss function**; loss functions, after all, need to be computable given only a mini-batch of data (ideally, a loss function should be computable\n",
        "for as little as a single data point) and must be differentiable (otherwise, you can’t use\n",
        "backpropagation to train your network). For instance, the widely used classification\n",
        "metric ROC AUC can’t be directly optimized. Hence, in classification tasks, it’s common to optimize for a proxy metric of ROC AUC, such as crossentropy. In general, you\n",
        "can hope that the lower the crossentropy gets, the higher the ROC AUC will be.\n",
        "\n",
        " Choosing the right last-layer activation and loss function for your model:\n",
        "\n",
        " <img src=\"https://drive.google.com/uc?id=1jqJIJhtPTSKMPHyhIwr3RB9LynzF9ieo\"></img><br>\n",
        " \n",
        "\n",
        "\n",
        "6. **Scaling up: developing a model that overfits**\n",
        "\n",
        " Remember that the universal tension in machine learning is between\n",
        "optimization and generalization; the ideal model is one that stands right at the border\n",
        "between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
        "\n",
        " To figure out how big a model you’ll need, you must develop a model that overfits.\n",
        "This is fairly easy:\n",
        "\n",
        "    1. Add layers.<br>\n",
        "    2. Make the layers bigger.<br>\n",
        "    3. Train for more epochs.<br>\n",
        "    \n",
        " Always **monitor the training loss and validation loss, as well as the training and validation values for any metrics you care about**. **When you see that the model’s performance on the validation data begins to degrade, you’ve achieved overfitting**.\n",
        "\n",
        " The next stage is to **start regularizing and tuning the model**, to get as close as possible to the ideal model that neither underfits nor overfits. \n",
        "\n",
        "\n",
        "\n",
        "7. **Regularizing your model and tuning your hyperparameters**\n",
        "\n",
        " This step will take the most time: you’ll repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and\n",
        "repeat, until the model is as good as it can get. These are some things you should try:\n",
        "\n",
        "    * Add dropout.\n",
        "    * Try different architectures: add or remove layers.\n",
        "    * Add L1 and/or L2 regularization.\n",
        "    * Try different hyperparameters (such as the number of units per layer or the\n",
        "learning rate of the optimizer) to find the optimal configuration.\n",
        "    * Optionally, iterate on feature engineering: add new features, or remove features that don’t seem to be informative.\n",
        "\n",
        " Be mindful of the following: every time you use feedback from your validation process\n",
        "to tune your model, you leak information about the validation process into the model.\n",
        "Repeated just a few times, this is innocuous; but done systematically over many iterations, it will eventually cause your model to overfit to the validation process (even\n",
        "though no model is directly trained on any of the validation data). This makes the\n",
        "evaluation process less reliable.\n",
        "\n",
        " Once you’ve developed a satisfactory model configuration, you can train your final\n",
        "production model on all the available data (training and validation) and evaluate it\n",
        "one last time on the test set. If it turns out that performance on the test set is significantly worse than the performance measured on the validation data, this may mean\n",
        "either that your validation procedure wasn’t reliable after all, or that you began overfitting to the validation data while tuning the parameters of the model. In this case,\n",
        "you may want to switch to a more reliable evaluation protocol (such as iterated K-fold\n",
        "validation). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LWJH8l_X4A9"
      },
      "source": [
        "### **Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZny1fN6gqq8"
      },
      "source": [
        "1. Define the problem at hand and the data on which you’ll train. Collect\n",
        "this data, or annotate it with labels if need be.\n",
        "\n",
        "2. Choose how you’ll measure success on your problem. Which metrics will\n",
        "you monitor on your validation data?\n",
        "\n",
        "3. Determine your evaluation protocol: hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
        "\n",
        "4. Develop a first model that does better than a basic baseline: a model with\n",
        "statistical power.\n",
        "\n",
        "5. Develop a model that overfits.\n",
        "\n",
        "6. Regularize your model and tune its hyperparameters, based on performance on the validation data. A lot of machine-learning research tends to\n",
        "focus only on this step—but keep the big picture in mind."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20I9wmNzi2jV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMqzZmndi2tX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7UWMNbmi0jr"
      },
      "source": [
        "# <font color=\"Orange\">**Deep learning for text and sequences**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3FZHArPi98q"
      },
      "source": [
        "This chapter covers:\n",
        "* *Preprocessing* text data into **useful\n",
        "representations**\n",
        "* Working with **recurrent neural networks**\n",
        "* Using **1D convnets** for sequence processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfmmTH68i1cj"
      },
      "source": [
        "This chapter explores deep-learning models that can process text (understood as\n",
        "sequences of word or sequences of characters), timeseries, and sequence data in\n",
        "general. \n",
        "The two fundamental deep-learning algorithms for **sequence processing**\n",
        "are ***recurrent neural networks*** and ***1D convnets***, the one-dimensional version of the 2D\n",
        "convnets that we covered in the previous chapters. We’ll discuss both of these\n",
        "approaches in this chapter.\n",
        "\n",
        " Applications of these algorithms include the following:\n",
        "* **Document classification** and **timeseries classification**, such as identifying the\n",
        "topic of an article or the author of a book.\n",
        "\n",
        "* **Timeseries comparisons**, such as estimating how closely related two documents or two stock tickers are.\n",
        "\n",
        "* **Sequence-to-sequence learning**, such as decoding an English sentence into\n",
        "French\n",
        "\n",
        "* **Sentiment analysis**, such as classifying the sentiment of tweets or movie reviews\n",
        "as positive or negative\n",
        "\n",
        "* **Timeseries forecasting**, such as predicting the future weather at a certain location, given recent weather data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNq29Eerlt-k"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Working with text data**</font>\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI3t3bY3mPMs"
      },
      "source": [
        "Text is one of the most widespread forms of ***sequence data***. It can be understood as\n",
        "either a **sequence of characters** or a **sequence of words**, but it’s most common to work\n",
        "at the level of words. \n",
        "\n",
        "\n",
        "Like all other neural networks, deep-learning models don’t take as input raw text:\n",
        "they only work with **numeric tensors**. \n",
        "\n",
        "**Vectorizing text** is the ***process of transforming text\n",
        "into numeric tensors***. This can be done in multiple ways:\n",
        "* Segment text into words (tokenizing), and transform each word into a vector.\n",
        "\n",
        "* Segment text into characters (tokenizing), and transform each character into a vector.\n",
        "\n",
        "* Extract n-grams of words or characters (tokenizing), and transform each n-gram into a vector.\n",
        "N-grams are overlapping groups of multiple consecutive words or characters.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOlov6YdwJwa"
      },
      "source": [
        "### **Tokenization**\n",
        "\n",
        "Collectively, the different **units** into which you can break down text (words, characters, or n-grams) are called ***tokens***, and breaking text into such tokens is called ***tokenization***. \n",
        "\n",
        "All **text-vectorization** processes consist of applying some ***tokenization scheme*** and\n",
        "then associating ***numeric vectors*** with the ***generated tokens***. These vectors, packed\n",
        "into **sequence tensors** - 3D tensors of shape *(samples, timesteps,\n",
        "features)*, are fed into deep neural networks. **Each sample will be vectorized into a <ins>sequence</ins> of letters, characters, or n-grams**.\n",
        "\n",
        "There are multiple ways to\n",
        "**associate a vector with a token**. In this section, I’ll present two major ones: \n",
        "* ***one-hot\n",
        "encoding of tokens***<br>\n",
        "\n",
        "* ***token embedding*** (typically used exclusively for words, and called **word embedding**). \n",
        "\n",
        "The remainder of this section explains these techniques and shows\n",
        "how to use them to go from raw text to a Numpy tensor that you can send to a Keras\n",
        "network.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0dxsnTZnz-e"
      },
      "source": [
        "**<ins>Vectorization process visualized</ins>**<br>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1S6ux_kP7u_F95sSGI6ZpNx5BhVRuSmUw\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUPQVyDypiqO"
      },
      "source": [
        "### **Understanding n-grams and bag-of-words**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTL0W-PZpn9Z"
      },
      "source": [
        "**Word n-grams** are groups of *N* (or fewer) consecutive words that you can extract from\n",
        "a sentence. The same concept may also be applied to characters instead of words.\n",
        "\n",
        "Here’s a simple example. Consider the sentence “The cat sat on the mat.” It may be\n",
        "decomposed into the following set of 2-grams:\n",
        "\n",
        "`{\"The\", \"The cat\", \"cat\", \"cat sat\", \"sat\",\n",
        "\"sat on\", \"on\", \"on the\", \"the\", \"the mat\", \"mat\"}`\n",
        "\n",
        "It may also be decomposed into the following set of 3-grams:\n",
        "\n",
        "`{\"The\", \"The cat\", \"cat\", \"cat sat\", \"The cat sat\",\n",
        "\"sat\", \"sat on\", \"on\", \"cat sat on\", \"on the\", \"the\",\n",
        "\"sat on the\", \"the mat\", \"mat\", \"on the mat\"}`<br><br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Such a set is called a bag-of-2-grams or bag-of-3-grams, respectively. The term **bag**\n",
        "here refers to the fact that you’re ***dealing with a set of tokens rather than a list or\n",
        "sequence***: the tokens have no specific order. This family of tokenization methods is\n",
        "called **bag-of-words**.\n",
        "\n",
        "\n",
        "Because bag-of-words isn’t an order-preserving tokenization method (the tokens generated are understood as a set, not a sequence, and the general structure of the sentences is lost), it tends to be used in shallow language-processing models rather than\n",
        "in deep-learning models. \n",
        "\n",
        "Extracting n-grams is a form of feature engineering, and\n",
        "deep learning does away with this kind of rigid, brittle approach, replacing it with hierarchical feature learning.\n",
        "\n",
        "\n",
        "**One-dimensional convnets** and **recurrent neural networks**,\n",
        "introduced later in this chapter, are ***capable of learning representations for groups of\n",
        "words and characters without being explicitly told about the existence of such groups,\n",
        "by looking at continuous word or character sequences***. For this reason, we won’t\n",
        "cover **n-grams** any further in this book. But do keep in mind that they’re a powerful,\n",
        "unavoidable feature-engineering tool when using lightweight, ***shallow text-processing\n",
        "models*** such as **logistic regression** and **random forests**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPH9sOpvre6j"
      },
      "source": [
        "### **One-hot encoding of words and characters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wiv_ECu2rlSB"
      },
      "source": [
        "**One-hot encoding** is the most common, **most basic way to turn a token into a vector**.\n",
        "You saw it in action in the initial *IMDB* and *Reuters* examples in chapter 3 (done with\n",
        "words, in that case). It consists of **associating a unique integer index with every word\n",
        "and then turning this integer index i into a binary vector of size N (the size of the\n",
        "vocabulary); the vector is all zeros except for the ith entry, which is 1 (one-hot encoding).**\n",
        "\n",
        " Of course, **one-hot encoding** can be done at the **character level**, as well. To unambiguously drive home what one-hot encoding is and how to implement it, let us show two toy examples: one for words, the other for characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2SmAdNHsVmB"
      },
      "source": [
        "<ins>**Word-level one-hot encoding example**<ins><br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vihFtklvo-5J"
      },
      "source": [
        "# Word-level one-hot encoding (toy example)\n",
        "import numpy as np\n",
        "\n",
        "# Initial data: one entry per sample \n",
        "# (in this example, a sample is a sentence, but it could be an entire document)\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "# Builds an index of all tokens (words) in the data\n",
        "token_index = {}\n",
        "for sample in samples:\n",
        "    # Tokenizes the samples via the split method. \n",
        "    # In real life, you’d also strip punctuation and special characters from the samples\n",
        "    for word in sample.split():\n",
        "        if word not in token_index:\n",
        "            # Assigns a unique index to each unique word. Note that you don’t attribute index 0 to anything\n",
        "            token_index[word] = len(token_index) + 1\n",
        "\n",
        "\n",
        "# Vectorizes the samples \n",
        "# Packs into sequence tensors - 3D tensors of shape (samples, timesteps, features)\n",
        "max_length = 10 # time/sequence order is second axis\n",
        "\n",
        "# This is where you store the results.\n",
        "# + 1 because index 0 is ignored\n",
        "results = np.zeros(shape=(len(samples),\n",
        "                          max_length,\n",
        "                          max(token_index.values()) + 1))\n",
        "\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "        index = token_index.get(word)\n",
        "        results[i, j, index] = 1. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN2_WXphu7Of"
      },
      "source": [
        "<ins>**Character-level one-hot encoding example**</ins><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcQrEaGm4y5F"
      },
      "source": [
        "#  Character-level one-hot encoding (toy example)\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "# tokenize\n",
        "characters = string.printable # All printable ASCII characters\n",
        "token_index = dict(zip(range(1, len(characters) + 1), characters))\n",
        "\n",
        "max_length = 50 # time/sequence order axis dimension\n",
        "\n",
        "# if for 100 chars, want 101 dimension size for feature axis (index 0 ignored)\n",
        "results = np.zeros((len(samples), max_length, max(token_index.keys()) + 1))\n",
        "\n",
        "# vectorize samples into one 3D tensor ready for deep neural network input\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, character in enumerate(sample):\n",
        "        index = token_index.get(character)\n",
        "        results[i, j, index] = 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeyn6cZq6YF9",
        "outputId": "bab2c53f-02c4-4d3f-8522-fbc932edb7ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(characters))\n",
        "print(len(token_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qwSyR7Qu50-"
      },
      "source": [
        "Note that *Keras* has built-in utilities for doing **one-hot encoding** of text at the <ins>word level</ins>\n",
        "or <ins>character level</ins>, starting from raw text data. You should use these utilities, because\n",
        "they take care of a number of important features such as stripping special characters\n",
        "from strings and only taking into account the N most common words in your dataset (a\n",
        "common restriction, to avoid dealing with very large input vector spaces)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYI90pvYxoSX"
      },
      "source": [
        "<ins>**Using Keras for word-level one-hot encoding**</ins><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Luj-cTygMyCK",
        "outputId": "9b851cf5-0965-4e02-ae71-036458f8d1c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "# Creates a tokenizer, configured to only take into account the 1,000 most common words\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "# Builds the word index\n",
        "tokenizer.fit_on_texts(samples)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(samples) # Turns strings into lists of integer indices\n",
        "\n",
        "# You could also directly get the one-hot binary representations.\n",
        "# Vectorization modes other than one-hot encoding are supported by this tokenizer.\n",
        "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
        "\n",
        "word_index = tokenizer.word_index # How you can recover the word index that was computed\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNro7HMXxy_P",
        "outputId": "d88c0b9e-a31b-44dc-ffab-5fe873de397e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_index['cat']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsfGIbQ5HSIa",
        "outputId": "fee4d42e-f40d-414c-88db-a0b1155e721a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "one_hot_results[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Cn35ssyHam"
      },
      "source": [
        "<ins>**One-hot hashing trick**</ins><br>\n",
        "\n",
        "\n",
        "A variant of one-hot encoding is the so-called **one-hot hashing trick**, which you can use\n",
        "when the **number of unique tokens in your vocabulary is too large to handle explicitly**.\n",
        "Instead of explicitly assigning an index to each word and keeping a reference of these\n",
        "indices in a dictionary, you can hash words into vectors of fixed size. This is typically\n",
        "done with a very lightweight hashing function. The main advantage of this method is\n",
        "that it does away with maintaining an explicit word index, which saves memory and\n",
        "allows online encoding of the data (you can generate token vectors right away, before\n",
        "you’ve seen all of the available data). The one drawback of this approach is that it’s\n",
        "susceptible to hash collisions: two different words may end up with the same hash, and\n",
        "subsequently any machine-learning model looking at these hashes won’t be able to tell\n",
        "the difference between these words. **The likelihood of hash collisions decreases when\n",
        "the dimensionality of the hashing space is much larger than the total number of\n",
        "unique tokens being hashed.**\n",
        "\n",
        "\n",
        "Stores the words as vectors of size 1,000. If you have close\n",
        "to 1,000 words (or more), you’ll see many hash collisions,\n",
        "which will decrease the accuracy of this encoding method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vns0r35Lx3y5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "dimensionality = 1000\n",
        "max_length = 10\n",
        "\n",
        "results = np.zeros((len(samples), max_length, dimensionality))\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "        # Hashes the word into a random integer index between 0 and 1,000\n",
        "        index = abs(hash(word)) % dimensionality\n",
        "        results[i, j, index] = 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxSsqjp7zPNh"
      },
      "source": [
        "### **Word embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGWjxbA1zUKk"
      },
      "source": [
        "#### ***CONCEPT***<br>\n",
        "Another popular and powerful way to associate a vector with a word is the use of dense\n",
        "**word vectors**, also called **word embeddings**. Whereas the vectors obtained through one-hot\n",
        "encoding are binary, sparse (mostly made of zeros), and very high-dimensional (same\n",
        "dimensionality as the number of words in the vocabulary), word embeddings are low-dimensional floating-point vectors (that is, dense vectors, as opposed to sparse vectors); see figure 6.2. **Unlike the word vectors obtained via one-hot encoding, word\n",
        "embeddings are learned from data**. It’s common to see ***word embeddings*** that are\n",
        "**256-dimensional, 512-dimensional, or 1,024-dimensional** when dealing with very large\n",
        "vocabularies. On the other hand, one-hot encoding words generally leads to vectors\n",
        "that are 20,000-dimensional or greater (capturing a vocabulary of 20,000 tokens, in\n",
        "this case). So, **word embeddings pack more information into far fewer dimensions**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cERK3o0DzuXC"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1ChlnVSULKUDIwX1qSR_AgLuLqTAoW172\"></img>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7XudfEK0J_B"
      },
      "source": [
        "There are two ways to obtain **word embeddings**:\n",
        "* Learn word embeddings jointly with the main task you care about (such as document classification or sentiment prediction). In this setup, you start with random word vectors and then learn word vectors in the same way you learn the\n",
        "weights of a neural network.\n",
        "\n",
        "* Load into your model word embeddings that were precomputed using a different machine-learning task than the one you’re trying to solve. These are called **pretrained word embeddings**.\n",
        "\n",
        "Let’s look at both."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVLtcz714-0x"
      },
      "source": [
        "\n",
        "\n",
        "The simplest way to **associate a dense vector with a word** is to choose the vector at\n",
        "random. The problem with this approach is that the resulting embedding space has\n",
        "no structure: for instance, the words *accurate* and *exact* may end up with completely\n",
        "different embeddings, even though they’re interchangeable in most sentences. It’s\n",
        "difficult for a deep neural network to make sense of such a noisy, unstructured\n",
        "embedding space.\n",
        "\n",
        "\n",
        "To get a bit more abstract, the **geometric relationships between word vectors**\n",
        "should reflect the **semantic relationships between these words**. Word embeddings are\n",
        "meant to **map human language into a geometric space**. For instance, in a reasonable\n",
        "embedding space, you would expect synonyms to be embedded into similar word vectors; and in general, you would expect the **geometric distance** (such as L2 distance aka Euclidean distance)\n",
        "between any two word vectors to relate to the **semantic distance** between the associated words (words meaning different things are embedded at points far away from\n",
        "each other, whereas related words are closer). In addition to distance, you may want\n",
        "specific ***directions*** in the embedding space to be meaningful. To make this clearer, let’s\n",
        "look at a concrete example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csEh1gGD6Sol"
      },
      "source": [
        "In figure 6.3, four words are embedded on a 2D plane:\n",
        "*cat, dog, wolf, and tiger*. With the vector representations we\n",
        "chose here, some **semantic relationships** between these\n",
        "words can be encoded as **geometric transformations**. \n",
        "\n",
        "For instance, the same vector allows us to go from *cat* to *tiger*\n",
        "and from *dog* to *wolf*: this vector could be interpreted as the\n",
        "“from pet to wild animal” vector. Similarly, another vector\n",
        "lets us go from *dog* to *cat* and from *wolf* to *tiger*, which could\n",
        "be interpreted as a “from canine to feline” vector.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1W5W8A1R611aiZdDkXZGwbCrQg0rvMZuY\"></img>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " In real-world **word-embedding spaces**, common examples of meaningful geometric transformations are “gender”\n",
        "vectors and “plural” vectors. For instance, by adding a “female” vector to the vector\n",
        "“king,” we obtain the vector “queen.” By adding a “plural” vector, we obtain “kings.”\n",
        "\n",
        "Word-embedding spaces typically feature thousands of such interpretable and potentially useful vectors.<br><br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Is there some ideal word-embedding space that would perfectly map human language and could be used for any natural-language-processing task? Possibly, but we\n",
        "have yet to compute anything of the sort. Also, there is no such a thing as *human language*—there are many different languages, and they aren’t isomorphic, because a language is the reflection of a specific culture and a specific context. \n",
        "\n",
        "But more\n",
        "pragmatically, what makes a **good word-embedding space depends heavily on your task**:\n",
        "the perfect word-embedding space for an English-language movie-review sentiment-analysis model may look different from the perfect embedding space for an English-language legal-document-classification model, **because the importance of certain\n",
        "semantic relationships varies from task to task.**\n",
        "\n",
        "\n",
        " It’s thus reasonable to **learn** a **new embedding space** with every new task. Fortunately, backpropagation makes this easy, and Keras makes it even easier. **It’s about\n",
        "learning the weights of a layer: the Embedding layer**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHvuVxhhCmmf"
      },
      "source": [
        "**Note about L1 (Manhattea) and L2 (Euclidian) distances:**\n",
        "\n",
        "\n",
        "Note that **L1 (Manhattan)** norm measures the distance along the \"streets\" (x axis) and \"avenues\" (y-axis) and adds the two numbers, rather than taking a diagonal length **(L2 norm)**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0zNlvWHCz0d"
      },
      "source": [
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1l64W8EKhntdhI6eMM1KI32_-BLMQ9Teq\"></img>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKbbfeheC7Nw"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqQSBMcaCzGp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljZE2BncAbUG"
      },
      "source": [
        "#### ***LEARNING WORD EMBEDDINGS WITH THE EMBEDDING LAYER***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvYPO_RK-0_d"
      },
      "source": [
        "**Word embeddings using Keras**<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2q2IzBbyxkp"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "# The Embedding layer takes at least two arguments: \n",
        "# the number of possible tokens (here, 1,000: 1 + maximum word index)\n",
        "# the dimensionality of the embeddings (here, 64).\n",
        "embedding_layer = Embedding(1000, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ngaavnt9gRR"
      },
      "source": [
        "The **Embedding layer** is best understood as a ***dictionary that maps integer indices\n",
        "(which stand for specific words) to dense vectors***. It takes integers as input, it looks up\n",
        "these integers in an internal dictionary, and it returns the associated vectors. It’s effectively a dictionary lookup (see figure 6.4).\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1B1noSRVoKzcacuTLdFwYbNpz1iLWNLcO\"></img>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The **Embedding layer** takes as input a 2D tensor of integers, of shape *(samples,\n",
        "sequence_length)*, where each entry is a sequence of integers. It can embed\n",
        "sequences of variable lengths: for instance, you could feed into the Embedding layer in\n",
        "the previous example batches with shapes (32, 10) (batch of 32 sequences of length\n",
        "10) or (64, 15) (batch of 64 sequences of length 15). All sequences in a batch must\n",
        "have the same length, though (because you need to pack them into a single tensor),\n",
        "so sequences that are shorter than others should be padded with zeros, and sequences\n",
        "that are longer should be truncated.\n",
        "\n",
        "\n",
        "This layer returns a 3D floating-point tensor of shape *(samples, sequence_\n",
        "length, embedding_dimensionality)*. Such a 3D tensor can then be processed by\n",
        "an RNN layer or a 1D convolution layer (both will be introduced in the following\n",
        "sections)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POHJSyF1-tRZ"
      },
      "source": [
        "When you instantiate an **Embedding layer**, its ***weights*** (its internal dictionary of\n",
        "token vectors) are initially random, just as with any other layer. During training, these\n",
        "word vectors are gradually adjusted via backpropagation, structuring the space into\n",
        "something the downstream model can exploit. Once fully trained, the embedding\n",
        "space will show a lot of structure—a kind of structure specialized for the specific problem for which you’re training your model.\n",
        "\n",
        " Let’s apply this idea to the IMDB movie-review sentiment-prediction task that\n",
        "you’re already familiar with. First, you’ll quickly prepare the data. You’ll restrict the\n",
        "movie reviews to the top 10,000 most common words (as you did the first time you\n",
        "worked with this dataset) and cut off the reviews after only 20 words. **The network will\n",
        "learn 8-dimensional embeddings for each of the 10,000 words, turn the input integer sequences (2D integer tensor) into embedded sequences (3D float tensor), flatten the\n",
        "tensor to 2D, and train a single Dense layer on top for classification.**\n",
        "\n",
        "**Remember:** the argument num_words=10000 means you’ll only keep the top 10,000 most frequently occurring words in the training data. Rare words will be discarded. This allows\n",
        "you to work with vector data of manageable size.\n",
        "\n",
        "\n",
        "**Loading the IMDB data for use with Embedding layer**<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oou5I1J19hxB",
        "outputId": "68884300-1814-466d-d87d-bc97e99f1b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Loading the IMDB data for use with Embedding layer\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras import preprocessing\n",
        "\n",
        "# Number of words to consider as features\n",
        "max_features = 10000 \n",
        "\n",
        "# Cuts off the text after this number of words (among the max_features most common words)\n",
        "maxlen = 20\n",
        "\n",
        "# Loads the data as lists of integers\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(\n",
        "    num_words=max_features)\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_train[0])\n",
        "# # Turns the lists of integers into a 2D integer tensor of shape (samples, maxlen)\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print(x_train.shape)\n",
        "\n",
        "# Each entry (sample) is a sequence of 20 integers\n",
        "print(x_train[0, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "(25000,)\n",
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "(25000, 20)\n",
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZdsRVg1_Rlv",
        "outputId": "6c304533-c6ff-4956-a7b6-8d39510ba38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train[9]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  78,  807,    9,  375,    8, 1167,    8,  794,   76,    7,    4,\n",
              "         58,    5,    4,  816,    9,  243,    7,   43,   50], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH-JS3LeAHVa",
        "outputId": "ad3083ad-27ec-4231-eca2-ee539aa22627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bTauAVxGh1U"
      },
      "source": [
        "**Using Embedding layer and classifier on the IMDB data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSBUWIMdBFjG",
        "outputId": "4510ff58-0bcf-425b-bb50-70b7a8b40af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "# Using Embedding layer and classifier on the IMDB data\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Embedding\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Specifies the maximum input length to the Embedding layer so you can later flatten the embedded inputs. \n",
        "# After the Embedding layer, the activations have shape (samples, maxlen, 8).\n",
        "model.add(Embedding(10000, 8, input_length=maxlen))\n",
        "\n",
        "# Flattens the 3D tensor of embeddings into a 2D tensor of shape (samples, maxlen * 8)\n",
        "model.add(Flatten())\n",
        "\n",
        "# Adds the classifier on top\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
        "    \n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 8)             80000     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 161       \n",
            "=================================================================\n",
            "Total params: 80,161\n",
            "Trainable params: 80,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.6708 - acc: 0.6173 - val_loss: 0.6238 - val_acc: 0.7032\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.5470 - acc: 0.7482 - val_loss: 0.5296 - val_acc: 0.7294\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4631 - acc: 0.7868 - val_loss: 0.5022 - val_acc: 0.7480\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.4226 - acc: 0.8081 - val_loss: 0.4938 - val_acc: 0.7532\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3950 - acc: 0.8253 - val_loss: 0.4937 - val_acc: 0.7572\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3719 - acc: 0.8365 - val_loss: 0.4961 - val_acc: 0.7554\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3510 - acc: 0.8479 - val_loss: 0.5012 - val_acc: 0.7558\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3320 - acc: 0.8592 - val_loss: 0.5068 - val_acc: 0.7524\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3134 - acc: 0.8705 - val_loss: 0.5159 - val_acc: 0.7518\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.2960 - acc: 0.8792 - val_loss: 0.5223 - val_acc: 0.7502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ummAQFVWLGQ9"
      },
      "source": [
        "You get to a validation accuracy of ~76%, which is pretty good considering that you’re\n",
        "only looking at the first 20 words in every review. But **note that merely flattening the\n",
        "embedded sequences and training a single Dense layer on top leads to a model that\n",
        "treats each word in the input sequence separately**, without considering inter-word\n",
        "relationships and sentence structure (for example, this model would likely treat both\n",
        "“this movie is a bomb” and “this movie is the bomb” as being negative reviews). \n",
        "\n",
        "It’s\n",
        "much better to **add recurrent layers or 1D convolutional layers on top of the embedded sequences to learn features that take into account each sequence as a whole.**\n",
        "That’s what we’ll focus on in the next few sections. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpRRhdR-LhkS"
      },
      "source": [
        "#### ***USING PRETRAINED EMBEDDING LAYER***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEpiyUqKLpN1"
      },
      "source": [
        "Sometimes, you have so little training data available that you can’t use your data\n",
        "alone to learn an appropriate task-specific embedding of your vocabulary. What do\n",
        "you do then?\n",
        "\n",
        "\n",
        " Instead of learning word embeddings jointly with the problem you want to solve,\n",
        "you can load embedding vectors from a precomputed embedding space that you\n",
        "know is highly structured and exhibits useful properties—that captures generic\n",
        "aspects of language structure. The rationale behind using pretrained word embeddings in natural-language processing is much the same as for using pretrained convnets in image classification: you don’t have enough data available to learn truly\n",
        "powerful features on your own, but you expect the features that you need to be fairly\n",
        "generic—that is, common visual features or semantic features. In this case, it makes\n",
        "sense to reuse features learned on a different problem.\n",
        "\n",
        "\n",
        " Such word embeddings are generally computed using word-occurrence statistics\n",
        "(observations about what words co-occur in sentences or documents), using a variety of\n",
        "techniques, some involving neural networks, others not. The idea of a dense, low-dimensional embedding space for words, computed in an unsupervised way, was initially explored by Bengio et al. in the early 2000s,1\n",
        " but it only started to take off in\n",
        "research and industry applications after the release of one of the most famous and successful word-embedding schemes: \n",
        "\n",
        "The [**Word2vec algorithm**](https://code.google.com/archive/p/word2vec), developed by Tomas Mikolov at Google in 2013. Word2vec\n",
        "dimensions capture specific semantic properties, such as gender.<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "There are various precomputed databases of word embeddings that you can download and use in a Keras Embedding layer. **Word2vec** is one of them. Another popular\n",
        "one is called [**Global Vectors for Word Representation (GloVe)**](https://nlp.stanford.edu/projects/glove), which was developed by Stanford researchers in 2014. This\n",
        "embedding technique is based on factorizing a matrix of word co-occurrence statistics. Its developers have made available precomputed embeddings for millions of\n",
        "English tokens, obtained from Wikipedia data and Common Crawl data.\n",
        "\n",
        " Let’s look at how you can get started using **GloVe embeddings** in a Keras model.\n",
        "The same method is valid for **Word2vec embeddings** or any other word-embedding\n",
        "database. You’ll also use this example to refresh the text-tokenization techniques\n",
        "introduced a few paragraphs ago: you’ll start from raw text and work your way up. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W1LZmGwMvQV"
      },
      "source": [
        "### <font color=\"Tomato\">**Putting it all together: from raw text to word embedding (IMDB data)**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38lWoxVvM9wo"
      },
      "source": [
        "You’ll use a model similar to the one we just went over:\n",
        "\n",
        "Embedding sentences (our samples - first axis) in\n",
        "sequences (second axis) of [word] vectors (third axis), flattening them, and training a Dense layer on top. But you’ll do\n",
        "so using pretrained word embeddings; and instead of using the pretokenized IMDB\n",
        "data packaged in Keras, you’ll start from scratch by downloading the original text data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSbiIHEWM9R2",
        "outputId": "ee89e8a1-4b25-4b01-b10a-d61f6594ccff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# to mount google drive for colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygC4EF8iZFb9",
        "outputId": "d7b2fb1a-1900-40ad-cdf2-9203c241d97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DztzOx9Xoxy",
        "outputId": "fb4a7f14-5ee7-42e4-efab-d661b19b0ce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "% cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmW6lTavX8kj"
      },
      "source": [
        "path_to_data = \"/content/drive/My Drive/machine learning/notebooks/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJE-U1rVZO1g",
        "outputId": "0e6ba200-7f97-4cc8-8cd6-9bb68285d5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "% cd \"/content/drive/My Drive/machine learning/notebooks/data\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/machine learning/notebooks/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpfEKGKrPQ4G"
      },
      "source": [
        "**DOWNLOADING THE IMDB DATA AS RAW TEXT**\n",
        "\n",
        "\n",
        "First, head to http://mng.bz/0tIo and download the raw IMDB dataset. Uncompress it.\n",
        "\n",
        " Now, let’s collect the individual training reviews into a list of strings, one string per\n",
        "review. You’ll also collect the review labels (positive/negative) into a labels list. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvRDRahUabHb",
        "outputId": "93e6a3c6-3219-4541-c5b1-44b1af3025c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PBa5yPLAW20"
      },
      "source": [
        "# Processing the labels of the raw IMDB data\n",
        "import os\n",
        "\n",
        "imdb_dir = \"/content/drive/My Drive/machine learning/notebooks/data/aclImdb\"\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(train_dir, label_type)\n",
        "    for fname in os.listdir(dir_name)[0:5]:\n",
        "        if fname[-4:] == '.txt':\n",
        "            # open a review file\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            #  get entire review in a string, append to texts list\n",
        "            texts.append(f.read())\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTTYMIE6kXI-",
        "outputId": "e22e037b-5b32-4af8-9455-9d3d61cba576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "texts[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I am appalled at how bad this film is. As a pastiche of early 20th century Hollywood artistes it sets a new low - even past The Moderns or (gasp) Cradle Will Rock & I never thought I'd see a film worse than those 2. Granted they were about a slightly different milieu & period. Nevertheless the intents & results were distressingly similar.<br /><br />First off there's the horrible casting: Eddie Izzard as CHAPLIN? Excuse me? Peter, did you owe this guy something? Jennifer Tilly as Loulla Parsons?? Kirsten Dunst as Marion Davies??? Holy smoke, these people don't even begin to try to capture the look or sound of the period they are purportedly depicting.<br /><br />Well, Last Picture Show was a decent film, but this thing is a disaster & the rest of Bogdonovitch's pics haven't been much better. Guess rubbing up against Welles & Hitch & Ford wore off a long time ago. Still good for hosting TCM though.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R__pLOYAdGmB",
        "outputId": "3ac351e1-b24d-471d-9c8a-ab72519e508c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(texts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCR6oYw7QrYs"
      },
      "source": [
        "**TOKENIZING THE DATA**\n",
        "\n",
        "\n",
        "Let’s vectorize the text and prepare a training and validation split, using the concepts\n",
        "introduced earlier in this section. Because pretrained word embeddings are meant to\n",
        "be particularly useful on problems where little training data is available (otherwise,\n",
        "task-specific embeddings are likely to outperform them), we’ll add the following twist:\n",
        "restricting the training data to the first 200 samples. So you’ll learn to classify movie\n",
        "reviews after looking at just 200 examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5m0QOUjQtuA",
        "outputId": "227324fa-8563-4136-ef37-755ee411b6a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# Tokenizing the text of the raw IMDB data\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "maxlen = 100 # Cuts off reviews after 100 words\n",
        "training_samples = 200 # Trains on 200 samples\n",
        "validation_samples = 10000\n",
        "max_words = 10000 # Considers only the top 10,000 words in the dataset\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "print(\"Sequences is a\", type(sequences))\n",
        "print(\"Each element is a\", type(sequences[0]))\n",
        "print(\"Length of Sequences is\", len(sequences))\n",
        "print(\"First element of Sequences is\", sequences[0])\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "print('Type of word_index is',  type(word_index))\n",
        "print(\"index of word appalled is\", word_index.get(\"appalled\"))\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Splits the data into a training set and a validation set, but first shuffles the data, \n",
        "# because you’re starting with data in which samples are ordered (all negative first, then all positive)\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]\n",
        "# Each entry (sample) is a sequence of 100 integers\n",
        "print(x_train.shape)\n",
        "print(x_train[1,10])\n",
        "print(x_train[9, :].shape)\n",
        "print(x_train[9, :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequences is a <class 'list'>\n",
            "Each element is a <class 'list'>\n",
            "Length of Sequences is 10\n",
            "First element of Sequences is [13, 118, 247, 37, 248, 83, 9, 10, 3, 14, 4, 249, 6, 250, 251, 252, 253, 254, 11, 84, 4, 119, 120, 26, 121, 1, 255, 43, 256, 257, 38, 258, 13, 85, 122, 123, 44, 4, 10, 259, 62, 86, 260, 261, 18, 124, 63, 4, 262, 263, 264, 125, 265, 1, 266, 267, 124, 268, 269, 7, 7, 87, 126, 127, 1, 270, 128, 271, 272, 14, 273, 274, 129, 275, 88, 17, 276, 9, 130, 277, 278, 279, 14, 280, 281, 282, 283, 14, 284, 285, 286, 131, 287, 64, 27, 26, 288, 5, 132, 5, 289, 1, 290, 43, 291, 6, 1, 125, 18, 15, 292, 293, 7, 7, 45, 89, 133, 39, 19, 4, 294, 10, 20, 9, 65, 3, 4, 295, 1, 296, 6, 297, 298, 299, 300, 66, 67, 301, 302, 46, 303, 304, 305, 306, 307, 126, 4, 134, 30, 308, 135, 28, 31, 309, 310, 136]\n",
            "Found 839 unique tokens.\n",
            "Type of word_index is <class 'dict'>\n",
            "index of word appalled is 247\n",
            "Shape of data tensor: (10, 100)\n",
            "Shape of label tensor: (10,)\n",
            "(10, 100)\n",
            "177\n",
            "(100,)\n",
            "[494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509   2 510\n",
            " 511   1 202  56   1 145   3  41  28   1 512  15  41  28   2  75   6  11\n",
            "   3 513   1  47   3 514  41  28  14  45 203  65 515  31   1 204   1  10\n",
            "   3  41  53   2   1  47  58 516  17 107 517   1 180   9   3   4  41 518\n",
            "  10 205  17   1   1 200   8   1  10 519 520 521  35  36 522 523   2  53\n",
            "  35 206  13 524  17   5  44   9  10 525]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MQkQwqOSDND"
      },
      "source": [
        "**DOWNLOADING THE GLOVE WORD EMBEDDINGS**\n",
        "\n",
        "Go to https://nlp.stanford.edu/projects/glove, and download the precomputed\n",
        "embeddings from 2014 English Wikipedia. It’s an 822 MB zip file called glove.6B.zip,\n",
        "containing 100-dimensional embedding vectors for 400,000 words (or nonword\n",
        "tokens). Unzip it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK1DC03iSHsN"
      },
      "source": [
        "**PREPROCESSING THE EMBEDDINGS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH_sDZ49RzC9",
        "outputId": "5bfe57a7-f10b-45df-e40d-498145fb704a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Parsing the GloVe word-embeddings file\n",
        "glove_dir = '/content/drive/My Drive/machine learning/notebooks/data/glove.6B'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FrbCbXQcfpl",
        "outputId": "fcce5f04-bf10-415f-90e2-bffee1490c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(embeddings_index.get(\"happy\").shape)\n",
        "print(type(embeddings_index.get(\"happy\")))\n",
        "print(len(embeddings_index))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100,)\n",
            "<class 'numpy.ndarray'>\n",
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH1s95kqSSvy"
      },
      "source": [
        "Next, you’ll build an embedding matrix that you can load into an ***Embedding layer***. It\n",
        "must be a matrix of shape ***(max_words, embedding_dim)***, where each entry i contains\n",
        "the **embedding_dim**-dimensional vector for the word of index i in the reference word\n",
        "index (built during tokenization). Note that index 0 isn’t supposed to stand for any\n",
        "word or token—it’s a placeholder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg9OWOkbSZP4"
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in the embedding index will be all zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x9L-UIalFyX",
        "outputId": "387b7148-62be-40b7-ae51-dcd8a616a0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# pretrained weights to load into Embedding layer\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AQe4mlASm7y"
      },
      "source": [
        "**DEFINING A MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvdmaErISnzK",
        "outputId": "1d1f2f30-0c05-4ba6-f8d2-6b69cf84c588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "# max len is 100 (sequence dimension)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                320032    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,320,065\n",
            "Trainable params: 1,320,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBtFu_Eul0h6"
      },
      "source": [
        "The **Embedding layer** outputs 3D tensor of **(samples, 100, 100)**. First 100 is the dimensionality of sequences, second is dimensionality of the word embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1VVOWkhSs-2"
      },
      "source": [
        "**LOADING THE GLOVE EMBEDDINGS IN THE MODEL**\n",
        "\n",
        "The Embedding layer has a single weight matrix: a 2D float matrix where each entry i is\n",
        "the (100-dimensional) **word vector** meant to be associated with index i. Simple enough. Load the GloVe\n",
        "matrix you prepared into the Embedding layer, the first layer in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyAVVn8RSwwo"
      },
      "source": [
        "# Loading pretrained word embeddings into the Embedding layer\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZaXKEHjS1O4"
      },
      "source": [
        "Additionally, you’ll freeze the **Embedding** layer (set its ***trainable*** attribute to *False*),\n",
        "following the same rationale you’re already familiar with in the context of pretrained\n",
        "convnet features: when parts of a model are pretrained (like your Embedding layer)\n",
        "and parts are randomly initialized (like your classifier), the pretrained parts shouldn’t\n",
        "be updated during training, to avoid forgetting what they already know. The large gradient updates triggered by the randomly initialized layers would be disruptive to the\n",
        "already-learned features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTqCDms4S8bf"
      },
      "source": [
        "**TRAINING AND EVALUATING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csoG3yGbnHnV",
        "outputId": "61cedca3-6d52-449d-aff1-a5c4e518fcbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Remember x_train is a 2d array where each entry is a number\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n",
        "# first sentence, 10th word\n",
        "print(x_train[0,10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 100)\n",
            "(200,)\n",
            "(1800, 100)\n",
            "(1800,)\n",
            "703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXWj37MxS1tT",
        "outputId": "0d82b894-a905-4548-97d4-972bd2726fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Training and evaluation\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))\n",
        "\n",
        "model.save_weights('pre_trained_glove_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9279 - val_acc: 0.4983\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 3.0915e-04 - acc: 1.0000 - val_loss: 0.8712 - val_acc: 0.4983\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 1.4008e-04 - acc: 1.0000 - val_loss: 0.9069 - val_acc: 0.4967\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 9.0593e-05 - acc: 1.0000 - val_loss: 0.9148 - val_acc: 0.4944\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 5.9310e-05 - acc: 1.0000 - val_loss: 0.9197 - val_acc: 0.4950\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 4.0189e-05 - acc: 1.0000 - val_loss: 0.9293 - val_acc: 0.4928\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 2.7561e-05 - acc: 1.0000 - val_loss: 0.9428 - val_acc: 0.4900\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 1.9271e-05 - acc: 1.0000 - val_loss: 0.9581 - val_acc: 0.4878\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 1.3597e-05 - acc: 1.0000 - val_loss: 0.9912 - val_acc: 0.4906\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 9.6462e-06 - acc: 1.0000 - val_loss: 0.9771 - val_acc: 0.4889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKZ-NBPSTLT5"
      },
      "source": [
        "Now, plot the model’s performance over time (see figures 6.5 and 6.6)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1umxvEnTNPV",
        "outputId": "501702e0-2bf5-476b-9664-30f63c19a6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "# Plotting the results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN5MXy3LTVqH"
      },
      "source": [
        "The model quickly starts overfitting, which is unsurprising given the small number of\n",
        "training samples. Validation accuracy has high variance for the same reason, but it\n",
        "seems to reach the high 50s.\n",
        "\n",
        "\n",
        " Note that your mileage may vary: because you have so few training samples, performance is heavily dependent on exactly which 200 samples you choose—and you’re\n",
        "choosing them at random. If this works poorly for you, try choosing a different random set of 200 samples, for the sake of the exercise (in real life, you don’t get to\n",
        "choose your training data).\n",
        "\n",
        "\n",
        " You can also train the same model without loading the pretrained word embeddings and without freezing the embedding layer. In that case, you’ll learn a taskspecific embedding of the input tokens, which is generally more powerful than\n",
        "pretrained word embeddings when lots of data is available. But in this case, you have\n",
        "only 200 training samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkR5_-SrTWzc",
        "outputId": "a97246df-21ae-4631-b392-ec4618cbfc22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "# Training the same model without pretrained word embeddings\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                320032    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,320,065\n",
            "Trainable params: 1,320,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.6968 - acc: 0.4700 - val_loss: 0.6962 - val_acc: 0.4789\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.5098 - acc: 0.9800 - val_loss: 0.6985 - val_acc: 0.4983\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.2994 - acc: 0.9950 - val_loss: 0.7178 - val_acc: 0.4939\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.1282 - acc: 1.0000 - val_loss: 0.7289 - val_acc: 0.4939\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0589 - acc: 1.0000 - val_loss: 0.7427 - val_acc: 0.4844\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.7565 - val_acc: 0.4989\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.7689 - val_acc: 0.4972\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.7776 - val_acc: 0.4967\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.7947 - val_acc: 0.4972\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.7927 - val_acc: 0.4983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPNplZ6oTniF"
      },
      "source": [
        "Validation accuracy stalls in the low 50s. So in this case, pretrained word embeddings\n",
        "outperform jointly learned embeddings. If you increase the number of training samples, this will quickly stop being the case—try it as an exercise.\n",
        " Finally, let’s evaluate the model on the test data. First, you need to tokenize the test\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auokZ525TqEd"
      },
      "source": [
        "# Tokenizing the data of the test set\n",
        "test_dir = os.path.join(imdb_dir, 'test')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "    dir_name = os.path.join(test_dir, label_type)\n",
        "    for fname in sorted(os.listdir(dir_name)[0:20]):\n",
        "        if fname[-4:] == '.txt':\n",
        "            f = open(os.path.join(dir_name, fname))\n",
        "            texts.append(f.read())\n",
        "\n",
        "            f.close()\n",
        "            if label_type == 'neg':\n",
        "                labels.append(0)\n",
        "            else:\n",
        "                labels.append(1)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
        "y_test = np.asarray(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLTrV-QKT-Sl"
      },
      "source": [
        "Next, load and evaluate the first model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9fWpSrnT_tU",
        "outputId": "a32f6743-5fd0-45ea-b912-6a539492aff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Evaluate model on test set\n",
        "model.load_weights('pre_trained_glove_model.h5')\n",
        "# Returns the loss value & metrics values for the model in test mode.\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 2ms/step - loss: 0.8432 - acc: 0.5500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8431736826896667, 0.550000011920929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwtp74o9UEM9"
      },
      "source": [
        "You get an appalling test accuracy of 56%. Working with just a handful of training\n",
        "samples is difficult!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "texzgwuiUM8_"
      },
      "source": [
        "### **Wrapping up**\n",
        "Now you’re able to do the following:\n",
        "- Turn raw text into something a neural network can process\n",
        "- Use the ***Embedding*** layer in a Keras model to learn task-specific token embeddings\n",
        "- Use pretrained **word embeddings** to get an extra boost on small natural language processing problems "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gnH7a7wUXtN"
      },
      "source": [
        "## <font color=\"MediumSeaGreen\">**Understanding recurrent neural networks**</font>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvlgpa6ycvlF"
      },
      "source": [
        "### **Concept**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMXJ7pEOUlDs"
      },
      "source": [
        "A major characteristic of all neural networks you’ve seen so far, such as densely connected networks and convnets, is that they have no memory. Each input shown to\n",
        "them is processed independently, with no state kept in between inputs. With such networks, in order to process a sequence or a temporal series of data points, you have to\n",
        "show the entire sequence to the network at once: turn it into a single data point. For\n",
        "instance, this is what you did in the IMDB example: an entire movie review was transformed into a single large vector and processed in one go. Such networks are called\n",
        "**feedforward networks**.\n",
        "\n",
        "\n",
        " In contrast, as you’re reading the present sentence, you’re processing it word by\n",
        "word—or rather, eye saccade by eye saccade—while keeping memories of what came\n",
        "before; this gives you a fluid representation of the meaning conveyed by this sentence.\n",
        "Biological intelligence processes information incrementally while maintaining an\n",
        "internal model of what it’s processing, built from past information and constantly\n",
        "updated as new information comes in.\n",
        "\n",
        "\n",
        " A ***recurrent neural network*** (RNN) adopts the same principle, albeit in an extremely\n",
        "simplified version: it processes sequences by iterating through the sequence elements\n",
        "and maintaining a **state** containing information relative\n",
        "to what it has seen so far. In effect, an RNN is a type of\n",
        "neural network that has an internal **loop** (see figure 6.9).\n",
        "The state of the RNN is reset between processing two different, independent sequences (such as two different\n",
        "IMDB reviews), so you still consider one sequence a single data point: a single input to the network. What\n",
        "changes is that this data point is no longer processed in a\n",
        "single step; rather, the network internally loops over\n",
        "sequence elements.\n",
        "\n",
        "\n",
        "To make these notions of **loop** and **state** clear, let’s implement the forward pass of a\n",
        "toy RNN in Numpy. This RNN takes as input a sequence of vectors, which you’ll encode\n",
        "as a 2D tensor of size (timesteps, input_features). **It loops over timesteps, and at\n",
        "each timestep, it considers its current state at t and the input at t (of shape (input_\n",
        "features,), and combines them to obtain the output at t. You’ll then set the state for\n",
        "the next step to be this previous output.** For the first timestep, the previous output\n",
        "isn’t defined; hence, there is no current state. So, you’ll initialize the state as an all-zero vector called the **initial state** of the network.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1CS4ehr8EQGPj0NZbBO2uI4BnuMBQ4Fpf\"></img><br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lay3dAyAV-W1"
      },
      "source": [
        "**RNN Pseudocode**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJHu1rG3WPNP"
      },
      "source": [
        "state_t = 0 # The state at t\n",
        "\n",
        "for input_t in input_sequence: # Iterates over sequence of elements\n",
        "    output_t = f(input_t, state_t)\n",
        "    state_t = output_t # The previous output becomes the state for the next iteration."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRE5NS30WfNB"
      },
      "source": [
        "You can even flesh out the function f: the transformation of the input and state into an\n",
        "output will be parameterized by two matrices, W and U, and a bias vector. It’s similar to\n",
        "the transformation operated by a densely connected layer in a feedforward network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R61O8MoLWhtY"
      },
      "source": [
        "**More detailed RNN Pseudocode**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyGvu1RxUEyD"
      },
      "source": [
        "state_t = 0\n",
        "for input_t in input_sequence:\n",
        "    output_t = activation(dot(W, input_t) + dot(U, state_t) + b)\n",
        "    state_t = output_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG1jfbcUzX-O"
      },
      "source": [
        "To make these notions absolutely unambiguous, let’s write a naive Numpy implementation of the forward pass of the simple RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ej9XXIgzZAY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# number of timesteps in input sequence\n",
        "timesteps = 100\n",
        "# dimensionality of input feature space\n",
        "input_features = 32\n",
        "# dimensionality of output feature space\n",
        "output_features = 64\n",
        "\n",
        "# Input data: random noise for the sake of the example\n",
        "inputs = np.random.random((timesteps, input_features))\n",
        "\n",
        "# Initial state: an all-zero vector\n",
        "state_t = np.zeros((output_features,))\n",
        "\n",
        "# Creates random weight matrices\n",
        "W = np.random.random((output_features, input_features))\n",
        "U = np.random.random((output_features, output_features))\n",
        "b = np.random.random((output_features,))\n",
        "\n",
        "successive_outputs = []\n",
        "# input_t is a vector of shape (input_features,)\n",
        "for input_t in inputs:\n",
        "    # Combines the input with the current state (the previous output) to obtain the current output\n",
        "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
        "\n",
        "    # Stores this output in a list\n",
        "    successive_outputs.append(output_t)\n",
        "\n",
        "    # Updates the state of the network for the next timestep\n",
        "    state_t = output_t\n",
        "\n",
        "# The final output is a 2D tensor of shape (timesteps, output_features).\n",
        "final_output_sequence = np.concatenate(successive_outputs, axis=0)\n",
        "\n",
        "\n",
        "# PSA: hyperbolic tangent function tanh,\n",
        "# is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R5ACZAH0Bod"
      },
      "source": [
        "Easy enough: in summary, an **RNN is a for loop that reuses quantities computed\n",
        "during the previous iteration of the loop**, nothing more. Of course, there are many\n",
        "different RNNs fitting this definition that you could build—this example is one of the\n",
        "simplest RNN formulations. RNNs are characterized by their **step function**, such as the\n",
        "following function in this case (see figure 6.10):\n",
        "\n",
        "`output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzkIRMLC0Njc"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1-fmi-ztURWJT2BSED68T8mcu7YgKI2yZ\"></img><br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNh5-aEi0VqC"
      },
      "source": [
        "**NOTE:**<br> In this example, the final output is a 2D tensor of shape (timesteps,\n",
        "output_features), where each timestep is the output of the loop at time t.\n",
        "Each timestep t in the output tensor contains information about timesteps 0\n",
        "to t in the input sequence—about the entire past. For this reason, in many\n",
        "cases, you don’t need this full sequence of outputs; you just need the last output (output_t at the end of the loop), because it already contains information about the entire sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmZQ0-nKW4ib"
      },
      "source": [
        "### **A recurrent layer in Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhOccnZYbHfP"
      },
      "source": [
        "The process you just naively implemented in Numpy corresponds to an actual Keras\n",
        "layer—the SimpleRNN layer:\n",
        "\n",
        "`from keras.layers import SimpleRNN`\n",
        "\n",
        "There is one minor difference: **SimpleRNN** processes batches of sequences, like all other\n",
        "Keras layers, not a single sequence as in the Numpy example. This means it takes inputs\n",
        "of shape ***(batch_size, timesteps, input_features)***, rather than ***(timesteps,\n",
        "input_features)***.\n",
        "\n",
        "\n",
        " Like all recurrent layers in Keras, SimpleRNN can be run in two different modes: it\n",
        "can return either the full sequences of successive outputs for each timestep (a 3D tensor of shape ***(batch_size, timesteps, output_features)***) or only the last output for\n",
        "each input sequence (a 2D tensor of shape ***(batch_size, output_features)***). These\n",
        "two modes are controlled by the **return_sequences** constructor argument. Let’s look\n",
        "at an example that uses **SimpleRNN** and returns only the output at the last timestep:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxnBUhQZW55u",
        "outputId": "604fd3c6-c0b2-4983-ba5e-59ad0861fff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32))\n",
        "model.add(SimpleRNN(32))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 32)                2080      \n",
            "=================================================================\n",
            "Total params: 322,080\n",
            "Trainable params: 322,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGl_BG8SbkwM"
      },
      "source": [
        "The following example returns the full state sequence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW_PqjixblT-",
        "outputId": "f77a6368-21ad-4e8e-bc91-5ef3d9ea3082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, None, 32)          2080      \n",
            "=================================================================\n",
            "Total params: 322,080\n",
            "Trainable params: 322,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNCvV9bJbpRr"
      },
      "source": [
        "It’s sometimes useful to stack several recurrent layers one after the other in order to\n",
        "increase the representational power of a network. In such a setup, you have to get all\n",
        "of the intermediate layers to return full sequence of outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s65Zc3Gjbt8d",
        "outputId": "8067b772-1d16-4b44-bc01-76779a53313e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(SimpleRNN(32))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_3 (SimpleRNN)     (None, None, 32)          2080      \n",
            "_________________________________________________________________\n",
            "simple_rnn_4 (SimpleRNN)     (None, None, 32)          2080      \n",
            "_________________________________________________________________\n",
            "simple_rnn_5 (SimpleRNN)     (None, None, 32)          2080      \n",
            "_________________________________________________________________\n",
            "simple_rnn_6 (SimpleRNN)     (None, 32)                2080      \n",
            "=================================================================\n",
            "Total params: 328,320\n",
            "Trainable params: 328,320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCKp6qm3b1ym"
      },
      "source": [
        "Now, let’s use such a model on the **IMDB movie-review-classification problem**. First,\n",
        "***preprocess the data***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtXYkzfAb5Zf",
        "outputId": "8cb9d76d-5925-4f64-9c0e-dfb4c920085e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
        "    num_words=max_features)\n",
        "\n",
        "# 25k dimensional array, each entry is a list of word indices\n",
        "print(len(input_train), 'train sequences')\n",
        "print(len(input_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "\n",
        "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
        "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
        "print('input_train shape:', input_train.shape)\n",
        "print('input_test shape:', input_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "input_train shape: (25000, 500)\n",
            "input_test shape: (25000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM89Dy6ycEdu"
      },
      "source": [
        "Let’s train a simple recurrent network using an **Embedding** layer and a **SimpleRNN**\n",
        "layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLprBJ1NcHGN",
        "outputId": "79b96da7-27b6-4735-f4da-7f2da451cd44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Training the model with Embedding and SimpleRNN layers\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(input_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 52s 334ms/step - loss: 0.5843 - acc: 0.6855 - val_loss: 0.4835 - val_acc: 0.7804\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 53s 338ms/step - loss: 0.3798 - acc: 0.8393 - val_loss: 0.4843 - val_acc: 0.7950\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 52s 332ms/step - loss: 0.2756 - acc: 0.8902 - val_loss: 0.3670 - val_acc: 0.8460\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 52s 330ms/step - loss: 0.2173 - acc: 0.9173 - val_loss: 0.3733 - val_acc: 0.8424\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 54s 341ms/step - loss: 0.1562 - acc: 0.9417 - val_loss: 0.3782 - val_acc: 0.8594\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 54s 344ms/step - loss: 0.1007 - acc: 0.9647 - val_loss: 0.4757 - val_acc: 0.8360\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 53s 338ms/step - loss: 0.0650 - acc: 0.9790 - val_loss: 0.5243 - val_acc: 0.8102\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 52s 331ms/step - loss: 0.0380 - acc: 0.9888 - val_loss: 0.5652 - val_acc: 0.8298\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 52s 333ms/step - loss: 0.0290 - acc: 0.9918 - val_loss: 0.5629 - val_acc: 0.8434\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 53s 337ms/step - loss: 0.0178 - acc: 0.9952 - val_loss: 0.8132 - val_acc: 0.7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXNSMnaXcQgN"
      },
      "source": [
        "Now, let’s display the training and validation loss and accuracy (see figures 6.11 and 6.12)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dlTfcuGcRIR",
        "outputId": "2c5907cc-bd8d-4d9f-ba28-ff321ebf693e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "# Plotting results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "\n",
        "\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo9Ll4yZcf3e"
      },
      "source": [
        "As a reminder, in chapter 3, the first naive approach to this dataset got you to a test\n",
        "accuracy of 88%. Unfortunately, this small recurrent network doesn’t perform well\n",
        "compared to this baseline (only 85% validation accuracy). Part of the problem is that\n",
        "your inputs only consider the first 500 words, rather than full sequences—hence, the\n",
        "RNN has access to less information than the earlier baseline model. The remainder of\n",
        "the problem is that **SimpleRNN** isn’t good at processing long sequences, such as text.\n",
        "\n",
        "\n",
        "**Other types of recurrent layers perform much better**. Let’s look at some more advanced layers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XCroGGcc7VH"
      },
      "source": [
        "### **Understanding the LSTM and GRU layers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Ds5Toh4d5Y"
      },
      "source": [
        "**SimpleRNN** isn’t the only recurrent layer available in Keras. There are two others: **LSTM**\n",
        "and **GRU**. In practice, you’ll always use one of these, because **SimpleRNN** is generally too\n",
        "simplistic to be of real use. **SimpleRNN** has a major issue: although it should theoretically\n",
        "be able to **retain at time t information about inputs seen many timesteps before, in\n",
        "practice, such long-term dependencies are impossible to learn**. This is due to the **vanishing gradient problem**, an effect that is similar to what is observed with non-recurrent\n",
        "networks (feedforward networks) that are many layers deep: as you keep adding layers\n",
        "to a network, the network eventually becomes untrainable. The theoretical reasons for\n",
        "this effect were studied by Hochreiter, Schmidhuber, and Bengio in the early 1990s.\n",
        "The **LSTM** and **GRU layers** are designed to solve this problem.\n",
        "\n",
        "\n",
        " Let’s consider the **LSTM layer**. The underlying Long Short-Term Memory (**LSTM**)\n",
        "algorithm was developed by Hochreiter and Schmidhuber in 1997; it was the culmination of their research on the vanishing gradient problem.\n",
        "\n",
        "\n",
        " This layer is a variant of the **SimpleRNN** layer you already know about; it adds a **way\n",
        "to carry information across many timesteps**. Imagine a conveyor belt running parallel\n",
        "to the sequence you’re processing. Information from the sequence can jump onto the\n",
        "conveyor belt at any point, be transported to a later timestep, and jump off, intact,\n",
        "when you need it. This is essentially what LSTM does: it saves information for later,\n",
        "thus preventing older signals from gradually vanishing during processing.\n",
        "\n",
        "\n",
        " To understand this in detail, let’s start from the SimpleRNN cell (see figure 6.13).\n",
        "Because you’ll have a lot of weight matrices, index the W and U matrices in the cell with\n",
        "the letter o (**Wo** and **Uo**) for *output*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgQxicpH6jfX"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1j2J1LlyemP5AyFHBLNWeNw9i38TfkyrW\"></img><br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ISap-IK7wKi"
      },
      "source": [
        "Let’s add to this picture an additional data flow that carries information across timesteps. Call its values at different timesteps **Ct**, where **C** stands for **carry**. This information will have the following impact on the cell: it will be combined with the input\n",
        "connection and the recurrent connection (via a dense transformation: a dot product\n",
        "with a weight matrix followed by a bias add and the application of an activation function), and it will affect the state being sent to the next timestep (via an activation\n",
        "function an a multiplication operation). Conceptually, the carry dataflow is a way to\n",
        "modulate (modify) the next output and the next state (see figure 6.14). Simple so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9Gtr7W7_mb"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1sL0NxwWnkk7HYgj8gSgh0UXoe30Ip6xv\"></img><br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqUWWjNE8WZi"
      },
      "source": [
        "Now the subtlety: the way the next value of the carry dataflow is computed. It involves\n",
        "three distinct transformations. All three have the form of a **SimpleRNN** cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mnUQPL9ch6s"
      },
      "source": [
        "# y = activation(dot(state_t, U) + dot(input_t, W) + b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhKSaXcE8k9u"
      },
      "source": [
        "But all three transformations have their own weight matrices, which you’ll index with\n",
        "the letters **i**, **f**, and **k**. Here’s what you have so far (it may seem a bit arbitrary, but bear\n",
        "with me)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlDR9hwIdDPc"
      },
      "source": [
        "**Pseudocode details of the LSTM architecture (1/2)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtE5z9q786bn"
      },
      "source": [
        "output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(C_t, Vo) + bo)\n",
        "\n",
        "i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)\n",
        "f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)\n",
        "k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9P0EAJC9DDQ"
      },
      "source": [
        "You obtain the new carry state (the next c_t) by combining i_t, f_t, and k_t."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVTlwyxZ9Irv"
      },
      "source": [
        "**Pseudocode details of the LSTM architecture (2/2)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLvOvqN789Zd"
      },
      "source": [
        "c_t+1 = i_t * k_t + c_t * f_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp9YXYyW9U0j"
      },
      "source": [
        "Add this as shown in figure 6.15. And that’s it. Not so complicated—merely a tad\n",
        "complex.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1fxKDXg83kqfTTw7ildjOjU8J-lpiytgl\"></img><br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7JOwShv9aiK"
      },
      "source": [
        "If you want to get philosophical, you can interpret what each of these operations is\n",
        "meant to do. For instance, you can say that multiplying *c_t* and *f_t* is a way to deliberately forget irrelevant information in the carry dataflow. Meanwhile, i_t and k_t provide information about the present, updating the carry track with new information.\n",
        "But at the end of the day, these interpretations don’t mean much, because what these\n",
        "operations actually do is determined by the contents of the weights parameterizing\n",
        "them; and the weights are learned in an end-to-end fashion, starting over with each\n",
        "training round, making it impossible to credit this or that operation with a specific\n",
        "purpose. The specification of an RNN cell (as just described) determines your hypothesis space—the space in which you’ll search for a good model configuration during\n",
        "training—but it doesn’t determine what the cell does; that is up to the cell weights.\n",
        "The same cell with different weights can be doing very different things. So the combination of operations making up an RNN cell is better interpreted as a set of constraints\n",
        "on your search, not as a design in an engineering sense.<br>\n",
        " To a researcher, it seems that the choice of such constraints—the question of how to\n",
        "implement RNN cells—is better left to optimization algorithms (like genetic algorithms\n",
        "or reinforcement learning processes) than to human engineers. And in the future,\n",
        "that’s how we’ll build networks. In summary: you don’t need to understand anything\n",
        "about the specific architecture of an LSTM cell; as a human, it shouldn’t be your job to\n",
        "understand it. Just keep in mind what the LSTM cell is meant to do: allow past information to be reinjected at a later time, thus fighting the vanishing-gradient problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZNQLvkV-KAY"
      },
      "source": [
        "#### **A concrete LSTM example in Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j3UY0xa-N48"
      },
      "source": [
        "Now let’s switch to more practical concerns: you’ll set up a model using an LSTM layer\n",
        "and train it on the IMDB data (see figures 6.16 and 6.17). The network is similar to the\n",
        "one with SimpleRNN that was just presented. You only specify the output dimensionality of the LSTM layer; leave every other argument (there are many) at the Keras defaults. Keras has good defaults, and things will almost always “just work” without you\n",
        "having to spend time tuning parameters by hand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOVg_96o9yTH",
        "outputId": "c7159f2e-64c6-43d5-bbb3-91f1e4217e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Using the LSTM layer in Keras\n",
        "from keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(input_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 5s 29ms/step - loss: 0.5083 - acc: 0.7598 - val_loss: 0.3869 - val_acc: 0.8484\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.3119 - acc: 0.8777 - val_loss: 0.3092 - val_acc: 0.8816\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.2424 - acc: 0.9083 - val_loss: 0.2796 - val_acc: 0.8876\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.2039 - acc: 0.9255 - val_loss: 0.2807 - val_acc: 0.8882\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.1765 - acc: 0.9355 - val_loss: 0.3025 - val_acc: 0.8882\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1610 - acc: 0.9420 - val_loss: 0.3756 - val_acc: 0.8818\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1494 - acc: 0.9481 - val_loss: 0.3431 - val_acc: 0.8472\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1336 - acc: 0.9548 - val_loss: 0.3184 - val_acc: 0.8724\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1235 - acc: 0.9570 - val_loss: 0.3947 - val_acc: 0.8834\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1141 - acc: 0.9598 - val_loss: 0.3832 - val_acc: 0.8420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4bQkVK2_jDF"
      },
      "source": [
        "This time, you achieve up to 89% validation accuracy. Not bad: certainly much better\n",
        "than the SimpleRNN network—that’s largely because **LSTM** suffers much less from the\n",
        "vanishing-gradient problem—and slightly better than the fully connected approach\n",
        "from chapter 3, even though you’re looking at less data than you were in chapter 3.\n",
        "You’re truncating sequences after 500 timesteps, whereas in chapter 3, you were considering full sequences.<br>\n",
        "\n",
        " But this result isn’t groundbreaking for such a computationally intensive\n",
        "approach. Why isn’t **LSTM** performing better? One reason is that you made no effort\n",
        "to tune hyperparameters such as the embeddings dimensionality or the LSTM output\n",
        "dimensionality. Another may be lack of regularization. But honestly, the primary reason is that analyzing the **global, long-term structure of the reviews** (what LSTM is good\n",
        "at) isn’t helpful for a sentiment-analysis problem. Such a basic problem is well solved\n",
        "by looking at what words occur in each review, and at what frequency. That’s what the\n",
        "first fully connected approach looked at. But there are far more difficult natural language processing problems out there, where the strength of LSTM will become\n",
        "apparent: in particular, question-answering and machine translation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqGXY46L_dSV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSC2P9yhgtPn",
        "outputId": "4a902974-8bcb-46ee-be14-32b0496bcca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# Using the LSTM Layer in Keras\n",
        "\n",
        "from keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(input_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0bf639f81c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8p2APMLhE5M"
      },
      "source": [
        "# Plotting results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "\n",
        "\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Rnw5uJmfOj"
      },
      "source": [
        ""
      ]
    }
  ]
}